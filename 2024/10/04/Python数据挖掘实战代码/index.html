

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="https://tingfeng-1320726713.cos.ap-beijing.myqcloud.com/halo/assets/fluid.png">
  <link rel="icon" href="https://tingfeng-1320726713.cos.ap-beijing.myqcloud.com/halo/assets/avatar.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Tingfeng">
  <meta name="keywords" content="">
  
    <meta name="description" content="Python数据挖掘实战课本代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969">
<meta property="og:type" content="article">
<meta property="og:title" content="Python数据挖掘实战代码">
<meta property="og:url" content="http://example.com/2024/10/04/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%98%E4%BB%A3%E7%A0%81/index.html">
<meta property="og:site_name" content="博客">
<meta property="og:description" content="Python数据挖掘实战课本代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://tingfeng-1320726713.cos.ap-beijing.myqcloud.com/halo/assets/%E5%AD%A6%E4%B9%A01.jpg">
<meta property="article:published_time" content="2024-10-04T13:20:00.000Z">
<meta property="article:modified_time" content="2025-02-13T03:20:43.589Z">
<meta property="article:author" content="Tingfeng">
<meta property="article:tag" content="python">
<meta property="article:tag" content="数据挖掘">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://tingfeng-1320726713.cos.ap-beijing.myqcloud.com/halo/assets/%E5%AD%A6%E4%B9%A01.jpg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>Python数据挖掘实战代码 - 博客</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/cloudedGlass.css">
<link rel="stylesheet" href="/css/selection.css">
<link rel="stylesheet" href="/css/scrollAnimation.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":80,"cursorChar":" ","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"https://tingfeng-1320726713.cos.ap-beijing.myqcloud.com/halo/assets/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"GkY2x4ae58lAD0OBkJHcUJ1P-gzGzoHsz","app_key":"xm4CRyD3XgXRCAPjCnvvIJe4","server_url":null,"path":"window.location.pathname","ignore_local":true}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', '');
        });
      }
    </script>
  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 7.1.1"><link rel="alternate" href="/atom.xml" title="博客" type="application/atom+xml">
</head>


<body><!-- hexo injector body_begin start --><div id="web_bg"></div><!-- hexo injector body_begin end -->
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://tingfeng-1320726713.cos.ap-beijing.myqcloud.com/halo/assets/%E4%B8%BB%E9%A1%B5.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Python数据挖掘实战代码"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-10-04 21:20" pubdate>
          2024年10月4日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          17k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          140 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Python数据挖掘实战代码</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="Python数据挖掘实战"><a href="#Python数据挖掘实战" class="headerlink" title="Python数据挖掘实战"></a>Python数据挖掘实战</h1><h2 id="课本代码"><a href="#课本代码" class="headerlink" title="课本代码"></a>课本代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br><span class="line">715</span><br><span class="line">716</span><br><span class="line">717</span><br><span class="line">718</span><br><span class="line">719</span><br><span class="line">720</span><br><span class="line">721</span><br><span class="line">722</span><br><span class="line">723</span><br><span class="line">724</span><br><span class="line">725</span><br><span class="line">726</span><br><span class="line">727</span><br><span class="line">728</span><br><span class="line">729</span><br><span class="line">730</span><br><span class="line">731</span><br><span class="line">732</span><br><span class="line">733</span><br><span class="line">734</span><br><span class="line">735</span><br><span class="line">736</span><br><span class="line">737</span><br><span class="line">738</span><br><span class="line">739</span><br><span class="line">740</span><br><span class="line">741</span><br><span class="line">742</span><br><span class="line">743</span><br><span class="line">744</span><br><span class="line">745</span><br><span class="line">746</span><br><span class="line">747</span><br><span class="line">748</span><br><span class="line">749</span><br><span class="line">750</span><br><span class="line">751</span><br><span class="line">752</span><br><span class="line">753</span><br><span class="line">754</span><br><span class="line">755</span><br><span class="line">756</span><br><span class="line">757</span><br><span class="line">758</span><br><span class="line">759</span><br><span class="line">760</span><br><span class="line">761</span><br><span class="line">762</span><br><span class="line">763</span><br><span class="line">764</span><br><span class="line">765</span><br><span class="line">766</span><br><span class="line">767</span><br><span class="line">768</span><br><span class="line">769</span><br><span class="line">770</span><br><span class="line">771</span><br><span class="line">772</span><br><span class="line">773</span><br><span class="line">774</span><br><span class="line">775</span><br><span class="line">776</span><br><span class="line">777</span><br><span class="line">778</span><br><span class="line">779</span><br><span class="line">780</span><br><span class="line">781</span><br><span class="line">782</span><br><span class="line">783</span><br><span class="line">784</span><br><span class="line">785</span><br><span class="line">786</span><br><span class="line">787</span><br><span class="line">788</span><br><span class="line">789</span><br><span class="line">790</span><br><span class="line">791</span><br><span class="line">792</span><br><span class="line">793</span><br><span class="line">794</span><br><span class="line">795</span><br><span class="line">796</span><br><span class="line">797</span><br><span class="line">798</span><br><span class="line">799</span><br><span class="line">800</span><br><span class="line">801</span><br><span class="line">802</span><br><span class="line">803</span><br><span class="line">804</span><br><span class="line">805</span><br><span class="line">806</span><br><span class="line">807</span><br><span class="line">808</span><br><span class="line">809</span><br><span class="line">810</span><br><span class="line">811</span><br><span class="line">812</span><br><span class="line">813</span><br><span class="line">814</span><br><span class="line">815</span><br><span class="line">816</span><br><span class="line">817</span><br><span class="line">818</span><br><span class="line">819</span><br><span class="line">820</span><br><span class="line">821</span><br><span class="line">822</span><br><span class="line">823</span><br><span class="line">824</span><br><span class="line">825</span><br><span class="line">826</span><br><span class="line">827</span><br><span class="line">828</span><br><span class="line">829</span><br><span class="line">830</span><br><span class="line">831</span><br><span class="line">832</span><br><span class="line">833</span><br><span class="line">834</span><br><span class="line">835</span><br><span class="line">836</span><br><span class="line">837</span><br><span class="line">838</span><br><span class="line">839</span><br><span class="line">840</span><br><span class="line">841</span><br><span class="line">842</span><br><span class="line">843</span><br><span class="line">844</span><br><span class="line">845</span><br><span class="line">846</span><br><span class="line">847</span><br><span class="line">848</span><br><span class="line">849</span><br><span class="line">850</span><br><span class="line">851</span><br><span class="line">852</span><br><span class="line">853</span><br><span class="line">854</span><br><span class="line">855</span><br><span class="line">856</span><br><span class="line">857</span><br><span class="line">858</span><br><span class="line">859</span><br><span class="line">860</span><br><span class="line">861</span><br><span class="line">862</span><br><span class="line">863</span><br><span class="line">864</span><br><span class="line">865</span><br><span class="line">866</span><br><span class="line">867</span><br><span class="line">868</span><br><span class="line">869</span><br><span class="line">870</span><br><span class="line">871</span><br><span class="line">872</span><br><span class="line">873</span><br><span class="line">874</span><br><span class="line">875</span><br><span class="line">876</span><br><span class="line">877</span><br><span class="line">878</span><br><span class="line">879</span><br><span class="line">880</span><br><span class="line">881</span><br><span class="line">882</span><br><span class="line">883</span><br><span class="line">884</span><br><span class="line">885</span><br><span class="line">886</span><br><span class="line">887</span><br><span class="line">888</span><br><span class="line">889</span><br><span class="line">890</span><br><span class="line">891</span><br><span class="line">892</span><br><span class="line">893</span><br><span class="line">894</span><br><span class="line">895</span><br><span class="line">896</span><br><span class="line">897</span><br><span class="line">898</span><br><span class="line">899</span><br><span class="line">900</span><br><span class="line">901</span><br><span class="line">902</span><br><span class="line">903</span><br><span class="line">904</span><br><span class="line">905</span><br><span class="line">906</span><br><span class="line">907</span><br><span class="line">908</span><br><span class="line">909</span><br><span class="line">910</span><br><span class="line">911</span><br><span class="line">912</span><br><span class="line">913</span><br><span class="line">914</span><br><span class="line">915</span><br><span class="line">916</span><br><span class="line">917</span><br><span class="line">918</span><br><span class="line">919</span><br><span class="line">920</span><br><span class="line">921</span><br><span class="line">922</span><br><span class="line">923</span><br><span class="line">924</span><br><span class="line">925</span><br><span class="line">926</span><br><span class="line">927</span><br><span class="line">928</span><br><span class="line">929</span><br><span class="line">930</span><br><span class="line">931</span><br><span class="line">932</span><br><span class="line">933</span><br><span class="line">934</span><br><span class="line">935</span><br><span class="line">936</span><br><span class="line">937</span><br><span class="line">938</span><br><span class="line">939</span><br><span class="line">940</span><br><span class="line">941</span><br><span class="line">942</span><br><span class="line">943</span><br><span class="line">944</span><br><span class="line">945</span><br><span class="line">946</span><br><span class="line">947</span><br><span class="line">948</span><br><span class="line">949</span><br><span class="line">950</span><br><span class="line">951</span><br><span class="line">952</span><br><span class="line">953</span><br><span class="line">954</span><br><span class="line">955</span><br><span class="line">956</span><br><span class="line">957</span><br><span class="line">958</span><br><span class="line">959</span><br><span class="line">960</span><br><span class="line">961</span><br><span class="line">962</span><br><span class="line">963</span><br><span class="line">964</span><br><span class="line">965</span><br><span class="line">966</span><br><span class="line">967</span><br><span class="line">968</span><br><span class="line">969</span><br><span class="line">970</span><br><span class="line">971</span><br><span class="line">972</span><br><span class="line">973</span><br><span class="line">974</span><br><span class="line">975</span><br><span class="line">976</span><br><span class="line">977</span><br><span class="line">978</span><br><span class="line">979</span><br><span class="line">980</span><br><span class="line">981</span><br><span class="line">982</span><br><span class="line">983</span><br><span class="line">984</span><br><span class="line">985</span><br><span class="line">986</span><br><span class="line">987</span><br><span class="line">988</span><br><span class="line">989</span><br><span class="line">990</span><br><span class="line">991</span><br><span class="line">992</span><br><span class="line">993</span><br><span class="line">994</span><br><span class="line">995</span><br><span class="line">996</span><br><span class="line">997</span><br><span class="line">998</span><br><span class="line">999</span><br><span class="line">1000</span><br><span class="line">1001</span><br><span class="line">1002</span><br><span class="line">1003</span><br><span class="line">1004</span><br><span class="line">1005</span><br><span class="line">1006</span><br><span class="line">1007</span><br><span class="line">1008</span><br><span class="line">1009</span><br><span class="line">1010</span><br><span class="line">1011</span><br><span class="line">1012</span><br><span class="line">1013</span><br><span class="line">1014</span><br><span class="line">1015</span><br><span class="line">1016</span><br><span class="line">1017</span><br><span class="line">1018</span><br><span class="line">1019</span><br><span class="line">1020</span><br><span class="line">1021</span><br><span class="line">1022</span><br><span class="line">1023</span><br><span class="line">1024</span><br><span class="line">1025</span><br><span class="line">1026</span><br><span class="line">1027</span><br><span class="line">1028</span><br><span class="line">1029</span><br><span class="line">1030</span><br><span class="line">1031</span><br><span class="line">1032</span><br><span class="line">1033</span><br><span class="line">1034</span><br><span class="line">1035</span><br><span class="line">1036</span><br><span class="line">1037</span><br><span class="line">1038</span><br><span class="line">1039</span><br><span class="line">1040</span><br><span class="line">1041</span><br><span class="line">1042</span><br><span class="line">1043</span><br><span class="line">1044</span><br><span class="line">1045</span><br><span class="line">1046</span><br><span class="line">1047</span><br><span class="line">1048</span><br><span class="line">1049</span><br><span class="line">1050</span><br><span class="line">1051</span><br><span class="line">1052</span><br><span class="line">1053</span><br><span class="line">1054</span><br><span class="line">1055</span><br><span class="line">1056</span><br><span class="line">1057</span><br><span class="line">1058</span><br><span class="line">1059</span><br><span class="line">1060</span><br><span class="line">1061</span><br><span class="line">1062</span><br><span class="line">1063</span><br><span class="line">1064</span><br><span class="line">1065</span><br><span class="line">1066</span><br><span class="line">1067</span><br><span class="line">1068</span><br><span class="line">1069</span><br><span class="line">1070</span><br><span class="line">1071</span><br><span class="line">1072</span><br><span class="line">1073</span><br><span class="line">1074</span><br><span class="line">1075</span><br><span class="line">1076</span><br><span class="line">1077</span><br><span class="line">1078</span><br><span class="line">1079</span><br><span class="line">1080</span><br><span class="line">1081</span><br><span class="line">1082</span><br><span class="line">1083</span><br><span class="line">1084</span><br><span class="line">1085</span><br><span class="line">1086</span><br><span class="line">1087</span><br><span class="line">1088</span><br><span class="line">1089</span><br><span class="line">1090</span><br><span class="line">1091</span><br><span class="line">1092</span><br><span class="line">1093</span><br><span class="line">1094</span><br><span class="line">1095</span><br><span class="line">1096</span><br><span class="line">1097</span><br><span class="line">1098</span><br><span class="line">1099</span><br><span class="line">1100</span><br><span class="line">1101</span><br><span class="line">1102</span><br><span class="line">1103</span><br><span class="line">1104</span><br><span class="line">1105</span><br><span class="line">1106</span><br><span class="line">1107</span><br><span class="line">1108</span><br><span class="line">1109</span><br><span class="line">1110</span><br><span class="line">1111</span><br><span class="line">1112</span><br><span class="line">1113</span><br><span class="line">1114</span><br><span class="line">1115</span><br><span class="line">1116</span><br><span class="line">1117</span><br><span class="line">1118</span><br><span class="line">1119</span><br><span class="line">1120</span><br><span class="line">1121</span><br><span class="line">1122</span><br><span class="line">1123</span><br><span class="line">1124</span><br><span class="line">1125</span><br><span class="line">1126</span><br><span class="line">1127</span><br><span class="line">1128</span><br><span class="line">1129</span><br><span class="line">1130</span><br><span class="line">1131</span><br><span class="line">1132</span><br><span class="line">1133</span><br><span class="line">1134</span><br><span class="line">1135</span><br><span class="line">1136</span><br><span class="line">1137</span><br><span class="line">1138</span><br><span class="line">1139</span><br><span class="line">1140</span><br><span class="line">1141</span><br><span class="line">1142</span><br><span class="line">1143</span><br><span class="line">1144</span><br><span class="line">1145</span><br><span class="line">1146</span><br><span class="line">1147</span><br><span class="line">1148</span><br><span class="line">1149</span><br><span class="line">1150</span><br><span class="line">1151</span><br><span class="line">1152</span><br><span class="line">1153</span><br><span class="line">1154</span><br><span class="line">1155</span><br><span class="line">1156</span><br><span class="line">1157</span><br><span class="line">1158</span><br><span class="line">1159</span><br><span class="line">1160</span><br><span class="line">1161</span><br><span class="line">1162</span><br><span class="line">1163</span><br><span class="line">1164</span><br><span class="line">1165</span><br><span class="line">1166</span><br><span class="line">1167</span><br><span class="line">1168</span><br><span class="line">1169</span><br><span class="line">1170</span><br><span class="line">1171</span><br><span class="line">1172</span><br><span class="line">1173</span><br><span class="line">1174</span><br><span class="line">1175</span><br><span class="line">1176</span><br><span class="line">1177</span><br><span class="line">1178</span><br><span class="line">1179</span><br><span class="line">1180</span><br><span class="line">1181</span><br><span class="line">1182</span><br><span class="line">1183</span><br><span class="line">1184</span><br><span class="line">1185</span><br><span class="line">1186</span><br><span class="line">1187</span><br><span class="line">1188</span><br><span class="line">1189</span><br><span class="line">1190</span><br><span class="line">1191</span><br><span class="line">1192</span><br><span class="line">1193</span><br><span class="line">1194</span><br><span class="line">1195</span><br><span class="line">1196</span><br><span class="line">1197</span><br><span class="line">1198</span><br><span class="line">1199</span><br><span class="line">1200</span><br><span class="line">1201</span><br><span class="line">1202</span><br><span class="line">1203</span><br><span class="line">1204</span><br><span class="line">1205</span><br><span class="line">1206</span><br><span class="line">1207</span><br><span class="line">1208</span><br><span class="line">1209</span><br><span class="line">1210</span><br><span class="line">1211</span><br><span class="line">1212</span><br><span class="line">1213</span><br><span class="line">1214</span><br><span class="line">1215</span><br><span class="line">1216</span><br><span class="line">1217</span><br><span class="line">1218</span><br><span class="line">1219</span><br><span class="line">1220</span><br><span class="line">1221</span><br><span class="line">1222</span><br><span class="line">1223</span><br><span class="line">1224</span><br><span class="line">1225</span><br><span class="line">1226</span><br><span class="line">1227</span><br><span class="line">1228</span><br><span class="line">1229</span><br><span class="line">1230</span><br><span class="line">1231</span><br><span class="line">1232</span><br><span class="line">1233</span><br><span class="line">1234</span><br><span class="line">1235</span><br><span class="line">1236</span><br><span class="line">1237</span><br><span class="line">1238</span><br><span class="line">1239</span><br><span class="line">1240</span><br><span class="line">1241</span><br><span class="line">1242</span><br><span class="line">1243</span><br><span class="line">1244</span><br><span class="line">1245</span><br><span class="line">1246</span><br><span class="line">1247</span><br><span class="line">1248</span><br><span class="line">1249</span><br><span class="line">1250</span><br><span class="line">1251</span><br><span class="line">1252</span><br><span class="line">1253</span><br><span class="line">1254</span><br><span class="line">1255</span><br><span class="line">1256</span><br><span class="line">1257</span><br><span class="line">1258</span><br><span class="line">1259</span><br><span class="line">1260</span><br><span class="line">1261</span><br><span class="line">1262</span><br><span class="line">1263</span><br><span class="line">1264</span><br><span class="line">1265</span><br><span class="line">1266</span><br><span class="line">1267</span><br><span class="line">1268</span><br><span class="line">1269</span><br><span class="line">1270</span><br><span class="line">1271</span><br><span class="line">1272</span><br><span class="line">1273</span><br><span class="line">1274</span><br><span class="line">1275</span><br><span class="line">1276</span><br><span class="line">1277</span><br><span class="line">1278</span><br><span class="line">1279</span><br><span class="line">1280</span><br><span class="line">1281</span><br><span class="line">1282</span><br><span class="line">1283</span><br><span class="line">1284</span><br><span class="line">1285</span><br><span class="line">1286</span><br><span class="line">1287</span><br><span class="line">1288</span><br><span class="line">1289</span><br><span class="line">1290</span><br><span class="line">1291</span><br><span class="line">1292</span><br><span class="line">1293</span><br><span class="line">1294</span><br><span class="line">1295</span><br><span class="line">1296</span><br><span class="line">1297</span><br><span class="line">1298</span><br><span class="line">1299</span><br><span class="line">1300</span><br><span class="line">1301</span><br><span class="line">1302</span><br><span class="line">1303</span><br><span class="line">1304</span><br><span class="line">1305</span><br><span class="line">1306</span><br><span class="line">1307</span><br><span class="line">1308</span><br><span class="line">1309</span><br><span class="line">1310</span><br><span class="line">1311</span><br><span class="line">1312</span><br><span class="line">1313</span><br><span class="line">1314</span><br><span class="line">1315</span><br><span class="line">1316</span><br><span class="line">1317</span><br><span class="line">1318</span><br><span class="line">1319</span><br><span class="line">1320</span><br><span class="line">1321</span><br><span class="line">1322</span><br><span class="line">1323</span><br><span class="line">1324</span><br><span class="line">1325</span><br><span class="line">1326</span><br><span class="line">1327</span><br><span class="line">1328</span><br><span class="line">1329</span><br><span class="line">1330</span><br><span class="line">1331</span><br><span class="line">1332</span><br><span class="line">1333</span><br><span class="line">1334</span><br><span class="line">1335</span><br><span class="line">1336</span><br><span class="line">1337</span><br><span class="line">1338</span><br><span class="line">1339</span><br><span class="line">1340</span><br><span class="line">1341</span><br><span class="line">1342</span><br><span class="line">1343</span><br><span class="line">1344</span><br><span class="line">1345</span><br><span class="line">1346</span><br><span class="line">1347</span><br><span class="line">1348</span><br><span class="line">1349</span><br><span class="line">1350</span><br><span class="line">1351</span><br><span class="line">1352</span><br><span class="line">1353</span><br><span class="line">1354</span><br><span class="line">1355</span><br><span class="line">1356</span><br><span class="line">1357</span><br><span class="line">1358</span><br><span class="line">1359</span><br><span class="line">1360</span><br><span class="line">1361</span><br><span class="line">1362</span><br><span class="line">1363</span><br><span class="line">1364</span><br><span class="line">1365</span><br><span class="line">1366</span><br><span class="line">1367</span><br><span class="line">1368</span><br><span class="line">1369</span><br><span class="line">1370</span><br><span class="line">1371</span><br><span class="line">1372</span><br><span class="line">1373</span><br><span class="line">1374</span><br><span class="line">1375</span><br><span class="line">1376</span><br><span class="line">1377</span><br><span class="line">1378</span><br><span class="line">1379</span><br><span class="line">1380</span><br><span class="line">1381</span><br><span class="line">1382</span><br><span class="line">1383</span><br><span class="line">1384</span><br><span class="line">1385</span><br><span class="line">1386</span><br><span class="line">1387</span><br><span class="line">1388</span><br><span class="line">1389</span><br><span class="line">1390</span><br><span class="line">1391</span><br><span class="line">1392</span><br><span class="line">1393</span><br><span class="line">1394</span><br><span class="line">1395</span><br><span class="line">1396</span><br><span class="line">1397</span><br><span class="line">1398</span><br><span class="line">1399</span><br><span class="line">1400</span><br><span class="line">1401</span><br><span class="line">1402</span><br><span class="line">1403</span><br><span class="line">1404</span><br><span class="line">1405</span><br><span class="line">1406</span><br><span class="line">1407</span><br><span class="line">1408</span><br><span class="line">1409</span><br><span class="line">1410</span><br><span class="line">1411</span><br><span class="line">1412</span><br><span class="line">1413</span><br><span class="line">1414</span><br><span class="line">1415</span><br><span class="line">1416</span><br><span class="line">1417</span><br><span class="line">1418</span><br><span class="line">1419</span><br><span class="line">1420</span><br><span class="line">1421</span><br><span class="line">1422</span><br><span class="line">1423</span><br><span class="line">1424</span><br><span class="line">1425</span><br><span class="line">1426</span><br><span class="line">1427</span><br><span class="line">1428</span><br><span class="line">1429</span><br><span class="line">1430</span><br><span class="line">1431</span><br><span class="line">1432</span><br><span class="line">1433</span><br><span class="line">1434</span><br><span class="line">1435</span><br><span class="line">1436</span><br><span class="line">1437</span><br><span class="line">1438</span><br><span class="line">1439</span><br><span class="line">1440</span><br><span class="line">1441</span><br><span class="line">1442</span><br><span class="line">1443</span><br><span class="line">1444</span><br><span class="line">1445</span><br><span class="line">1446</span><br><span class="line">1447</span><br><span class="line">1448</span><br><span class="line">1449</span><br><span class="line">1450</span><br><span class="line">1451</span><br><span class="line">1452</span><br><span class="line">1453</span><br><span class="line">1454</span><br><span class="line">1455</span><br><span class="line">1456</span><br><span class="line">1457</span><br><span class="line">1458</span><br><span class="line">1459</span><br><span class="line">1460</span><br><span class="line">1461</span><br><span class="line">1462</span><br><span class="line">1463</span><br><span class="line">1464</span><br><span class="line">1465</span><br><span class="line">1466</span><br><span class="line">1467</span><br><span class="line">1468</span><br><span class="line">1469</span><br><span class="line">1470</span><br><span class="line">1471</span><br><span class="line">1472</span><br><span class="line">1473</span><br><span class="line">1474</span><br><span class="line">1475</span><br><span class="line">1476</span><br><span class="line">1477</span><br><span class="line">1478</span><br><span class="line">1479</span><br><span class="line">1480</span><br><span class="line">1481</span><br><span class="line">1482</span><br><span class="line">1483</span><br><span class="line">1484</span><br><span class="line">1485</span><br><span class="line">1486</span><br><span class="line">1487</span><br><span class="line">1488</span><br><span class="line">1489</span><br><span class="line">1490</span><br><span class="line">1491</span><br><span class="line">1492</span><br><span class="line">1493</span><br><span class="line">1494</span><br><span class="line">1495</span><br><span class="line">1496</span><br><span class="line">1497</span><br><span class="line">1498</span><br><span class="line">1499</span><br><span class="line">1500</span><br><span class="line">1501</span><br><span class="line">1502</span><br><span class="line">1503</span><br><span class="line">1504</span><br><span class="line">1505</span><br><span class="line">1506</span><br><span class="line">1507</span><br><span class="line">1508</span><br><span class="line">1509</span><br><span class="line">1510</span><br><span class="line">1511</span><br><span class="line">1512</span><br><span class="line">1513</span><br><span class="line">1514</span><br><span class="line">1515</span><br><span class="line">1516</span><br><span class="line">1517</span><br><span class="line">1518</span><br><span class="line">1519</span><br><span class="line">1520</span><br><span class="line">1521</span><br><span class="line">1522</span><br><span class="line">1523</span><br><span class="line">1524</span><br><span class="line">1525</span><br><span class="line">1526</span><br><span class="line">1527</span><br><span class="line">1528</span><br><span class="line">1529</span><br><span class="line">1530</span><br><span class="line">1531</span><br><span class="line">1532</span><br><span class="line">1533</span><br><span class="line">1534</span><br><span class="line">1535</span><br><span class="line">1536</span><br><span class="line">1537</span><br><span class="line">1538</span><br><span class="line">1539</span><br><span class="line">1540</span><br><span class="line">1541</span><br><span class="line">1542</span><br><span class="line">1543</span><br><span class="line">1544</span><br><span class="line">1545</span><br><span class="line">1546</span><br><span class="line">1547</span><br><span class="line">1548</span><br><span class="line">1549</span><br><span class="line">1550</span><br><span class="line">1551</span><br><span class="line">1552</span><br><span class="line">1553</span><br><span class="line">1554</span><br><span class="line">1555</span><br><span class="line">1556</span><br><span class="line">1557</span><br><span class="line">1558</span><br><span class="line">1559</span><br><span class="line">1560</span><br><span class="line">1561</span><br><span class="line">1562</span><br><span class="line">1563</span><br><span class="line">1564</span><br><span class="line">1565</span><br><span class="line">1566</span><br><span class="line">1567</span><br><span class="line">1568</span><br><span class="line">1569</span><br><span class="line">1570</span><br><span class="line">1571</span><br><span class="line">1572</span><br><span class="line">1573</span><br><span class="line">1574</span><br><span class="line">1575</span><br><span class="line">1576</span><br><span class="line">1577</span><br><span class="line">1578</span><br><span class="line">1579</span><br><span class="line">1580</span><br><span class="line">1581</span><br><span class="line">1582</span><br><span class="line">1583</span><br><span class="line">1584</span><br><span class="line">1585</span><br><span class="line">1586</span><br><span class="line">1587</span><br><span class="line">1588</span><br><span class="line">1589</span><br><span class="line">1590</span><br><span class="line">1591</span><br><span class="line">1592</span><br><span class="line">1593</span><br><span class="line">1594</span><br><span class="line">1595</span><br><span class="line">1596</span><br><span class="line">1597</span><br><span class="line">1598</span><br><span class="line">1599</span><br><span class="line">1600</span><br><span class="line">1601</span><br><span class="line">1602</span><br><span class="line">1603</span><br><span class="line">1604</span><br><span class="line">1605</span><br><span class="line">1606</span><br><span class="line">1607</span><br><span class="line">1608</span><br><span class="line">1609</span><br><span class="line">1610</span><br><span class="line">1611</span><br><span class="line">1612</span><br><span class="line">1613</span><br><span class="line">1614</span><br><span class="line">1615</span><br><span class="line">1616</span><br><span class="line">1617</span><br><span class="line">1618</span><br><span class="line">1619</span><br><span class="line">1620</span><br><span class="line">1621</span><br><span class="line">1622</span><br><span class="line">1623</span><br><span class="line">1624</span><br><span class="line">1625</span><br><span class="line">1626</span><br><span class="line">1627</span><br><span class="line">1628</span><br><span class="line">1629</span><br><span class="line">1630</span><br><span class="line">1631</span><br><span class="line">1632</span><br><span class="line">1633</span><br><span class="line">1634</span><br><span class="line">1635</span><br><span class="line">1636</span><br><span class="line">1637</span><br><span class="line">1638</span><br><span class="line">1639</span><br><span class="line">1640</span><br><span class="line">1641</span><br><span class="line">1642</span><br><span class="line">1643</span><br><span class="line">1644</span><br><span class="line">1645</span><br><span class="line">1646</span><br><span class="line">1647</span><br><span class="line">1648</span><br><span class="line">1649</span><br><span class="line">1650</span><br><span class="line">1651</span><br><span class="line">1652</span><br><span class="line">1653</span><br><span class="line">1654</span><br><span class="line">1655</span><br><span class="line">1656</span><br><span class="line">1657</span><br><span class="line">1658</span><br><span class="line">1659</span><br><span class="line">1660</span><br><span class="line">1661</span><br><span class="line">1662</span><br><span class="line">1663</span><br><span class="line">1664</span><br><span class="line">1665</span><br><span class="line">1666</span><br><span class="line">1667</span><br><span class="line">1668</span><br><span class="line">1669</span><br><span class="line">1670</span><br><span class="line">1671</span><br><span class="line">1672</span><br><span class="line">1673</span><br><span class="line">1674</span><br><span class="line">1675</span><br><span class="line">1676</span><br><span class="line">1677</span><br><span class="line">1678</span><br><span class="line">1679</span><br><span class="line">1680</span><br><span class="line">1681</span><br><span class="line">1682</span><br><span class="line">1683</span><br><span class="line">1684</span><br><span class="line">1685</span><br><span class="line">1686</span><br><span class="line">1687</span><br><span class="line">1688</span><br><span class="line">1689</span><br><span class="line">1690</span><br><span class="line">1691</span><br><span class="line">1692</span><br><span class="line">1693</span><br><span class="line">1694</span><br><span class="line">1695</span><br><span class="line">1696</span><br><span class="line">1697</span><br><span class="line">1698</span><br><span class="line">1699</span><br><span class="line">1700</span><br><span class="line">1701</span><br><span class="line">1702</span><br><span class="line">1703</span><br><span class="line">1704</span><br><span class="line">1705</span><br><span class="line">1706</span><br><span class="line">1707</span><br><span class="line">1708</span><br><span class="line">1709</span><br><span class="line">1710</span><br><span class="line">1711</span><br><span class="line">1712</span><br><span class="line">1713</span><br><span class="line">1714</span><br><span class="line">1715</span><br><span class="line">1716</span><br><span class="line">1717</span><br><span class="line">1718</span><br><span class="line">1719</span><br><span class="line">1720</span><br><span class="line">1721</span><br><span class="line">1722</span><br><span class="line">1723</span><br><span class="line">1724</span><br><span class="line">1725</span><br><span class="line">1726</span><br><span class="line">1727</span><br><span class="line">1728</span><br><span class="line">1729</span><br><span class="line">1730</span><br><span class="line">1731</span><br><span class="line">1732</span><br><span class="line">1733</span><br><span class="line">1734</span><br><span class="line">1735</span><br><span class="line">1736</span><br><span class="line">1737</span><br><span class="line">1738</span><br><span class="line">1739</span><br><span class="line">1740</span><br><span class="line">1741</span><br><span class="line">1742</span><br><span class="line">1743</span><br><span class="line">1744</span><br><span class="line">1745</span><br><span class="line">1746</span><br><span class="line">1747</span><br><span class="line">1748</span><br><span class="line">1749</span><br><span class="line">1750</span><br><span class="line">1751</span><br><span class="line">1752</span><br><span class="line">1753</span><br><span class="line">1754</span><br><span class="line">1755</span><br><span class="line">1756</span><br><span class="line">1757</span><br><span class="line">1758</span><br><span class="line">1759</span><br><span class="line">1760</span><br><span class="line">1761</span><br><span class="line">1762</span><br><span class="line">1763</span><br><span class="line">1764</span><br><span class="line">1765</span><br><span class="line">1766</span><br><span class="line">1767</span><br><span class="line">1768</span><br><span class="line">1769</span><br><span class="line">1770</span><br><span class="line">1771</span><br><span class="line">1772</span><br><span class="line">1773</span><br><span class="line">1774</span><br><span class="line">1775</span><br><span class="line">1776</span><br><span class="line">1777</span><br><span class="line">1778</span><br><span class="line">1779</span><br><span class="line">1780</span><br><span class="line">1781</span><br><span class="line">1782</span><br><span class="line">1783</span><br><span class="line">1784</span><br><span class="line">1785</span><br><span class="line">1786</span><br><span class="line">1787</span><br><span class="line">1788</span><br><span class="line">1789</span><br><span class="line">1790</span><br><span class="line">1791</span><br><span class="line">1792</span><br><span class="line">1793</span><br><span class="line">1794</span><br><span class="line">1795</span><br><span class="line">1796</span><br><span class="line">1797</span><br><span class="line">1798</span><br><span class="line">1799</span><br><span class="line">1800</span><br><span class="line">1801</span><br><span class="line">1802</span><br><span class="line">1803</span><br><span class="line">1804</span><br><span class="line">1805</span><br><span class="line">1806</span><br><span class="line">1807</span><br><span class="line">1808</span><br><span class="line">1809</span><br><span class="line">1810</span><br><span class="line">1811</span><br><span class="line">1812</span><br><span class="line">1813</span><br><span class="line">1814</span><br><span class="line">1815</span><br><span class="line">1816</span><br><span class="line">1817</span><br><span class="line">1818</span><br><span class="line">1819</span><br><span class="line">1820</span><br><span class="line">1821</span><br><span class="line">1822</span><br><span class="line">1823</span><br><span class="line">1824</span><br><span class="line">1825</span><br><span class="line">1826</span><br><span class="line">1827</span><br><span class="line">1828</span><br><span class="line">1829</span><br><span class="line">1830</span><br><span class="line">1831</span><br><span class="line">1832</span><br><span class="line">1833</span><br><span class="line">1834</span><br><span class="line">1835</span><br><span class="line">1836</span><br><span class="line">1837</span><br><span class="line">1838</span><br><span class="line">1839</span><br><span class="line">1840</span><br><span class="line">1841</span><br><span class="line">1842</span><br><span class="line">1843</span><br><span class="line">1844</span><br><span class="line">1845</span><br><span class="line">1846</span><br><span class="line">1847</span><br><span class="line">1848</span><br><span class="line">1849</span><br><span class="line">1850</span><br><span class="line">1851</span><br><span class="line">1852</span><br><span class="line">1853</span><br><span class="line">1854</span><br><span class="line">1855</span><br><span class="line">1856</span><br><span class="line">1857</span><br><span class="line">1858</span><br><span class="line">1859</span><br><span class="line">1860</span><br><span class="line">1861</span><br><span class="line">1862</span><br><span class="line">1863</span><br><span class="line">1864</span><br><span class="line">1865</span><br><span class="line">1866</span><br><span class="line">1867</span><br><span class="line">1868</span><br><span class="line">1869</span><br><span class="line">1870</span><br><span class="line">1871</span><br><span class="line">1872</span><br><span class="line">1873</span><br><span class="line">1874</span><br><span class="line">1875</span><br><span class="line">1876</span><br><span class="line">1877</span><br><span class="line">1878</span><br><span class="line">1879</span><br><span class="line">1880</span><br><span class="line">1881</span><br><span class="line">1882</span><br><span class="line">1883</span><br><span class="line">1884</span><br><span class="line">1885</span><br><span class="line">1886</span><br><span class="line">1887</span><br><span class="line">1888</span><br><span class="line">1889</span><br><span class="line">1890</span><br><span class="line">1891</span><br><span class="line">1892</span><br><span class="line">1893</span><br><span class="line">1894</span><br><span class="line">1895</span><br><span class="line">1896</span><br><span class="line">1897</span><br><span class="line">1898</span><br><span class="line">1899</span><br><span class="line">1900</span><br><span class="line">1901</span><br><span class="line">1902</span><br><span class="line">1903</span><br><span class="line">1904</span><br><span class="line">1905</span><br><span class="line">1906</span><br><span class="line">1907</span><br><span class="line">1908</span><br><span class="line">1909</span><br><span class="line">1910</span><br><span class="line">1911</span><br><span class="line">1912</span><br><span class="line">1913</span><br><span class="line">1914</span><br><span class="line">1915</span><br><span class="line">1916</span><br><span class="line">1917</span><br><span class="line">1918</span><br><span class="line">1919</span><br><span class="line">1920</span><br><span class="line">1921</span><br><span class="line">1922</span><br><span class="line">1923</span><br><span class="line">1924</span><br><span class="line">1925</span><br><span class="line">1926</span><br><span class="line">1927</span><br><span class="line">1928</span><br><span class="line">1929</span><br><span class="line">1930</span><br><span class="line">1931</span><br><span class="line">1932</span><br><span class="line">1933</span><br><span class="line">1934</span><br><span class="line">1935</span><br><span class="line">1936</span><br><span class="line">1937</span><br><span class="line">1938</span><br><span class="line">1939</span><br><span class="line">1940</span><br><span class="line">1941</span><br><span class="line">1942</span><br><span class="line">1943</span><br><span class="line">1944</span><br><span class="line">1945</span><br><span class="line">1946</span><br><span class="line">1947</span><br><span class="line">1948</span><br><span class="line">1949</span><br><span class="line">1950</span><br><span class="line">1951</span><br><span class="line">1952</span><br><span class="line">1953</span><br><span class="line">1954</span><br><span class="line">1955</span><br><span class="line">1956</span><br><span class="line">1957</span><br><span class="line">1958</span><br><span class="line">1959</span><br><span class="line">1960</span><br><span class="line">1961</span><br><span class="line">1962</span><br><span class="line">1963</span><br><span class="line">1964</span><br><span class="line">1965</span><br><span class="line">1966</span><br><span class="line">1967</span><br><span class="line">1968</span><br><span class="line">1969</span><br><span class="line">1970</span><br><span class="line">1971</span><br><span class="line">1972</span><br><span class="line">1973</span><br><span class="line">1974</span><br><span class="line">1975</span><br><span class="line">1976</span><br><span class="line">1977</span><br><span class="line">1978</span><br><span class="line">1979</span><br><span class="line">1980</span><br><span class="line">1981</span><br><span class="line">1982</span><br><span class="line">1983</span><br><span class="line">1984</span><br><span class="line">1985</span><br><span class="line">1986</span><br><span class="line">1987</span><br><span class="line">1988</span><br><span class="line">1989</span><br><span class="line">1990</span><br><span class="line">1991</span><br><span class="line">1992</span><br><span class="line">1993</span><br><span class="line">1994</span><br><span class="line">1995</span><br><span class="line">1996</span><br><span class="line">1997</span><br><span class="line">1998</span><br><span class="line">1999</span><br><span class="line">2000</span><br><span class="line">2001</span><br><span class="line">2002</span><br><span class="line">2003</span><br><span class="line">2004</span><br><span class="line">2005</span><br><span class="line">2006</span><br><span class="line">2007</span><br><span class="line">2008</span><br><span class="line">2009</span><br><span class="line">2010</span><br><span class="line">2011</span><br><span class="line">2012</span><br><span class="line">2013</span><br><span class="line">2014</span><br><span class="line">2015</span><br><span class="line">2016</span><br><span class="line">2017</span><br><span class="line">2018</span><br><span class="line">2019</span><br><span class="line">2020</span><br><span class="line">2021</span><br><span class="line">2022</span><br><span class="line">2023</span><br><span class="line">2024</span><br><span class="line">2025</span><br><span class="line">2026</span><br><span class="line">2027</span><br><span class="line">2028</span><br><span class="line">2029</span><br><span class="line">2030</span><br><span class="line">2031</span><br><span class="line">2032</span><br><span class="line">2033</span><br><span class="line">2034</span><br><span class="line">2035</span><br><span class="line">2036</span><br><span class="line">2037</span><br><span class="line">2038</span><br><span class="line">2039</span><br><span class="line">2040</span><br><span class="line">2041</span><br><span class="line">2042</span><br><span class="line">2043</span><br><span class="line">2044</span><br><span class="line">2045</span><br><span class="line">2046</span><br><span class="line">2047</span><br><span class="line">2048</span><br><span class="line">2049</span><br><span class="line">2050</span><br><span class="line">2051</span><br><span class="line">2052</span><br><span class="line">2053</span><br><span class="line">2054</span><br><span class="line">2055</span><br><span class="line">2056</span><br><span class="line">2057</span><br><span class="line">2058</span><br><span class="line">2059</span><br><span class="line">2060</span><br><span class="line">2061</span><br><span class="line">2062</span><br><span class="line">2063</span><br><span class="line">2064</span><br><span class="line">2065</span><br><span class="line">2066</span><br><span class="line">2067</span><br><span class="line">2068</span><br><span class="line">2069</span><br><span class="line">2070</span><br><span class="line">2071</span><br><span class="line">2072</span><br><span class="line">2073</span><br><span class="line">2074</span><br><span class="line">2075</span><br><span class="line">2076</span><br><span class="line">2077</span><br><span class="line">2078</span><br><span class="line">2079</span><br><span class="line">2080</span><br><span class="line">2081</span><br><span class="line">2082</span><br><span class="line">2083</span><br><span class="line">2084</span><br><span class="line">2085</span><br><span class="line">2086</span><br><span class="line">2087</span><br><span class="line">2088</span><br><span class="line">2089</span><br><span class="line">2090</span><br><span class="line">2091</span><br><span class="line">2092</span><br><span class="line">2093</span><br><span class="line">2094</span><br><span class="line">2095</span><br><span class="line">2096</span><br><span class="line">2097</span><br><span class="line">2098</span><br><span class="line">2099</span><br><span class="line">2100</span><br><span class="line">2101</span><br><span class="line">2102</span><br><span class="line">2103</span><br><span class="line">2104</span><br><span class="line">2105</span><br><span class="line">2106</span><br><span class="line">2107</span><br><span class="line">2108</span><br><span class="line">2109</span><br><span class="line">2110</span><br><span class="line">2111</span><br><span class="line">2112</span><br><span class="line">2113</span><br><span class="line">2114</span><br><span class="line">2115</span><br><span class="line">2116</span><br><span class="line">2117</span><br><span class="line">2118</span><br><span class="line">2119</span><br><span class="line">2120</span><br><span class="line">2121</span><br><span class="line">2122</span><br><span class="line">2123</span><br><span class="line">2124</span><br><span class="line">2125</span><br><span class="line">2126</span><br><span class="line">2127</span><br><span class="line">2128</span><br><span class="line">2129</span><br><span class="line">2130</span><br><span class="line">2131</span><br><span class="line">2132</span><br><span class="line">2133</span><br><span class="line">2134</span><br><span class="line">2135</span><br><span class="line">2136</span><br><span class="line">2137</span><br><span class="line">2138</span><br><span class="line">2139</span><br><span class="line">2140</span><br><span class="line">2141</span><br><span class="line">2142</span><br><span class="line">2143</span><br><span class="line">2144</span><br><span class="line">2145</span><br><span class="line">2146</span><br><span class="line">2147</span><br><span class="line">2148</span><br><span class="line">2149</span><br><span class="line">2150</span><br><span class="line">2151</span><br><span class="line">2152</span><br><span class="line">2153</span><br><span class="line">2154</span><br><span class="line">2155</span><br><span class="line">2156</span><br><span class="line">2157</span><br><span class="line">2158</span><br><span class="line">2159</span><br><span class="line">2160</span><br><span class="line">2161</span><br><span class="line">2162</span><br><span class="line">2163</span><br><span class="line">2164</span><br><span class="line">2165</span><br><span class="line">2166</span><br><span class="line">2167</span><br><span class="line">2168</span><br><span class="line">2169</span><br><span class="line">2170</span><br><span class="line">2171</span><br><span class="line">2172</span><br><span class="line">2173</span><br><span class="line">2174</span><br><span class="line">2175</span><br><span class="line">2176</span><br><span class="line">2177</span><br><span class="line">2178</span><br><span class="line">2179</span><br><span class="line">2180</span><br><span class="line">2181</span><br><span class="line">2182</span><br><span class="line">2183</span><br><span class="line">2184</span><br><span class="line">2185</span><br><span class="line">2186</span><br><span class="line">2187</span><br><span class="line">2188</span><br><span class="line">2189</span><br><span class="line">2190</span><br><span class="line">2191</span><br><span class="line">2192</span><br><span class="line">2193</span><br><span class="line">2194</span><br><span class="line">2195</span><br><span class="line">2196</span><br><span class="line">2197</span><br><span class="line">2198</span><br><span class="line">2199</span><br><span class="line">2200</span><br><span class="line">2201</span><br><span class="line">2202</span><br><span class="line">2203</span><br><span class="line">2204</span><br><span class="line">2205</span><br><span class="line">2206</span><br><span class="line">2207</span><br><span class="line">2208</span><br><span class="line">2209</span><br><span class="line">2210</span><br><span class="line">2211</span><br><span class="line">2212</span><br><span class="line">2213</span><br><span class="line">2214</span><br><span class="line">2215</span><br><span class="line">2216</span><br><span class="line">2217</span><br><span class="line">2218</span><br><span class="line">2219</span><br><span class="line">2220</span><br><span class="line">2221</span><br><span class="line">2222</span><br><span class="line">2223</span><br><span class="line">2224</span><br><span class="line">2225</span><br><span class="line">2226</span><br><span class="line">2227</span><br><span class="line">2228</span><br><span class="line">2229</span><br><span class="line">2230</span><br><span class="line">2231</span><br><span class="line">2232</span><br><span class="line">2233</span><br><span class="line">2234</span><br><span class="line">2235</span><br><span class="line">2236</span><br><span class="line">2237</span><br><span class="line">2238</span><br><span class="line">2239</span><br><span class="line">2240</span><br><span class="line">2241</span><br><span class="line">2242</span><br><span class="line">2243</span><br><span class="line">2244</span><br><span class="line">2245</span><br><span class="line">2246</span><br><span class="line">2247</span><br><span class="line">2248</span><br><span class="line">2249</span><br><span class="line">2250</span><br><span class="line">2251</span><br><span class="line">2252</span><br><span class="line">2253</span><br><span class="line">2254</span><br><span class="line">2255</span><br><span class="line">2256</span><br><span class="line">2257</span><br><span class="line">2258</span><br><span class="line">2259</span><br><span class="line">2260</span><br><span class="line">2261</span><br><span class="line">2262</span><br><span class="line">2263</span><br><span class="line">2264</span><br><span class="line">2265</span><br><span class="line">2266</span><br><span class="line">2267</span><br><span class="line">2268</span><br><span class="line">2269</span><br><span class="line">2270</span><br><span class="line">2271</span><br><span class="line">2272</span><br><span class="line">2273</span><br><span class="line">2274</span><br><span class="line">2275</span><br><span class="line">2276</span><br><span class="line">2277</span><br><span class="line">2278</span><br><span class="line">2279</span><br><span class="line">2280</span><br><span class="line">2281</span><br><span class="line">2282</span><br><span class="line">2283</span><br><span class="line">2284</span><br><span class="line">2285</span><br><span class="line">2286</span><br><span class="line">2287</span><br><span class="line">2288</span><br><span class="line">2289</span><br><span class="line">2290</span><br><span class="line">2291</span><br><span class="line">2292</span><br><span class="line">2293</span><br><span class="line">2294</span><br><span class="line">2295</span><br><span class="line">2296</span><br><span class="line">2297</span><br><span class="line">2298</span><br><span class="line">2299</span><br><span class="line">2300</span><br><span class="line">2301</span><br><span class="line">2302</span><br><span class="line">2303</span><br><span class="line">2304</span><br><span class="line">2305</span><br><span class="line">2306</span><br><span class="line">2307</span><br><span class="line">2308</span><br><span class="line">2309</span><br><span class="line">2310</span><br><span class="line">2311</span><br><span class="line">2312</span><br><span class="line">2313</span><br><span class="line">2314</span><br><span class="line">2315</span><br><span class="line">2316</span><br><span class="line">2317</span><br><span class="line">2318</span><br><span class="line">2319</span><br><span class="line">2320</span><br><span class="line">2321</span><br><span class="line">2322</span><br><span class="line">2323</span><br><span class="line">2324</span><br><span class="line">2325</span><br><span class="line">2326</span><br><span class="line">2327</span><br><span class="line">2328</span><br><span class="line">2329</span><br><span class="line">2330</span><br><span class="line">2331</span><br><span class="line">2332</span><br><span class="line">2333</span><br><span class="line">2334</span><br><span class="line">2335</span><br><span class="line">2336</span><br><span class="line">2337</span><br><span class="line">2338</span><br><span class="line">2339</span><br><span class="line">2340</span><br><span class="line">2341</span><br><span class="line">2342</span><br><span class="line">2343</span><br><span class="line">2344</span><br><span class="line">2345</span><br><span class="line">2346</span><br><span class="line">2347</span><br><span class="line">2348</span><br><span class="line">2349</span><br><span class="line">2350</span><br><span class="line">2351</span><br><span class="line">2352</span><br><span class="line">2353</span><br><span class="line">2354</span><br><span class="line">2355</span><br><span class="line">2356</span><br><span class="line">2357</span><br><span class="line">2358</span><br><span class="line">2359</span><br><span class="line">2360</span><br><span class="line">2361</span><br><span class="line">2362</span><br><span class="line">2363</span><br><span class="line">2364</span><br><span class="line">2365</span><br><span class="line">2366</span><br><span class="line">2367</span><br><span class="line">2368</span><br><span class="line">2369</span><br><span class="line">2370</span><br><span class="line">2371</span><br><span class="line">2372</span><br><span class="line">2373</span><br><span class="line">2374</span><br><span class="line">2375</span><br><span class="line">2376</span><br><span class="line">2377</span><br><span class="line">2378</span><br><span class="line">2379</span><br><span class="line">2380</span><br><span class="line">2381</span><br><span class="line">2382</span><br><span class="line">2383</span><br><span class="line">2384</span><br><span class="line">2385</span><br><span class="line">2386</span><br><span class="line">2387</span><br><span class="line">2388</span><br><span class="line">2389</span><br><span class="line">2390</span><br><span class="line">2391</span><br><span class="line">2392</span><br><span class="line">2393</span><br><span class="line">2394</span><br><span class="line">2395</span><br><span class="line">2396</span><br><span class="line">2397</span><br><span class="line">2398</span><br><span class="line">2399</span><br><span class="line">2400</span><br><span class="line">2401</span><br><span class="line">2402</span><br><span class="line">2403</span><br><span class="line">2404</span><br><span class="line">2405</span><br><span class="line">2406</span><br><span class="line">2407</span><br><span class="line">2408</span><br><span class="line">2409</span><br><span class="line">2410</span><br><span class="line">2411</span><br><span class="line">2412</span><br><span class="line">2413</span><br><span class="line">2414</span><br><span class="line">2415</span><br><span class="line">2416</span><br><span class="line">2417</span><br><span class="line">2418</span><br><span class="line">2419</span><br><span class="line">2420</span><br><span class="line">2421</span><br><span class="line">2422</span><br><span class="line">2423</span><br><span class="line">2424</span><br><span class="line">2425</span><br><span class="line">2426</span><br><span class="line">2427</span><br><span class="line">2428</span><br><span class="line">2429</span><br><span class="line">2430</span><br><span class="line">2431</span><br><span class="line">2432</span><br><span class="line">2433</span><br><span class="line">2434</span><br><span class="line">2435</span><br><span class="line">2436</span><br><span class="line">2437</span><br><span class="line">2438</span><br><span class="line">2439</span><br><span class="line">2440</span><br><span class="line">2441</span><br><span class="line">2442</span><br><span class="line">2443</span><br><span class="line">2444</span><br><span class="line">2445</span><br><span class="line">2446</span><br><span class="line">2447</span><br><span class="line">2448</span><br><span class="line">2449</span><br><span class="line">2450</span><br><span class="line">2451</span><br><span class="line">2452</span><br><span class="line">2453</span><br><span class="line">2454</span><br><span class="line">2455</span><br><span class="line">2456</span><br><span class="line">2457</span><br><span class="line">2458</span><br><span class="line">2459</span><br><span class="line">2460</span><br><span class="line">2461</span><br><span class="line">2462</span><br><span class="line">2463</span><br><span class="line">2464</span><br><span class="line">2465</span><br><span class="line">2466</span><br><span class="line">2467</span><br><span class="line">2468</span><br><span class="line">2469</span><br><span class="line">2470</span><br><span class="line">2471</span><br><span class="line">2472</span><br><span class="line">2473</span><br><span class="line">2474</span><br><span class="line">2475</span><br><span class="line">2476</span><br><span class="line">2477</span><br><span class="line">2478</span><br><span class="line">2479</span><br><span class="line">2480</span><br><span class="line">2481</span><br><span class="line">2482</span><br><span class="line">2483</span><br><span class="line">2484</span><br><span class="line">2485</span><br><span class="line">2486</span><br><span class="line">2487</span><br><span class="line">2488</span><br><span class="line">2489</span><br><span class="line">2490</span><br><span class="line">2491</span><br><span class="line">2492</span><br><span class="line">2493</span><br><span class="line">2494</span><br><span class="line">2495</span><br><span class="line">2496</span><br><span class="line">2497</span><br><span class="line">2498</span><br><span class="line">2499</span><br><span class="line">2500</span><br><span class="line">2501</span><br><span class="line">2502</span><br><span class="line">2503</span><br><span class="line">2504</span><br><span class="line">2505</span><br><span class="line">2506</span><br><span class="line">2507</span><br><span class="line">2508</span><br><span class="line">2509</span><br><span class="line">2510</span><br><span class="line">2511</span><br><span class="line">2512</span><br><span class="line">2513</span><br><span class="line">2514</span><br><span class="line">2515</span><br><span class="line">2516</span><br><span class="line">2517</span><br><span class="line">2518</span><br><span class="line">2519</span><br><span class="line">2520</span><br><span class="line">2521</span><br><span class="line">2522</span><br><span class="line">2523</span><br><span class="line">2524</span><br><span class="line">2525</span><br><span class="line">2526</span><br><span class="line">2527</span><br><span class="line">2528</span><br><span class="line">2529</span><br><span class="line">2530</span><br><span class="line">2531</span><br><span class="line">2532</span><br><span class="line">2533</span><br><span class="line">2534</span><br><span class="line">2535</span><br><span class="line">2536</span><br><span class="line">2537</span><br><span class="line">2538</span><br><span class="line">2539</span><br><span class="line">2540</span><br><span class="line">2541</span><br><span class="line">2542</span><br><span class="line">2543</span><br><span class="line">2544</span><br><span class="line">2545</span><br><span class="line">2546</span><br><span class="line">2547</span><br><span class="line">2548</span><br><span class="line">2549</span><br><span class="line">2550</span><br><span class="line">2551</span><br><span class="line">2552</span><br><span class="line">2553</span><br><span class="line">2554</span><br><span class="line">2555</span><br><span class="line">2556</span><br><span class="line">2557</span><br><span class="line">2558</span><br><span class="line">2559</span><br><span class="line">2560</span><br><span class="line">2561</span><br><span class="line">2562</span><br><span class="line">2563</span><br><span class="line">2564</span><br><span class="line">2565</span><br><span class="line">2566</span><br><span class="line">2567</span><br><span class="line">2568</span><br><span class="line">2569</span><br><span class="line">2570</span><br><span class="line">2571</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># ==== 代码2-1.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>a = np.array([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>], dtype = np.int64)<br><span class="hljs-built_in">print</span>(a)<br><br><span class="hljs-comment"># ==== 代码2-2.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>a = np.arange(<span class="hljs-number">5</span>)   <span class="hljs-comment">#只给定stop参数值</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组对象a：\n&quot;</span>, a)  <br>b = np.arange(<span class="hljs-number">2</span>, <span class="hljs-number">5.0</span>)  <span class="hljs-comment">#给定start和stop参数值，生成一个浮点型数组</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组对象b：\n&quot;</span>, b)  <br>c = np.arange(<span class="hljs-number">2</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, dtype = np.int32)  <span class="hljs-comment">#给定start、stop、step和dtype参数值</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组对象c：\n&quot;</span>, c)<br><br><span class="hljs-comment"># ==== 代码2-3.py ====</span><br><br>a = np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, endpoint = <span class="hljs-literal">True</span>)  <span class="hljs-comment">#数组包含截止值3</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组对象a：\n&quot;</span>, a)<br><br><br><span class="hljs-comment"># ==== 代码2-4.py ====</span><br><br>a = np.zeros((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>), dtype = np.int32)   <span class="hljs-comment">#生成2×3形状的全0数组</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组对象a：\n&quot;</span>, a)<br>a = np.array([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>])<br>b = np.zeros_like(b)     <span class="hljs-comment">#生成与数组a形状相同，数据类型也相同的全0数组</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组对象b：\n&quot;</span>, b)<br><br><br><span class="hljs-comment"># ==== 代码2-5.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>a = np.random.rand(<span class="hljs-number">4</span>)     <span class="hljs-comment">#生成有4个元素的一维随机数组</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组对象a：\n&quot;</span>, a)<br>b = np.random.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)  <span class="hljs-comment">#生成形状为2×3，符合正态分布的随机数组</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组的对象b：\n&quot;</span>, b)<br>c = np.random.randint(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, size = (<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))  <br><span class="hljs-comment"># 生成形状为2×3，符合均匀分布的随机整数数组，取值区间为[1,3)</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组对象c：\n&quot;</span>, c)<br><br><br><span class="hljs-comment"># ==== 代码2-6.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>a = np.ones((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>), dtype = np.float32)   <span class="hljs-comment">#生成2x3形状的float32型数组</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组对象a的类型：\n&quot;</span>, a.dtype)<br>a = a.astype(np.int32)    <span class="hljs-comment">#将float32类型的数据转化为整型数组</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组对象a的类型：\n&quot;</span>, a.dtype)<br><br><br><span class="hljs-comment"># ==== 代码2-7.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>a = np.ones((<span class="hljs-number">3</span>, <span class="hljs-number">4</span>), dtype = np.int32)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组a的维数：&quot;</span>, a.ndim)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组a的形状：&quot;</span>, a.shape)<br><br><br><span class="hljs-comment"># ==== 代码2-8.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>a = np.array([[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>], [<span class="hljs-number">8</span>, <span class="hljs-number">9</span>,<span class="hljs-number">10</span>,<span class="hljs-number">11</span>]])<br>b = a[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组a的第0行第1列元素为:\n&quot;</span>, b)<br><br><br><span class="hljs-comment"># ==== 代码2-9.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>a = np.arange(<span class="hljs-number">24</span>).reshape(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>)  <span class="hljs-comment">#生成形状为(2,3,4)的数组</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组对象a:\n&quot;</span>, a)<br>b = a[<span class="hljs-number">0</span>:<span class="hljs-number">1</span>:<span class="hljs-number">1</span>, <span class="hljs-number">0</span>:<span class="hljs-number">2</span>:<span class="hljs-number">1</span>, ...]    <span class="hljs-comment">#第1次切片：在第0和1个维度上进行切片</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\n第1次切片的结果：\n&quot;</span>, b)<br>c = a[:<span class="hljs-number">1</span>, :<span class="hljs-number">2</span>]               <span class="hljs-comment">#第2次切片：更精简的切片方式</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\n第2次切片的结果：\n&quot;</span>, c)<br><br><span class="hljs-comment"># ==== 代码2-10.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>a = np.random.randint(-<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, size = (<span class="hljs-number">3</span>, <span class="hljs-number">4</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组对象a的原始值:\n&quot;</span>, a)<br>index = (a &lt;= <span class="hljs-number">0</span>)    <span class="hljs-comment">#单条件索引</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;单条件索引的布尔数组:\n&quot;</span>, index)<br>a[index] = <span class="hljs-number">0</span>      <span class="hljs-comment"># 将布尔索引取值为True的对应位置上的数据赋值为0 </span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;数组对象a的新值:\n&quot;</span>, a)<br><br><br><span class="hljs-comment"># ==== 代码2-11.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>a = np.random.randint(-<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, size = (<span class="hljs-number">3</span>, <span class="hljs-number">4</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;排序前的数组对象a:\n&quot;</span>, a)<br>b = np.sort(a, axis = <span class="hljs-number">1</span>)   <span class="hljs-comment">#对数组对象a按行排序</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;对数组对象a行排序后的结果:\n&quot;</span>, b)<br><br><br><span class="hljs-comment"># ==== 代码2-12.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-comment">#1. Numpy数组与数值的算术运算的例子</span><br>a = np.array([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>], dtype = np.int32)<br>b1 = a+<span class="hljs-number">2</span>            <span class="hljs-comment">#算术加</span><br>b2 = a*<span class="hljs-number">2</span>            <span class="hljs-comment">#算术乘</span><br>b3 = a**<span class="hljs-number">2</span>           <span class="hljs-comment">#算术乘方</span><br><span class="hljs-comment">#2. Numpy数组与数组的算术运算的例子</span><br>a = np.arange(<span class="hljs-number">24</span>).reshape(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>)         <span class="hljs-comment">#生成形状为(2,3,4)的3维数组</span><br>weight = np.random.random(size = (<span class="hljs-number">3</span>, <span class="hljs-number">4</span>))  <span class="hljs-comment">#生成2维的权重数组 </span><br>b4 = a*weight                        <span class="hljs-comment">#利用广播特性实现数组和数组相乘</span><br><br><br><span class="hljs-comment"># ==== 代码2-13.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-comment">#使用python列表创建Series对象，并指定索引</span><br>s1 = pd.Series([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, np.nan], index = [<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;c&#x27;</span>, <span class="hljs-string">&#x27;d&#x27;</span>]) <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;使用列表创建的Series对象s1：\n&quot;</span>, s1)<br>dic = &#123;<span class="hljs-string">&#x27;张三&#x27;</span>: <span class="hljs-number">97</span>, <span class="hljs-string">&#x27;李四&#x27;</span>: <span class="hljs-number">68</span>, <span class="hljs-string">&#x27;王五&#x27;</span>: <span class="hljs-number">88</span>&#125;<br>s2 = pd.Series(dic)              <span class="hljs-comment">#使用python字典创建Series对象</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;使用字典创建的Series对象s2：\n&quot;</span>, s2)<br>arr = np.arange(<span class="hljs-number">4</span>)               <span class="hljs-comment">#使用Numpy数组创建Series对象</span><br>s3 = pd.Series(arr)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;使用Numpy数组创建的Series对象s3：\n&quot;</span>, s3)<br><br><br><span class="hljs-comment"># ==== 代码2-14.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-comment">#使用二维列表创建</span><br>df1 = pd.DataFrame([[<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-string">&#x27;c&#x27;</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>]], columns = [<span class="hljs-string">&#x27;x&#x27;</span>, <span class="hljs-string">&#x27;y&#x27;</span>, <span class="hljs-string">&#x27;z&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;使用二维列表创建DataFrame对象：\n&quot;</span>, df1)<br><span class="hljs-comment">#使用Numpy二维数组创建</span><br>df2 = pd.DataFrame(np.zeros((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)), columns = [<span class="hljs-string">&#x27;x&#x27;</span>, <span class="hljs-string">&#x27;y&#x27;</span>, <span class="hljs-string">&#x27;z&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;使用Numpy二维数组创建DataFrame对象:\n&quot;</span>, df2)<br><span class="hljs-comment">#使用字典创建</span><br>dic = &#123; <span class="hljs-string">&#x27;语文&#x27;</span>: [<span class="hljs-number">98</span>, <span class="hljs-number">88</span>, <span class="hljs-number">78</span>],<br>      <span class="hljs-string">&#x27;数学&#x27;</span>: [<span class="hljs-number">89</span>, <span class="hljs-number">72</span>, <span class="hljs-number">93</span>],<br>      <span class="hljs-string">&#x27;英语&#x27;</span>: [<span class="hljs-number">84</span>, <span class="hljs-number">85</span>, <span class="hljs-number">77</span>]&#125;<br>df3 = pd.DataFrame(dic,  index = [<span class="hljs-string">&#x27;张三&#x27;</span>, <span class="hljs-string">&#x27;李四&#x27;</span>, <span class="hljs-string">&#x27;王五&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;使用字典创建DataFrame对象:\n&quot;</span>, df3)<br><br><br><span class="hljs-comment"># ==== 代码2-15.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>dic = &#123;<span class="hljs-string">&#x27;语文&#x27;</span>: [<span class="hljs-number">98</span>, <span class="hljs-number">88</span>, <span class="hljs-number">78</span>],<br>       <span class="hljs-string">&#x27;数学&#x27;</span>: [<span class="hljs-number">89</span>, <span class="hljs-number">72</span>, <span class="hljs-number">93</span>],<br>       <span class="hljs-string">&#x27;英语&#x27;</span>: [<span class="hljs-number">84</span>, <span class="hljs-number">85</span>, <span class="hljs-number">77</span>]&#125;<br>df = pd.DataFrame(dic,  index = [<span class="hljs-string">&#x27;张三&#x27;</span>, <span class="hljs-string">&#x27;李四&#x27;</span>, <span class="hljs-string">&#x27;王五&#x27;</span>])<br>df1 = df[<span class="hljs-string">&#x27;语文&#x27;</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;获取DataFrame对象的一列:\n&quot;</span>, df1)<br>df2 = df[[<span class="hljs-string">&#x27;语文&#x27;</span>, <span class="hljs-string">&#x27;英语&#x27;</span>]]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;获取DataFrame对象的多列:\n&quot;</span>, df2)<br>df3 = df.iloc[<span class="hljs-number">1</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;使用iloc函数获得DataFrame对象的一行:\n&quot;</span>, df3)<br>df4 = df.iloc[<span class="hljs-number">1</span>:, <span class="hljs-number">1</span>:]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;使用iloc函数获得DataFrame对象的多行多列（切片）:\n&quot;</span>, df4)<br>df5 = df.loc[<span class="hljs-string">&#x27;王五&#x27;</span>, <span class="hljs-string">&#x27;英语&#x27;</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;使用loc函数获得DataFrame对象中的指定行列索引的一个数据:\n&quot;</span>, df5)<br>df6 = df[df[<span class="hljs-string">&#x27;语文&#x27;</span>] &gt; <span class="hljs-number">85</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;使用条件索引获得满足条件的行:\n&quot;</span>, df6)<br><br><br><span class="hljs-comment"># ==== 代码2-16.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>df1 = pd.DataFrame(np.arange(<span class="hljs-number">6</span>).reshape(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>), index = [<span class="hljs-string">&#x27;x&#x27;</span>, <span class="hljs-string">&#x27;y&#x27;</span>], columns = [<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;c&#x27;</span>])<br>df2 = pd.DataFrame(np.arange(<span class="hljs-number">9</span>).reshape(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), index = [<span class="hljs-string">&#x27;x&#x27;</span>, <span class="hljs-string">&#x27;y&#x27;</span>, <span class="hljs-string">&#x27;z&#x27;</span>], columns = [<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;c2&#x27;</span>])<br>df3 = df1 + df2<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;使用运算符相加的结果:\n&#x27;</span>, df3)<br>df4 = df1.add(df2)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;使用add()函数相加的结果:\n&#x27;</span>, df4)<br><br><br><span class="hljs-comment"># ==== 代码2-17.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>df = pd.DataFrame([[<span class="hljs-number">98.2</span>,<span class="hljs-number">79.3</span>,<span class="hljs-number">28.7</span>], [<span class="hljs-number">78.3</span>,<span class="hljs-number">87.3</span>,<span class="hljs-number">54.7</span>], [<span class="hljs-number">77.7</span>,<span class="hljs-number">65.9</span>,<span class="hljs-number">34.2</span>]],<br>                  index = [<span class="hljs-string">&#x27;2022-3-1&#x27;</span>, <span class="hljs-string">&#x27;2022-3-2&#x27;</span>, <span class="hljs-string">&#x27;2022-3-3&#x27;</span>],<br>                  columns = [<span class="hljs-string">&#x27;商店A&#x27;</span>, <span class="hljs-string">&#x27;商店B&#x27;</span>, <span class="hljs-string">&#x27;商店C&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;三家商店三天的营业额数据为:\n&#x27;</span>, df)<br>s1 = df.<span class="hljs-built_in">sum</span>()  <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;每家商店在三天的总营业额:\n&quot;</span>, s1)<br>s2 = df.mean(axis = <span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;每家商店每天的平均营业额:\n&quot;</span>, s2)<br>s3 = df.<span class="hljs-built_in">sum</span>(axis = <span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;每天三家商店的营业额之和:\n&quot;</span>, s3)<br>s4 = df.idxmax(axis = <span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;每家商店销售额最高的日期是：\n&quot;</span>, s4)<br>s5 = df.cumsum(axis = <span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;每家商店的销售额累计和：\n&quot;</span>, s5)<br>s6 = df.describe()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;销售数据的一般描述性统计情况（按商店）:\n&quot;</span>, s6)<br><br><br><span class="hljs-comment"># ==== 代码2-18.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>s0 = pd.Series([<span class="hljs-number">98</span>, <span class="hljs-number">79</span>, <span class="hljs-number">67</span>], index = [<span class="hljs-string">&#x27;语文&#x27;</span>, <span class="hljs-string">&#x27;数学&#x27;</span>, <span class="hljs-string">&#x27;英语&#x27;</span>])<br>s1 = s0.reindex(index = [<span class="hljs-string">&#x27;数学&#x27;</span>, <span class="hljs-string">&#x27;语文&#x27;</span>, <span class="hljs-string">&#x27;英语&#x27;</span>, <span class="hljs-string">&#x27;计算机&#x27;</span>], fill_value=<span class="hljs-number">60.0</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;行索引重排后的Series对象:\n&quot;</span>, s1)<br>s2 = pd.Series([<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;c&#x27;</span>], index = [<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br>s3 = s2.reindex(np.arange(<span class="hljs-number">5</span>), method = <span class="hljs-string">&#x27;ffill&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;行索引重排后的Series对象:\n&quot;</span>, s3)<br><br><br><span class="hljs-comment"># ==== 代码2-19.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>dic = &#123;<span class="hljs-string">&#x27;语文&#x27;</span>: [<span class="hljs-number">98</span>, <span class="hljs-number">88</span>, <span class="hljs-number">78</span>],<br>      <span class="hljs-string">&#x27;数学&#x27;</span>: [<span class="hljs-number">89</span>, <span class="hljs-number">72</span>, <span class="hljs-number">93</span>],<br>      <span class="hljs-string">&#x27;英语&#x27;</span>: [<span class="hljs-number">84</span>, <span class="hljs-number">85</span>, <span class="hljs-number">77</span>]&#125;<br>df = pd.DataFrame(dic,  index = [<span class="hljs-string">&#x27;张三&#x27;</span>, <span class="hljs-string">&#x27;李四&#x27;</span>, <span class="hljs-string">&#x27;王五&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;DataFrame的原始数据对象:\n&quot;</span>, df)<br>df1 = df.reindex(index = [<span class="hljs-string">&#x27;李四&#x27;</span>, <span class="hljs-string">&#x27;张三&#x27;</span>, <span class="hljs-string">&#x27;王五&#x27;</span>, <span class="hljs-string">&#x27;陈六&#x27;</span>], <br>columns = [<span class="hljs-string">&#x27;数学&#x27;</span>, <span class="hljs-string">&#x27;语文&#x27;</span>, <span class="hljs-string">&#x27;英语&#x27;</span>, <span class="hljs-string">&#x27;计算机&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;对df对象进行行列索引重排后的结果:\n&quot;</span>, df1)<br><br><br><br><br><br><span class="hljs-comment"># ==== 代码2-20.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>dic = &#123;<span class="hljs-string">&#x27;语文&#x27;</span>: [<span class="hljs-number">98</span>, <span class="hljs-number">88</span>, <span class="hljs-number">78</span>],<br>      <span class="hljs-string">&#x27;数学&#x27;</span>: [<span class="hljs-number">89</span>, <span class="hljs-number">72</span>, <span class="hljs-number">93</span>],<br>      <span class="hljs-string">&#x27;英语&#x27;</span>: [<span class="hljs-number">84</span>, <span class="hljs-number">85</span>, <span class="hljs-number">77</span>]&#125;<br>df = pd.DataFrame(dic, index = [<span class="hljs-string">&#x27;张三&#x27;</span>, <span class="hljs-string">&#x27;李四&#x27;</span>, <span class="hljs-string">&#x27;王五&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;DataFrame的原始对象:\n&quot;</span>, df)<br>df1 = df.drop(labels = [<span class="hljs-string">&#x27;李四&#x27;</span>, <span class="hljs-string">&#x27;王五&#x27;</span>], axis = <span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;删除指定行后的DataFrame对象:\n&quot;</span>, df1)<br><br><br><span class="hljs-comment"># ==== 代码2-21.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>dic = &#123;<span class="hljs-string">&#x27;语文&#x27;</span>: [<span class="hljs-number">98</span>, <span class="hljs-number">88</span>, <span class="hljs-number">78</span>],<br>      <span class="hljs-string">&#x27;数学&#x27;</span>: [<span class="hljs-number">89</span>, <span class="hljs-number">72</span>, <span class="hljs-number">93</span>],<br>      <span class="hljs-string">&#x27;英语&#x27;</span>: [<span class="hljs-number">84</span>, <span class="hljs-number">85</span>, <span class="hljs-number">77</span>]&#125;<br>df = pd.DataFrame(dic, index = [<span class="hljs-string">&#x27;张三&#x27;</span>, <span class="hljs-string">&#x27;李四&#x27;</span>, <span class="hljs-string">&#x27;王五&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;DataFrame的原始对象df:\n&quot;</span>, df)<br>df1 = df.sort_index(axis = <span class="hljs-number">1</span>, ascending = <span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;使用sort_index函数对df对象沿水平轴降序排序的结果:\n&quot;</span>, df1)<br>df2 = df.sort_values(by = [<span class="hljs-string">&#x27;语文&#x27;</span>, <span class="hljs-string">&#x27;英语&#x27;</span>], ascending = <span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;使用sort_values函数对df对象多列升序排序的结果:\n&quot;</span>, df2)<br><br><br><span class="hljs-comment"># ==== 代码2-22.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>x = np.arange(-<span class="hljs-number">2</span>*np.pi, <span class="hljs-number">2</span>*np.pi, <span class="hljs-number">0.01</span>)<br>y1, y2 = np.sin(x), np.cos(x)<br>plt.figure(figsize = (<span class="hljs-number">6</span>, <span class="hljs-number">4</span>))<br>plt.plot(x, y1)<br>plt.plot(x, y2)<br>plt.xlim(-<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)      <span class="hljs-comment">#设置X轴和Y轴的显示范围</span><br>plt.ylim(-<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>plt.xlabel(<span class="hljs-string">&quot;x&quot;</span>)     <span class="hljs-comment">#设置X轴和Y轴的显示标签</span><br>plt.ylabel(<span class="hljs-string">u&quot;函数值&quot;</span>, fontproperties = <span class="hljs-string">&#x27;SimHei&#x27;</span>)<br><span class="hljs-comment">#设置Y轴的刻度及显示的刻度值</span><br>plt.yticks([-<span class="hljs-number">1</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-string">u&#x27;最小值&#x27;</span>, <span class="hljs-string">u&#x27;中间值&#x27;</span>, <span class="hljs-string">u&#x27;最大值&#x27;</span>, <span class="hljs-string">&#x27;2&#x27;</span>], fontproperties = <span class="hljs-string">&#x27;SimHei&#x27;</span>)<br><span class="hljs-comment">#设置图例</span><br>plt.legend(prop = &#123;<span class="hljs-string">&#x27;family&#x27;</span>: <span class="hljs-string">&#x27;SimHei&#x27;</span>, <span class="hljs-string">&#x27;size&#x27;</span>:<span class="hljs-number">16</span>&#125;,<br>         loc = <span class="hljs-string">&#x27;lower right&#x27;</span>, labels = [<span class="hljs-string">&#x27;正弦&#x27;</span>, <span class="hljs-string">&#x27;余弦&#x27;</span>])<br><span class="hljs-comment">#设置文本注释</span><br>plt.annotate(s = <span class="hljs-string">&#x27;sin(x)&#x27;</span>, xy = (<span class="hljs-number">0.5</span>, np.sin(<span class="hljs-number">0.5</span>)), xytext = (<span class="hljs-number">0</span>, <span class="hljs-number">1.5</span>), <br>             weight = <span class="hljs-string">&#x27;bold&#x27;</span>, color = <span class="hljs-string">&#x27;black&#x27;</span>,<br>             arrowprops = <span class="hljs-built_in">dict</span>(arrowstyle = <span class="hljs-string">&#x27;-|&gt;&#x27;</span>, connectionstyle = <span class="hljs-string">&#x27;arc3&#x27;</span>, color = <span class="hljs-string">&#x27;red&#x27;</span>),<br>             bbox = <span class="hljs-built_in">dict</span>(boxstyle = <span class="hljs-string">&#x27;round, pad = 0.5&#x27;</span>))<br>plt.text(-<span class="hljs-number">1</span>, np.cos(-<span class="hljs-number">1</span>), <span class="hljs-string">&#x27;cos(x)&#x27;</span>, family = <span class="hljs-string">&#x27;fantasy&#x27;</span>, fontsize = <span class="hljs-number">14</span>, style = <span class="hljs-string">&#x27;italic&#x27;</span>, color = <span class="hljs-string">&#x27;k&#x27;</span>)<br>plt.show()<br><br><br><span class="hljs-comment"># ==== 代码2-23.py ====</span><br><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>x = np.arange(-<span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">1</span>)          <span class="hljs-comment">#获得变量x和y的值</span><br>y = x**<span class="hljs-number">2</span><br><span class="hljs-comment">#绘制折线图</span><br>plt.figure(figsize = (<span class="hljs-number">6</span>, <span class="hljs-number">4</span>), dpi = <span class="hljs-number">200</span>)<br>plt.plot(x, y, color = <span class="hljs-string">&#x27;r&#x27;</span>, linewidth = <span class="hljs-number">1.5</span>, linestyle = <span class="hljs-string">&#x27;--&#x27;</span>, marker = <span class="hljs-string">&#x27;o&#x27;</span>, markersize = <span class="hljs-number">6</span>)<br>plt.xlim(-<span class="hljs-number">11</span>, <span class="hljs-number">11</span>)<br>plt.ylim(-<span class="hljs-number">3</span>, <span class="hljs-number">103</span>)<br>plt.xlabel(<span class="hljs-string">&quot;x&quot;</span>)                    <span class="hljs-comment">#设置X轴和Y轴标签</span><br>plt.ylabel(<span class="hljs-string">&quot;y&quot;</span>)<br>y_ticks = np.arange(<span class="hljs-number">0</span>, <span class="hljs-number">101</span>, <span class="hljs-number">10</span>)      <span class="hljs-comment">#设置Y轴刻度</span><br>plt.yticks(y_ticks)<br>plt.title(<span class="hljs-string">u&#x27;折线图示例&#x27;</span>, fontproperties = <span class="hljs-string">&#x27;SimHei&#x27;</span>)     <span class="hljs-comment">#设置Title</span><br>plt.grid(<span class="hljs-literal">True</span>, which = <span class="hljs-string">&#x27;major&#x27;</span>, linestyle = <span class="hljs-string">&#x27;--&#x27;</span>, linewidth = <span class="hljs-number">1</span>)<br>plt.show()<br><br><br><span class="hljs-comment"># ==== 代码2-24.py ====</span><br><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>n = <span class="hljs-number">400</span>                         <span class="hljs-comment">#数据集的规模</span><br>point = np.random.randn(n, <span class="hljs-number">2</span>)<br><span class="hljs-comment">#绘制散点图</span><br>plt.figure(figsize = (<span class="hljs-number">6</span>, <span class="hljs-number">4</span>), dpi = <span class="hljs-number">200</span>)<br>plt.scatter(point[:, <span class="hljs-number">0</span>], point[:, <span class="hljs-number">1</span>], s = <span class="hljs-number">60</span>, marker = <span class="hljs-string">&#x27;o&#x27;</span>, alpha = <span class="hljs-number">0.6</span>) <br>plt.xlim(-<span class="hljs-number">4</span>, <span class="hljs-number">4</span>)<br>plt.ylim(-<span class="hljs-number">4</span>, <span class="hljs-number">4</span>)<br>plt.xlabel(<span class="hljs-string">&quot;x&quot;</span>)                   <span class="hljs-comment">#设置X轴和Y轴标签</span><br>plt.ylabel(<span class="hljs-string">&quot;y&quot;</span>)<br>plt.title(<span class="hljs-string">u&#x27;散点图示例&#x27;</span>, fontproperties = <span class="hljs-string">&#x27;SimHei&#x27;</span>)  <br>plt.grid(<span class="hljs-literal">True</span>, which = <span class="hljs-string">&#x27;major&#x27;</span>, linestyle = <span class="hljs-string">&#x27;--&#x27;</span>, linewidth = <span class="hljs-number">1</span>)<br>plt.show()<br><br><br><span class="hljs-comment"># ==== 代码2-25.py ====</span><br><br><span class="hljs-keyword">import</span> matplotlib<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-comment">#获得柱状图数据和标签</span><br>names = [<span class="hljs-string">&#x27;张三&#x27;</span>, <span class="hljs-string">&#x27;李四&#x27;</span>, <span class="hljs-string">&#x27;王五&#x27;</span>, <span class="hljs-string">&#x27;陈六&#x27;</span>]<br>scores = [<span class="hljs-number">98</span>, <span class="hljs-number">67</span>, <span class="hljs-number">77</span>, <span class="hljs-number">56</span>]<br><span class="hljs-comment">#绘制柱状图</span><br>plt.figure(figsize = (<span class="hljs-number">6</span>, <span class="hljs-number">4</span>), dpi = <span class="hljs-number">200</span>)<br>matplotlib.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]<br>plt.bar(x = names, height = scores, width = <span class="hljs-number">0.5</span>, color = <span class="hljs-string">&#x27;blue&#x27;</span>,<br>      edgecolor = <span class="hljs-string">&#x27;black&#x27;</span>, label = <span class="hljs-string">&#x27;成绩&#x27;</span>)<br><span class="hljs-keyword">for</span> xx, yy <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(names, scores):           <span class="hljs-comment">#绘制文本注释</span><br>    plt.text(xx, yy+<span class="hljs-number">1</span>, <span class="hljs-built_in">str</span>(yy))<br>plt.xlabel(<span class="hljs-string">&quot;姓名&quot;</span>)<br>plt.ylabel(<span class="hljs-string">&quot;分数&quot;</span>)<br>plt.title(<span class="hljs-string">u&#x27;柱状图示例&#x27;</span>, fontproperties = <span class="hljs-string">&#x27;SimHei&#x27;</span>)<br>plt.grid(<span class="hljs-literal">True</span>, which = <span class="hljs-string">&#x27;major&#x27;</span>, linestyle = <span class="hljs-string">&#x27;--&#x27;</span>, linewidth = <span class="hljs-number">1</span>)<br>plt.show()<br><br><br><span class="hljs-comment"># ==== 代码2-26.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> tree<br><span class="hljs-comment">#步骤1: 加载数据集</span><br>iris = datasets.load_iris()<br>n_samples, n_features = iris.data.shape<br>X = iris.data<br>Y = iris.target<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;步骤1：加载iris数据集&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;iris数据集中有%d个样本，%d个特征。&#x27;</span> % (n_samples, n_features))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;iris的前5个样本为:\n&#x27;</span>, X[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>])<br><span class="hljs-comment">#步骤2: 数据预处理</span><br>min_max_scaler = preprocessing.MinMaxScaler()<br>X_scale = min_max_scaler.fit_transform(X)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;步骤2：数据预处理&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;规范化后iris的前5个样本:\n&#x27;</span>, X_scale[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>])<br><span class="hljs-comment">#步骤3: 使用决策树算法构建分类器模型</span><br>classifier = tree.DecisionTreeClassifier()<br>classifier = classifier.fit(X, Y)   <span class="hljs-comment">#在训练集上训练</span><br>Y_predict = classifier.predict(X)  <span class="hljs-comment">#使用训练好的模型进行预测</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;步骤3：决策树模型构建…&#x27;</span>)<br><span class="hljs-comment">#步骤4:模型的评估</span><br>accuracy = (Y == Y_predict).<span class="hljs-built_in">sum</span>() / Y.shape[<span class="hljs-number">0</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;步骤4：模型评估&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;决策树在训练集上的分类准确度为: %.3f&quot;</span> % (accuracy*<span class="hljs-number">100</span>))<br><br><br><br><br><br><span class="hljs-comment"># ==== 代码3-1.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>iris = load_iris()<br>features = iris.data.T<br>plt.figure(figsize = (<span class="hljs-number">8</span>,<span class="hljs-number">6</span>), dpi=<span class="hljs-number">200</span>)<br>plt.scatter(features[<span class="hljs-number">2</span>], features[<span class="hljs-number">3</span>])       <span class="hljs-comment">#绘制散点图</span><br>plt.xlabel(iris.feature_names[<span class="hljs-number">2</span>])<br>plt.ylabel(iris.feature_names[<span class="hljs-number">3</span>])<br>plt.show()<br><br><br><span class="hljs-comment"># ==== 代码3-2.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>iris = load_iris()<br>features = iris.data.T<br>plt.figure(figsize = (<span class="hljs-number">8</span>,<span class="hljs-number">6</span>), dpi = <span class="hljs-number">200</span>)<br>figure,axes = plt.subplots()                 <span class="hljs-comment">#得到画板、轴</span><br>axes.boxplot(features[<span class="hljs-number">1</span>], patch_artist = <span class="hljs-literal">True</span>)  <span class="hljs-comment">#描点上色</span><br>plt.ylabel(iris.feature_names[<span class="hljs-number">1</span>])<br>plt.show()                               <span class="hljs-comment">#图形展示</span><br><br><br><span class="hljs-comment"># ==== 代码3-3.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>plt.style.use (<span class="hljs-string">&#x27;seaborn-white&#x27;</span>)    <span class="hljs-comment">#使用seaborn包设置white背景</span><br>iris = load_iris()<br>features = iris.data.T<br>data=np.rint(features[<span class="hljs-number">2</span>])        <span class="hljs-comment"># 四舍五入取整np.rint</span><br><span class="hljs-comment"># 也可以用其他取整方法</span><br><span class="hljs-comment"># 截取整数部分 np.trunc</span><br><span class="hljs-comment"># 向上取整 np.ceil</span><br><span class="hljs-comment"># 向下取整np.floor</span><br>plt.hist(data, bins = <span class="hljs-number">14</span>, density = <span class="hljs-literal">True</span>, color = <span class="hljs-string">&#x27;steelblue&#x27;</span>);<br><br><br><span class="hljs-comment"># ==== 代码3-4.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt  <br>iris = load_iris()<br>species = iris.target<br>cate_list = iris.target_names<br>lables, counts = np.unique(species, return_counts = <span class="hljs-literal">True</span>)<br>num_list = <span class="hljs-built_in">list</span>(counts)<br>num_list<br>plt.bar(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(num_list)), num_list)  <br>plt.xlabel(<span class="hljs-string">&quot;species&quot;</span>)              <span class="hljs-comment"># 指定X轴描述信息</span><br>plt.ylabel(<span class="hljs-string">&quot;numbers&quot;</span>)             <span class="hljs-comment"># 指定Y轴描述信息</span><br>plt.ylim(<span class="hljs-number">0</span>,<span class="hljs-number">60</span>)                   <span class="hljs-comment"># 指定Y轴的高度</span><br>idx = np.arange(<span class="hljs-built_in">len</span>(cate_list))<br>plt.xticks(idx,cate_list)<br>plt.show() <br><br><br><span class="hljs-comment"># ==== 代码3-5.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt  <br>iris = load_iris()<br>species = iris.target<br>cate_list = iris.target_names<br>lables, counts = np.unique(species, return_counts = <span class="hljs-literal">True</span>)<br>explode = [<span class="hljs-number">0</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">0</span>]                      <span class="hljs-comment"># 用于突出显示一个品种</span><br>colors = [<span class="hljs-string">&#x27;#7FFFD4&#x27;</span>, <span class="hljs-string">&#x27;#458B74&#x27;</span>, <span class="hljs-string">&#x27;#FFE4C4&#x27;</span>]   <span class="hljs-comment">#自定义颜色</span><br>plt.axes(aspect=<span class="hljs-string">&#x27;equal&#x27;</span>)                 <span class="hljs-comment"># 将X,Y坐标轴标准化处理，设置饼图是正圆</span><br>plt.xlim(<span class="hljs-number">0</span>, <span class="hljs-number">3.8</span>)                           <span class="hljs-comment"># 控制X轴和Y轴的范围</span><br>plt.ylim(<span class="hljs-number">0</span>, <span class="hljs-number">3.8</span>)<br>plt.pie(x = counts,         <span class="hljs-comment"># 绘图数据</span><br>     explode = explode,    <span class="hljs-comment"># 用于突出显示一个品种</span><br>     labels = cate_list,     <span class="hljs-comment"># 添加鸢尾花品种标签</span><br>     colors = colors,       <span class="hljs-comment"># 设置饼图的自定义填充色</span><br>     autopct = <span class="hljs-string">&#x27;%0.1f%%&#x27;</span> )  <span class="hljs-comment"># 设置显示扇形所占的比例  </span><br>plt.show()                 <span class="hljs-comment"># 显示图形</span><br><br><br><span class="hljs-comment"># ==== 代码3-6.py ====</span><br><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br>iris = load_iris()<br>X_train, X_test, y_train, y_test  =  train_test_split(iris[<span class="hljs-string">&#x27;data&#x27;</span>], iris[<span class="hljs-string">&#x27;target&#x27;</span>], random_state=<span class="hljs-number">0</span>)<br>iris_dataframe = pd.DataFrame(X_train, columns = iris.feature_names)<br>grr = pd.plotting.scatter_matrix(iris_dataframe,<br>                        c = y_train,               <span class="hljs-comment"># 设置不同品种鸢尾花的颜色</span><br>                        alpha = <span class="hljs-number">.8</span>,<br>figsize = (<span class="hljs-number">15</span>,<span class="hljs-number">15</span>),<br>                        marker = <span class="hljs-string">&#x27;o&#x27;</span>,<br>                        hist_kwds = &#123;<span class="hljs-string">&#x27;bins&#x27;</span>:<span class="hljs-number">20</span>&#125;)     <span class="hljs-comment"># 频率直方图上的箱体数量</span><br>plt.show()<br><br><br><span class="hljs-comment"># ==== 代码3-7.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris<br>iris = load_iris()<br>features = pd.DataFrame(iris.data, columns = iris.feature_names)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;协方差的结果为:&#x27;</span>)<br><span class="hljs-built_in">print</span>(np.cov(features[<span class="hljs-string">&quot;petal length (cm)&quot;</span>], features[<span class="hljs-string">&quot;petal width (cm)&quot;</span>]))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;pearson相关系数的结果为:&#x27;</span>)<br><span class="hljs-built_in">print</span>(features.iloc[:, [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]].corr(method = <span class="hljs-string">&quot;pearson&quot;</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;spearman相关系数的结果为:&#x27;</span>)<br><span class="hljs-built_in">print</span>(features.iloc[:, [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]].corr(method = <span class="hljs-string">&quot;spearman&quot;</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;kendall相关系数的结果为:&#x27;</span>)<br><span class="hljs-built_in">print</span>(features.iloc[:, [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]].corr(method = <span class="hljs-string">&quot;kendall&quot;</span>)) <br><br><br><span class="hljs-comment"># ==== 代码4-1.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>left = pd.DataFrame(&#123;<span class="hljs-string">&quot;A&quot;</span>:[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>], <span class="hljs-string">&quot;B&quot;</span>:[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>], <span class="hljs-string">&quot;C&quot;</span>:[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]&#125;)<br>right = pd.DataFrame(&#123;<span class="hljs-string">&quot;A&quot;</span>:[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>], <span class="hljs-string">&quot;B&quot;</span>:[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>], <span class="hljs-string">&quot;D&quot;</span>:[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]&#125;)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;左数据框对象: \n&quot;</span>, left)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;右数据框对象: \n&quot;</span>, right)<br>result1 = pd.merge(left, right, how = <span class="hljs-string">&quot;left&quot;</span>, on = [<span class="hljs-string">&quot;A&quot;</span>, <span class="hljs-string">&quot;B&quot;</span>])    <span class="hljs-comment"># 左连接</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;（1）左连接数据结果: \n&quot;</span>, result1)<br>result2 = pd.merge(left, right, how = <span class="hljs-string">&quot;right&quot;</span>, on = [<span class="hljs-string">&quot;A&quot;</span>, <span class="hljs-string">&quot;B&quot;</span>])   <span class="hljs-comment"># 右连接</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;（2）右连接数据结果: \n&quot;</span>, result2)<br>result3 = pd.merge(left, right, how = <span class="hljs-string">&quot;inner&quot;</span>, on = [<span class="hljs-string">&quot;A&quot;</span>, <span class="hljs-string">&quot;B&quot;</span>])   <span class="hljs-comment"># 内连接</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;（3）内连接数据结果: \n&quot;</span>, result3)<br>result4 = pd.merge(left, right, how = <span class="hljs-string">&quot;outer&quot;</span>, on = [<span class="hljs-string">&quot;A&quot;</span>, <span class="hljs-string">&quot;B&quot;</span>])   <span class="hljs-comment"># 外连接</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;（4）外连接数据结果: \n&quot;</span>, result4)<br><br><span class="hljs-comment"># ==== 代码4-2.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>scores = &#123;<span class="hljs-string">&#x27;姓名&#x27;</span>: [<span class="hljs-string">&#x27;张三&#x27;</span>, <span class="hljs-string">&#x27;李四&#x27;</span>, <span class="hljs-string">&#x27;王五&#x27;</span>, <span class="hljs-string">&#x27;张三&#x27;</span>],<br>        <span class="hljs-string">&#x27;语文&#x27;</span>: [ <span class="hljs-number">84</span>, <span class="hljs-number">92</span>, <span class="hljs-number">87</span>, <span class="hljs-number">84</span>],<br>    <span class="hljs-string">&#x27;数学&#x27;</span>: [ <span class="hljs-number">89</span>, <span class="hljs-number">90</span>, <span class="hljs-number">95</span>, <span class="hljs-number">89</span>],<br>        <span class="hljs-string">&#x27;英语&#x27;</span>: [ <span class="hljs-number">90</span>, <span class="hljs-number">81</span>, <span class="hljs-number">75</span>, <span class="hljs-number">92</span>],<br>    <span class="hljs-string">&#x27;计算机&#x27;</span>: [ <span class="hljs-number">85</span>, <span class="hljs-number">92</span>, <span class="hljs-number">90</span>, <span class="hljs-number">85</span>]&#125;<br>df = pd.DataFrame(scores)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;检验重复的记录：\n&quot;</span>, df.duplicated(subset = [<span class="hljs-string">&#x27;姓名&#x27;</span>]))<br>df_drop = df.drop_duplicates(subset = [<span class="hljs-string">&#x27;姓名&#x27;</span>], keep = <span class="hljs-string">&#x27;first&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;去重的数据为：\n&quot;</span>, df_drop )<br><br><br><span class="hljs-comment"># ==== 代码4-3.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>scores = &#123;<span class="hljs-string">&#x27;姓名&#x27;</span>: [<span class="hljs-string">&#x27;张三&#x27;</span>, <span class="hljs-string">&#x27;李四&#x27;</span>, <span class="hljs-string">&#x27;王五&#x27;</span>, <span class="hljs-string">&#x27;张三&#x27;</span>],<br>    <span class="hljs-string">&#x27;语文&#x27;</span>: [ <span class="hljs-number">84</span>, <span class="hljs-number">92</span>, <span class="hljs-number">87</span>, <span class="hljs-number">84</span>],<br>    <span class="hljs-string">&#x27;数学&#x27;</span>: [ <span class="hljs-number">89</span>, <span class="hljs-number">90</span>, <span class="hljs-number">95</span>, <span class="hljs-number">89</span>],<br>        <span class="hljs-string">&#x27;英语&#x27;</span>: [ <span class="hljs-number">90</span>, <span class="hljs-number">81</span>, <span class="hljs-number">75</span>, <span class="hljs-number">92</span>],<br>    <span class="hljs-string">&#x27;计算机&#x27;</span>: [ <span class="hljs-number">85</span>, <span class="hljs-number">92</span>, <span class="hljs-number">90</span>, <span class="hljs-number">85</span>],<br>    <span class="hljs-string">&#x27;计算机基础&#x27;</span>: [ <span class="hljs-number">85</span>, <span class="hljs-number">92</span>, <span class="hljs-number">90</span>, <span class="hljs-number">85</span>]&#125;<br>df = pd.DataFrame(scores)<br><span class="hljs-built_in">print</span>(df.corr(method = <span class="hljs-string">&#x27;pearson&#x27;</span>))<br><br><br><span class="hljs-comment"># ==== 代码4-4.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>scores = &#123;<span class="hljs-string">&#x27;姓名&#x27;</span>: [<span class="hljs-string">&#x27;张三&#x27;</span>, <span class="hljs-string">&#x27;李四&#x27;</span>, <span class="hljs-string">&#x27;王五&#x27;</span>, <span class="hljs-string">&#x27;刘一&#x27;</span>],<br>        <span class="hljs-string">&#x27;语文&#x27;</span>: [ <span class="hljs-number">84</span>, <span class="hljs-number">92</span>, <span class="hljs-number">87</span>, <span class="hljs-number">84</span>],<br>    <span class="hljs-string">&#x27;数学&#x27;</span>: [ <span class="hljs-number">89</span>, np.NaN, <span class="hljs-number">95</span>, <span class="hljs-number">89</span>],<br>        <span class="hljs-string">&#x27;英语&#x27;</span>: [ <span class="hljs-number">90</span>, <span class="hljs-number">81</span>, np.NaN, <span class="hljs-number">92</span>],<br>    <span class="hljs-string">&#x27;计算机&#x27;</span>: [ <span class="hljs-number">85</span>, <span class="hljs-number">92</span>, <span class="hljs-number">90</span>, <span class="hljs-number">85</span>]&#125;<br>df = pd.DataFrame(scores)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;成绩数据对象的特征缺失值情况:&#x27;</span>)<br><span class="hljs-built_in">print</span>(df.isnull().<span class="hljs-built_in">sum</span>())          <span class="hljs-comment">#判断每列是否有缺失值</span><br><br><br><span class="hljs-comment"># ==== 代码4-5.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>scores = &#123;<span class="hljs-string">&#x27;姓名&#x27;</span>: [<span class="hljs-string">&#x27;张三&#x27;</span>, <span class="hljs-string">&#x27;李四&#x27;</span>, <span class="hljs-string">&#x27;王五&#x27;</span>, <span class="hljs-string">&#x27;刘一&#x27;</span>],<br>        <span class="hljs-string">&#x27;语文&#x27;</span>: [ <span class="hljs-number">84</span>, <span class="hljs-number">92</span>, <span class="hljs-number">87</span>, <span class="hljs-number">84</span>],<br>        <span class="hljs-string">&#x27;数学&#x27;</span>: [ <span class="hljs-number">89</span>, pd.NA, <span class="hljs-number">95</span>, <span class="hljs-number">89</span>],<br>        <span class="hljs-string">&#x27;英语&#x27;</span>: [ <span class="hljs-number">90</span>, <span class="hljs-number">81</span>, pd.NA, <span class="hljs-number">92</span>],<br>    <span class="hljs-string">&#x27;计算机&#x27;</span>: [ <span class="hljs-number">85</span>, <span class="hljs-number">92</span>, <span class="hljs-number">90</span>, <span class="hljs-number">85</span>]&#125;<br>df = pd.DataFrame(scores)<br>df.dropna(axis = <span class="hljs-number">0</span>, how = <span class="hljs-string">&#x27;any&#x27;</span>, inplace = <span class="hljs-literal">True</span>)       <span class="hljs-comment"># 删除所有包含缺失值的行</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;删除包含缺失值记录后的数据为：\n&#x27;</span>, df)<br><br><br><span class="hljs-comment"># ==== 代码4-6.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-comment">#生成包含缺失值的数据</span><br>scores = &#123;<span class="hljs-string">&#x27;姓名&#x27;</span>: [<span class="hljs-string">&#x27;张三&#x27;</span>, <span class="hljs-string">&#x27;李四&#x27;</span>, <span class="hljs-string">&#x27;王五&#x27;</span>, <span class="hljs-string">&#x27;刘一&#x27;</span>],<br>    <span class="hljs-string">&#x27;语文&#x27;</span>: [ <span class="hljs-number">84</span>, <span class="hljs-number">92</span>, <span class="hljs-number">87</span>, <span class="hljs-number">84</span>],<br>        <span class="hljs-string">&#x27;数学&#x27;</span>: [ <span class="hljs-number">89</span>, pd.NA, <span class="hljs-number">95</span>, <span class="hljs-number">89</span>],<br>    <span class="hljs-string">&#x27;英语&#x27;</span>: [ <span class="hljs-number">90</span>, <span class="hljs-number">81</span>, pd.NA, <span class="hljs-number">92</span>],<br>        <span class="hljs-string">&#x27;计算机&#x27;</span>: [ <span class="hljs-number">85</span>, <span class="hljs-number">92</span>, <span class="hljs-number">90</span>, <span class="hljs-number">85</span>]&#125;<br>df = pd.DataFrame(scores)<br><span class="hljs-comment"># 1.均值替换</span><br>df_mean = df[<span class="hljs-string">&#x27;数学&#x27;</span>].fillna(value = df[<span class="hljs-string">&#x27;数学&#x27;</span>].mean(), inplace = <span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;使用均值替换: \n&#x27;</span>, df_mean)<br><span class="hljs-comment"># 2.中位数替换</span><br>df_median = df[<span class="hljs-string">&#x27;数学&#x27;</span>].fillna(df[<span class="hljs-string">&#x27;数学&#x27;</span>].median(), inplace = <span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;使用中位数替换: \n&#x27;</span>, df_median)<br><span class="hljs-comment"># 3.使用固定值0替换</span><br>df_zero = df[<span class="hljs-string">&#x27;数学&#x27;</span>].fillna(value = <span class="hljs-number">0</span>, inplace = <span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;使用0替换: \n&#x27;</span>,df_zero)<br><span class="hljs-comment"># 4.使用缺失值前一个值进行填充(按照相应index前后填充)</span><br>df_ffill = df[<span class="hljs-string">&#x27;数学&#x27;</span>].fillna(method = <span class="hljs-string">&#x27;ffill&#x27;</span>, inplace = <span class="hljs-literal">False</span>, axis = <span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;使用缺失值前一个值替换: \n&#x27;</span>, df_ffill)<br><span class="hljs-comment"># 5.使用缺失值后一个值进行填充(按照相应columns前后填充)</span><br>df_bfill = df[<span class="hljs-string">&#x27;数学&#x27;</span>].fillna(method = <span class="hljs-string">&#x27;bfill&#x27;</span>, inplace = <span class="hljs-literal">False</span>, axis = <span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;使用缺失值后一个值替换: \n&#x27;</span>, df_bfill)<br><span class="hljs-comment"># 6.使用线性插值法进行填充</span><br>df[<span class="hljs-string">&#x27;数学&#x27;</span>] = pd.to_numeric(df[<span class="hljs-string">&#x27;数学&#x27;</span>], errors = <span class="hljs-string">&#x27;coerce&#x27;</span>)<br>df_linear = df[<span class="hljs-string">&#x27;数学&#x27;</span>].interpolate(method = <span class="hljs-string">&#x27;linear&#x27;</span>, inplace = <span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;使用线性插值法进行填充: \n&#x27;</span>, df_linear)<br><span class="hljs-comment"># 7.使用多项式插值插值法进行填充</span><br>df_poly = df[<span class="hljs-string">&#x27;数学&#x27;</span>].interpolate(method = <span class="hljs-string">&#x27;polynomial&#x27;</span>, order = <span class="hljs-number">2</span>, inplace = <span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;使用多项式插值插值法进行填充: \n&#x27;</span>, df_poly)<br><span class="hljs-comment"># 8.使用样条插值法进行填充</span><br>df_spline = df[<span class="hljs-string">&#x27;数学&#x27;</span>].interpolate(method = <span class="hljs-string">&#x27;spline&#x27;</span>, order = <span class="hljs-number">2</span>, inplace = <span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;(6)使用样条插值法进行填充: \n&#x27;</span>, df_spline) <br><br><br><span class="hljs-comment"># ==== 代码4-7.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-comment">#生成原始数据</span><br>scores = &#123;<span class="hljs-string">&#x27;姓名&#x27;</span>: [<span class="hljs-string">&#x27;S1&#x27;</span>, <span class="hljs-string">&#x27;S2&#x27;</span>, <span class="hljs-string">&#x27;S3&#x27;</span>, <span class="hljs-string">&#x27;S4&#x27;</span>, <span class="hljs-string">&#x27;S5&#x27;</span>, <span class="hljs-string">&#x27;S6&#x27;</span>], <span class="hljs-string">&#x27;英语&#x27;</span>: [<span class="hljs-number">90</span>, <span class="hljs-number">81</span>, <span class="hljs-number">110</span>, <span class="hljs-number">92</span>, <span class="hljs-number">83</span>, <span class="hljs-number">85</span>]&#125;<br>df = pd.DataFrame(scores)<br><span class="hljs-comment"># 绘制箱线图</span><br>plt.figure(figsize = (<span class="hljs-number">8</span>, <span class="hljs-number">6</span>), dpi = <span class="hljs-number">200</span>)<br>axes = plt.boxplot(df[<span class="hljs-string">&#x27;英语&#x27;</span>], notch = <span class="hljs-literal">True</span>, patch_artist = <span class="hljs-literal">True</span>)        <span class="hljs-comment">#箱线图</span><br>outlier = axes[<span class="hljs-string">&#x27;fliers&#x27;</span>][<span class="hljs-number">0</span>].get_ydata()                          <span class="hljs-comment">#获取异常值</span><br>plt.show()                                               <span class="hljs-comment">#图形展示</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;异常值为：\n&#x27;</span>, outlier)<br><br><br><span class="hljs-comment"># ==== 代码4-8.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> MinMaxScaler<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>iris = load_iris().data<br><span class="hljs-comment">#使用离差标准化对数据进行预处理</span><br>m_scaler = MinMaxScaler()              <span class="hljs-comment">#创建一个min-max规范化对象</span><br>iris_scale = m_scaler.fit_transform(iris)<br>iris_scale= pd.DataFrame(data = iris_scale,<br> columns = [<span class="hljs-string">&quot;petal_len&quot;</span>, <span class="hljs-string">&quot;petal_wid&quot;</span>, <span class="hljs-string">&quot;sepal_len&quot;</span>, <span class="hljs-string">&quot;sepal_wid&quot;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;规范化后的前5条iris数据:\n&quot;</span>,  iris_scale[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>] )<br><br><br><span class="hljs-comment"># ==== 代码4-9.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler <br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>iris = load_iris().data<br><span class="hljs-comment">#使用标准差规范化对数据进行处理 </span><br>iris_scale = StandardScaler()                   <span class="hljs-comment">#创建一个标准差规范化对象</span><br>iris_scale = iris_scale.fit_transform(iris)<br>iris_scale= pd.DataFrame(data = iris_scale,<br> columns = [<span class="hljs-string">&quot;petal_len&quot;</span>, <span class="hljs-string">&quot;petal_wid&quot;</span>, <span class="hljs-string">&quot;sepal_len&quot;</span>, <span class="hljs-string">&quot;sepal_wid&quot;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;规范化后的前5条iris数据:\n&quot;</span>,  iris_scale[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>] ) <br><br><span class="hljs-comment"># ==== 代码4-10.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>x = np.array([[ <span class="hljs-number">0.</span>, -<span class="hljs-number">3.</span>, <span class="hljs-number">1.</span>],              <span class="hljs-comment"># 初始化数据</span><br>           [ <span class="hljs-number">3.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],<br>           [ <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, -<span class="hljs-number">1.</span>]])<br>j = np.ceil(np.log10(np.<span class="hljs-built_in">max</span>(<span class="hljs-built_in">abs</span>(x))))     <span class="hljs-comment"># 获取小数点移动最大位数</span><br>sc_C = x/(<span class="hljs-number">10</span>**j)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;标准化后的数据为: \n&#x27;</span>, sc_C)<br><br><br><span class="hljs-comment"># ==== 代码4-11.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> Binarizer<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>price= np.array([<span class="hljs-number">1000</span>, <span class="hljs-number">2530</span>, <span class="hljs-number">3500</span>, <span class="hljs-number">6000</span>, <span class="hljs-number">200</span>, <span class="hljs-number">8200</span>])<br>b = Binarizer(threshold = <span class="hljs-number">3000</span>)            <span class="hljs-comment">#创建二值化对象，阙值为3000</span><br>b_price = b.fit_transform(price.reshape(<span class="hljs-number">1</span>,-<span class="hljs-number">1</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;二值化后的价格:\n&quot;</span>, b_price)<br><br><br><span class="hljs-comment"># ==== 代码4-12.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-comment">#生成销量数据</span><br>sale_df = pd.DataFrame(&#123;<span class="hljs-string">&#x27;sale&#x27;</span>: [<span class="hljs-number">400</span>, <span class="hljs-number">50</span>, <span class="hljs-number">100</span>, <span class="hljs-number">450</span>, <span class="hljs-number">500</span>, <span class="hljs-number">320</span>, <span class="hljs-number">160</span>, <span class="hljs-number">280</span>, <br>                          <span class="hljs-number">320</span>, <span class="hljs-number">380</span>, <span class="hljs-number">200</span>, <span class="hljs-number">460</span>]&#125;)<br><span class="hljs-comment"># 等宽离散化</span><br>sale_df[<span class="hljs-string">&#x27;sale_fixedwid&#x27;</span>] = pd.cut(sale_df[<span class="hljs-string">&quot;sale&quot;</span>], bins = <span class="hljs-number">3</span>)<br><span class="hljs-comment"># 等频离散化</span><br>sale_df[<span class="hljs-string">&#x27;sale_fixedfreq&#x27;</span>] = pd.qcut(sale_df[<span class="hljs-string">&quot;sale&quot;</span>], q = <span class="hljs-number">4</span>)<br><span class="hljs-built_in">print</span>(sale_df) <br><br><br><span class="hljs-comment"># ==== 代码4-13.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> OneHotEncoder,LabelEncoder<br><span class="hljs-comment">#原始数据</span><br>weather_df = pd.DataFrame(&#123;<span class="hljs-string">&#x27;天气&#x27;</span>: [<span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;雨天&#x27;</span>, <span class="hljs-string">&#x27;阴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>], <span class="hljs-string">&#x27;销量&#x27;</span>: [<span class="hljs-number">400</span>, <span class="hljs-number">50</span>, <span class="hljs-number">100</span>, <span class="hljs-number">450</span>]&#125;)<br><span class="hljs-comment">#独热编码</span><br>oneHot_weather = OneHotEncoder().fit_transform(weather_df[[<span class="hljs-string">&quot;天气&quot;</span>]])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;独热编码的结果为：&#x27;</span>)<br><span class="hljs-built_in">print</span>(oneHot_weather)<br><span class="hljs-comment">#哑变量编码</span><br>dummy_weather = pd.get_dummies(weather_df[[<span class="hljs-string">&quot;天气&quot;</span>]], drop_first = <span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;哑变量的结果为：&#x27;</span>)<br><span class="hljs-built_in">print</span>(dummy_weather)<br><span class="hljs-comment">#标签编码</span><br>label_weather = LabelEncoder().fit_transform(weather_df[[<span class="hljs-string">&quot;天气&quot;</span>]])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;标签编码的结果为：&#x27;</span>)<br><span class="hljs-built_in">print</span>(label_weather)<br><br><br><span class="hljs-comment"># ==== 代码4-14.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>sale_df = pd.DataFrame(<br>&#123;<span class="hljs-string">&#x27;weather&#x27;</span>: [<span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;雨天&#x27;</span>, <span class="hljs-string">&#x27;阴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;阴天&#x27;</span>, <span class="hljs-string">&#x27;雨天&#x27;</span>, <span class="hljs-string">&#x27;阴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>,<span class="hljs-string">&#x27;阴天&#x27;</span>, <span class="hljs-string">&#x27;雨天&#x27;</span>, <span class="hljs-string">&#x27;阴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;阴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;阴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>, <span class="hljs-string">&#x27;晴天&#x27;</span>],<br><span class="hljs-string">&#x27;sale&#x27;</span>:[<span class="hljs-number">400</span>, <span class="hljs-number">50</span>, <span class="hljs-number">100</span>, <span class="hljs-number">450</span>, <span class="hljs-number">620</span>, <span class="hljs-number">325</span>, <span class="hljs-number">170</span>, <span class="hljs-number">280</span>, <span class="hljs-number">710</span>, <span class="hljs-number">330</span>, <span class="hljs-number">500</span>, <span class="hljs-number">320</span>, <span class="hljs-number">160</span>, <span class="hljs-number">280</span>, <span class="hljs-number">175</span>, <span class="hljs-number">240</span>, <span class="hljs-number">605</span>, <span class="hljs-number">270</span>, <span class="hljs-number">250</span>, <span class="hljs-number">510</span>, <span class="hljs-number">320</span>, <span class="hljs-number">380</span>, <span class="hljs-number">200</span>, <span class="hljs-number">460</span>, <span class="hljs-number">380</span>, <span class="hljs-number">420</span>, <span class="hljs-number">560</span>, <span class="hljs-number">80</span>, <span class="hljs-number">240</span>, <span class="hljs-number">630</span>]&#125;<br>)<br><span class="hljs-comment">#1.简单随机抽样</span><br>random_sample = sale_df.sample(<span class="hljs-number">10</span>, random_state = <span class="hljs-number">124</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;简单随机抽样方法的结果：\n&#x27;</span>, random_sample)<br><span class="hljs-comment">#2.分层抽样</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> StratifiedShuffleSplit<br>split = StratifiedShuffleSplit(n_splits = <span class="hljs-number">1</span>, train_size = <span class="hljs-number">10</span>, random_state = <span class="hljs-number">124</span>)<br><span class="hljs-keyword">for</span> train_index, test_index <span class="hljs-keyword">in</span> split.split(sale_df, sale_df[<span class="hljs-string">&#x27;weather&#x27;</span>]):<br>    strat_sample_set = sale_df.loc[train_index]<br>    strat_test_set = sale_df.loc[test_index] <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;分层抽样方法的结果：\n&#x27;</span>, strat_sample_set)<br><br><br><span class="hljs-comment"># ==== 代码4-15.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris<br><span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> PCA<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">from</span> sklearn.discriminant_analysis <span class="hljs-keyword">import</span> LinearDiscriminantAnalysis<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br>iris = load_iris()<br>X = iris.data<br>y = iris.target<br>sc = StandardScaler()<br>X_scaled = sc.fit_transform(X)<br>pca = PCA(n_components = <span class="hljs-number">2</span>)<br>X_pca = pca.fit_transform(X_scaled)<br>lda = LinearDiscriminantAnalysis(n_components = <span class="hljs-number">2</span>, solver = <span class="hljs-string">&#x27;svd&#x27;</span>)<br>X_lda = lda.fit_transform(X, y)<br>fig, ax = plt.subplots(nrows = <span class="hljs-number">1</span>, ncols = <span class="hljs-number">2</span>, figsize = (<span class="hljs-number">13.5</span> ,<span class="hljs-number">4</span>))<br>sns.scatterplot(X_pca[:, <span class="hljs-number">0</span>], X_pca[:, <span class="hljs-number">1</span>], hue = y, palette = <span class="hljs-string">&#x27;Set1&#x27;</span>, ax = ax[<span class="hljs-number">0</span>])<br>sns.scatterplot(X_lda[:, <span class="hljs-number">0</span>], X_lda[:, <span class="hljs-number">1</span>], hue = y, palette = <span class="hljs-string">&#x27;Set1&#x27;</span>, ax = ax[<span class="hljs-number">1</span>])<br>ax[<span class="hljs-number">0</span>].set_title(<span class="hljs-string">&quot;PCA of IRIS dataset&quot;</span>, fontsize = <span class="hljs-number">15</span>, pad = <span class="hljs-number">15</span>)<br>ax[<span class="hljs-number">1</span>].set_title(<span class="hljs-string">&quot;LDA of IRIS dataset&quot;</span>, fontsize = <span class="hljs-number">15</span>, pad = <span class="hljs-number">15</span>)<br>ax[<span class="hljs-number">0</span>].set_xlabel(<span class="hljs-string">&quot;PC1&quot;</span>, fontsize = <span class="hljs-number">12</span>)<br>ax[<span class="hljs-number">0</span>].set_ylabel(<span class="hljs-string">&quot;PC2&quot;</span>, fontsize = <span class="hljs-number">12</span>)<br>ax[<span class="hljs-number">1</span>].set_xlabel(<span class="hljs-string">&quot;LD1&quot;</span>, fontsize = <span class="hljs-number">12</span>)<br>ax[<span class="hljs-number">1</span>].set_ylabel(<span class="hljs-string">&quot;LD2&quot;</span>, fontsize = <span class="hljs-number">12</span>)<br>plt.savefig(<span class="hljs-string">&#x27;PCA vs LDA.png&#x27;</span>, dpi = <span class="hljs-number">80</span>)<br><br><br><span class="hljs-comment"># ==== 代码5-1.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> VarianceThreshold<br><span class="hljs-comment">#模拟数据集</span><br>X = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">9</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">1</span>], [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">5</span>,<span class="hljs-number">2</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">7</span>,<span class="hljs-number">4</span>,<span class="hljs-number">7</span>]]) <br>selector = VarianceThreshold(<span class="hljs-number">1.0</span>)         <span class="hljs-comment">#阈值设置为1</span><br>selector.fit(X)                         <span class="hljs-comment">#训练</span><br>transformed_X = selector.transform(X)     <span class="hljs-comment"># 特征选择</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;特征的方差:&quot;</span>, selector.variances_)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;特征选择后的数据集&quot;</span>, transformed_X)<br><br><br><span class="hljs-comment"># ==== 代码5-2.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> chi2<br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectKBest<br><span class="hljs-comment"># 模拟数据集</span><br>X = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">7</span>,<span class="hljs-number">9</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">1</span>], [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">5</span>,<span class="hljs-number">2</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">7</span>,<span class="hljs-number">2</span>,<span class="hljs-number">7</span>]]) <br>Y = np.array([<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>])<br>selector = SelectKBest(chi2, k = <span class="hljs-number">2</span>) <br>selector.fit(X, Y)                      <span class="hljs-comment"># 训练</span><br>transformed_X = selector.transform(X)    <span class="hljs-comment"># 特征选择</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;特征的卡方统计量值：&quot;</span>, selector.scores_)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;特征选择后的数据集：&quot;</span>, transformed_X)<br><br><br><span class="hljs-comment"># ==== 代码5-3.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> mutual_info_classif<br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectKBest<br>X = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">9</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">1</span>], [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">5</span>,<span class="hljs-number">2</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">7</span>,<span class="hljs-number">4</span>,<span class="hljs-number">7</span>]]) <br>Y = np.array([<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>])<br>selector = SelectKBest(mutual_info_classif, k = <span class="hljs-number">2</span>) <br>selector.fit(X, Y)                            <span class="hljs-comment"># 训练</span><br>transformed_X = selector.transform(X)          <span class="hljs-comment"># 特征选择</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;特征和目标变量的互信息值：&quot;</span>, selector.scores_)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;特征选择后的数据集：&quot;</span>, transformed_X)<br><br><br><span class="hljs-comment"># ==== 代码5-4.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> f_classif<br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectKBest<br>X = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">9</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">1</span>], [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">5</span>,<span class="hljs-number">2</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">7</span>,<span class="hljs-number">4</span>,<span class="hljs-number">7</span>]])<br>Y = np.array([<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>])<br>selector = SelectKBest(f_classif, k = <span class="hljs-number">2</span>)<br>selector.fit(X, Y)                        <span class="hljs-comment"># 训练</span><br>transformed_X = selector.transform(X)      <span class="hljs-comment"># 特征选择</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;特征F-统计量值：&quot;</span>, selector.scores_)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;特征选择后的数据集：&quot;</span>, transformed_X)<br><br><br><span class="hljs-comment"># ==== 代码5-5.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> tarfile<br><span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> pearsonr<br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectKBest<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">with</span> tarfile.<span class="hljs-built_in">open</span>(mode=<span class="hljs-string">&quot;r:gz&quot;</span>, name=<span class="hljs-string">&#x27;cal_housing.tgz&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    cal_housing= np.loadtxt(f.extractfile(<span class="hljs-string">&#x27;CaliforniaHousing/cal_housing.data&#x27;</span>),delimiter=<span class="hljs-string">&#x27;,&#x27;</span>)<br>cols=[<span class="hljs-string">&#x27;longitude&#x27;</span>, <span class="hljs-string">&#x27;latitude&#x27;</span>, <span class="hljs-string">&#x27;housingMedianAge&#x27;</span>, <span class="hljs-string">&#x27;totalRooms&#x27;</span>, <span class="hljs-string">&#x27;totalBedrooms&#x27;</span>, <span class="hljs-string">&#x27;population&#x27;</span>, <span class="hljs-string">&#x27;households&#x27;</span>, <span class="hljs-string">&#x27;medianIncome&#x27;</span>] <br>X=cal_housing[:,<span class="hljs-number">0</span>:<span class="hljs-number">8</span>]<br>Y=cal_housing[: ,<span class="hljs-number">8</span>]<br><span class="hljs-comment">#封装的皮尔森相关系数计算函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ud_pearsonr</span>(<span class="hljs-params">X, y</span>):  <br>    result = np.array([pearsonr(x, y) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X.T])     <span class="hljs-comment">#返回皮尔森相关系数, p值</span><br>    <span class="hljs-keyword">return</span> np.absolute(result[:, <span class="hljs-number">0</span>]), result[:, <span class="hljs-number">1</span>] <br>selector = SelectKBest(ud_pearsonr, k = <span class="hljs-number">4</span>) <br>selector.fit(X,Y)                                 <span class="hljs-comment"># 训练</span><br>transformed_X = selector.transform(X) <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;特征的皮尔森相关系数值:\n&quot;</span>, pd.Series(selector.scores_, index=cols))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;选择的特征为：\n&quot;</span>, np.array(cols)[selector.get_support(indices=<span class="hljs-literal">True</span>)])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;特征选择后的数据集：\n&quot;</span>, transformed_X)<br><br><br><span class="hljs-comment"># ==== 代码5-6.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> mrmr <span class="hljs-keyword">import</span> mrmr_classif<br>X = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">9</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">1</span>], [<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">5</span>,<span class="hljs-number">2</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">7</span>,<span class="hljs-number">4</span>,<span class="hljs-number">7</span>]]) <br>Y = np.array([<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>])<br>X = pd.DataFrame(X, columns=[<span class="hljs-string">&#x27;0&#x27;</span>, <span class="hljs-string">&#x27;1&#x27;</span>, <span class="hljs-string">&#x27;2&#x27;</span>, <span class="hljs-string">&#x27;3&#x27;</span>])<br>F = mrmr_classif(X = X, y = Y, K = <span class="hljs-number">2</span>)       <span class="hljs-comment">#特征选择                            </span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;选择的特征索引为：&quot;</span>, F)<br><br><br><span class="hljs-comment"># ==== 代码5-7.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_wine               <span class="hljs-comment"># 导入红酒数据集</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split <br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> VarianceThreshold, chi2, SelectKBest<br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> mutual_info_classif,f_classif<br><span class="hljs-keyword">from</span> mrmr <span class="hljs-keyword">import</span> mrmr_classif<br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier <span class="hljs-keyword">as</span> DTC<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-comment"># 1. 获得数据</span><br>wine = load_wine()<br>X, Y = wine.data, wine.target<br>num_class = <span class="hljs-number">5</span>                            <span class="hljs-comment">#待选取的特征子集的大小</span><br><span class="hljs-comment"># 2. 特征选择过程</span><br>vt_sel = VarianceThreshold(<span class="hljs-number">1.0</span>)            <span class="hljs-comment">#方差阈值法（阈值为1）</span><br>vt_sel.fit(X) <br>vt_trans_X = vt_sel.transform(X) <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;方差阈值法选择的特征：&quot;</span>, vt_sel.get_support(<span class="hljs-literal">True</span>))<br>chi_sel = SelectKBest(chi2, k=num_class)    <span class="hljs-comment"># 卡方统计量法</span><br>chi_sel.fit(X, Y)  <br>chi_trans_X = chi_sel.transform(X)  <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;卡方统计量方法选择的特征：&quot;</span>, chi_sel.get_support(<span class="hljs-literal">True</span>))<br>mi_sel = SelectKBest(mutual_info_classif, k = num_class)       <span class="hljs-comment"># 互信息法</span><br>mi_sel.fit(X, Y)  <br>mi_trans_X = mi_sel.transform(X)  <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;互信息法选择的特征：&quot;</span>, mi_sel.get_support(<span class="hljs-literal">True</span>))<br>F_sel = SelectKBest(f_classif, k =  num_class)                <span class="hljs-comment"># F统计量法</span><br>F_sel.fit(X, Y)  <br>F_trans_X = F_sel.transform(X) <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;F统计量法选择的特征：&quot;</span>, F_sel.get_support(<span class="hljs-literal">True</span>))<br>dfX = pd.DataFrame(X, columns = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(wine.feature_names))])<br>F = mrmr_classif(dfX, Y, num_class)          <span class="hljs-comment">#mRMR方法</span><br>mrmr_trans_X = X[:, F]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;mRMR方法选择的特征：&quot;</span>, np.sort(F).tolist( ))<br><span class="hljs-comment"># 3. 函数：调用统一的决策树分类模型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ClassifyingModel</span>(<span class="hljs-params">X, Y</span>):<br>    <span class="hljs-comment"># 分割数据集</span><br>    X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = <span class="hljs-number">9</span>)<br>    tree = DTC(criterion = <span class="hljs-string">&quot;entropy&quot;</span>, max_depth = <span class="hljs-number">3</span>, random_state = <span class="hljs-number">9</span>)  <span class="hljs-comment"># 决策树模型</span><br>    tree.fit(X_train, y_train)<br>    score = tree.score(X_test, y_test, sample_weight = <span class="hljs-literal">None</span>)           <span class="hljs-comment"># 计算测试精度</span><br>    <span class="hljs-keyword">return</span> score<br><span class="hljs-comment"># 4. 不同特征选择结果能达到的测试精度(accuracy)</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;决策树模型在不同的特征选择方法选取的子集上取得的测试精度：&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;方差阈值法：&quot;</span>, ClassifyingModel(vt_trans_X, Y))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;卡方统计量法：&quot;</span>, ClassifyingModel(chi_trans_X, Y))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;互信息法：&quot;</span>, ClassifyingModel(mi_trans_X, Y))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;F统计量法：&quot;</span>, ClassifyingModel(F_trans_X, Y))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;mRMR法：&quot;</span>, ClassifyingModel(mrmr_trans_X, Y))<br><br><br><span class="hljs-comment"># ==== 代码5-8.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_wine <br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier <span class="hljs-keyword">as</span> DTC<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split  <br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> RFE, RFECV<br><span class="hljs-comment"># 1. 获得数据</span><br>wine = load_wine()<br>X,Y = wine.data, wine.target<br>X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = <span class="hljs-number">9</span>)<br><span class="hljs-comment">#2. RFE特征选择结果</span><br>tree = DTC(criterion = <span class="hljs-string">&quot;entropy&quot;</span>, max_depth = <span class="hljs-number">3</span>, random_state = <span class="hljs-number">9</span>)     <span class="hljs-comment">#决策树模型</span><br>RFE_selector = RFE(estimator = tree, n_features_to_select = <span class="hljs-number">5</span>, step = <span class="hljs-number">1</span>) <br>RFE_selector.fit(X_train, y_train)                                 <span class="hljs-comment">#训练</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;RFE选择的特征&quot;</span>, RFE_selector.get_support(<span class="hljs-literal">True</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;RFE方法选取特征所获得的测试精度&quot;</span>, RFE_selector.score(X_test, y_test))<br><span class="hljs-comment">#3. RFECV特征选择结果</span><br>RFECV_selector = RFECV(estimator = tree, cv = <span class="hljs-number">5</span>, step = <span class="hljs-number">1</span>) <br>RFECV_selector.fit(X_train, y_train)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;RFECV选择的特征&quot;</span>, RFECV_selector.get_support(<span class="hljs-literal">True</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;RFECV方法选取特征所获得的测试精度&quot;</span>, RFECV_selector.score(X_test, y_test))<br><br><br><span class="hljs-comment"># ==== 代码5-9.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SequentialFeatureSelector<br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_wine <br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier <span class="hljs-keyword">as</span> DTC<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split  <br><span class="hljs-comment">#辅助函数：特征子集的性能评价函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_select_subset</span>(<span class="hljs-params">Xtrain, y_train, X_test, y_test, feature_index</span>):<br>    Xtrain= X_train[: , feature_index]<br>    Xtest= X_test[: , feature_index]<br>    tree =DTC(criterion = <span class="hljs-string">&quot;entropy&quot;</span>, max_depth = <span class="hljs-number">3</span>, random_state = <span class="hljs-number">9</span>)<br>    tree.fit(Xtrain, y_train)  <br>    <span class="hljs-keyword">return</span> tree.score(Xtest, y_test)<br><span class="hljs-comment"># 1. 获得数据</span><br>wine = load_wine()<br>X, Y = wine.data, wine.target<br>X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = <span class="hljs-number">9</span>)<br><span class="hljs-comment">#2. SFS特征选择结果</span><br>tree =DTC(criterion = <span class="hljs-string">&quot;entropy&quot;</span>, max_depth = <span class="hljs-number">3</span>, random_state = <span class="hljs-number">9</span>)     <span class="hljs-comment">#决策树模型</span><br>SFS_selector = SequentialFeatureSelector(estimator = tree, <br>                            n_features_to_select = <span class="hljs-number">5</span>, direction = <span class="hljs-string">&#x27;forward&#x27;</span>) <br>SFS_selector.fit(X_train, y_train)                                <span class="hljs-comment"># 训练</span><br>sd_feat = SFS_selector.get_support(<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SFS选择的特征&quot;</span>, SFS_selector.get_support(<span class="hljs-literal">True</span>))  <br>SFS_score = evaluate_select_subset(X_train, y_train, X_test, y_test, sd_feat)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SFS选择的特征子集上获得的测试精度：&quot;</span>, SFS_score)<br><span class="hljs-comment">#2. SBS特征选择结果</span><br>tree = DTC(criterion = <span class="hljs-string">&quot;entropy&quot;</span>, max_depth = <span class="hljs-number">3</span>, random_state = <span class="hljs-number">9</span>)     <span class="hljs-comment">#决策树模型</span><br>SBS_selector = SequentialFeatureSelector(estimator = tree, <br>                            n_features_to_select = <span class="hljs-number">5</span>, direction = <span class="hljs-string">&#x27;backward&#x27;</span>) <br>SBS_selector.fit(X_train, y_train)                                 <span class="hljs-comment"># 训练</span><br>sd_feat = SBS_selector.get_support(<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SBS选择的特征&quot;</span>, SBS_selector.get_support(<span class="hljs-literal">True</span>))<br>SBS_score = evaluate_select_subset(X_train, y_train, X_test, y_test, sd_feat)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SBS选择的特征子集上获得的测试精度：&quot;</span>, SBS_score)<br><br><span class="hljs-comment"># ==== 代码5-10.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_wine  <br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split  <br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectFromModel<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br><span class="hljs-comment"># 1. 获得数据</span><br>wine = load_wine()<br>X,Y = wine.data, wine.target<br><span class="hljs-comment">#对X进行规范化</span><br>normalize_model = StandardScaler().fit(X) <br>X=normalize_model.transform(X)<br>X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = <span class="hljs-number">9</span>)<br><span class="hljs-comment">#2. L1正则化Logitsitc回归模型进行特征选择</span><br><span class="hljs-comment">#logistic分类模型: 正则参数C控制正则效果的大小，C越大，正则效果越弱</span><br>logistic_model = LogisticRegression(penalty = <span class="hljs-string">&#x27;l1&#x27;</span>, C = <span class="hljs-number">0.5</span>, solver = <span class="hljs-string">&#x27;liblinear&#x27;</span>,<br>                                   random_state = <span class="hljs-number">1234</span>)<br><span class="hljs-comment">#嵌入式特征选择模型</span><br>selector = SelectFromModel(estimator = logistic_model, max_features = <span class="hljs-number">5</span>)<br>selector.fit(X_train, y_train)<br><span class="hljs-comment">#特征选择结果</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;L1正则嵌入法选择的特征：&quot;</span>, selector.get_support(<span class="hljs-literal">True</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;L1正则化Logistic回归模型获得的测试精度&quot;</span>,<br>      selector.estimator_.score(X_test, y_test))<br><br><br><span class="hljs-comment"># ==== 代码5-11.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_wine <br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split  <br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectFromModel<br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier <span class="hljs-keyword">as</span> DTC<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-comment"># 1. 获得数据</span><br>wine = load_wine()<br>X,Y = wine.data, wine.target<br>X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = <span class="hljs-number">9</span>)<br><span class="hljs-comment">#2. 决策树模型进行嵌入式特征选择</span><br>tree = DTC(criterion = <span class="hljs-string">&quot;entropy&quot;</span>, max_depth = <span class="hljs-number">3</span>, random_state = <span class="hljs-number">9</span>)      <span class="hljs-comment">#决策树模型</span><br><span class="hljs-comment">#嵌入式特征选择</span><br>selector = SelectFromModel(estimator = tree, threshold = <span class="hljs-string">&#x27;mean&#x27;</span>)<br>selector.fit(X_train, y_train)<br><span class="hljs-comment">#特征选择结果</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;决策树嵌入法选择的特征：&quot;</span>, selector.get_support(<span class="hljs-literal">True</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;决策树输出的特征重要性系数&quot;</span>,   <br>np.<span class="hljs-built_in">round</span>(selector.estimator_.feature_importances_, <span class="hljs-number">3</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;决策树嵌入法获得的测试精度&quot;</span>, selector.estimator_.score(X_test, y_test))<br><br><span class="hljs-comment"># ==== 代码6-1.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.naive_bayes <span class="hljs-keyword">import</span> GaussianNB<br><span class="hljs-comment">#1. 读入数据</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;UniversalBank.csv&#x27;</span>)<br>y = df[<span class="hljs-string">&#x27;Personal Loan&#x27;</span>]<br>X = df.drop([<span class="hljs-string">&#x27;ID&#x27;</span>, <span class="hljs-string">&#x27;ZIP Code&#x27;</span>, <span class="hljs-string">&#x27;Personal Loan&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">0</span>)<br><span class="hljs-comment">#2. 训练高斯朴素贝叶斯模型</span><br>gnb = GaussianNB()<br>gnb.fit(X_train, y_train)<br><span class="hljs-comment"># 3. 评估模型</span><br>y_pred = gnb.predict(X_test)<br>acc = gnb.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;GaussianNB模型的准确度: %s&#x27;</span>%acc)<br>y_pred = gnb.predict_proba(X_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;测试数据对象0的预测结果（概率）:&#x27;</span>, y_pred[<span class="hljs-number">0</span>])<br><br><br><span class="hljs-comment"># ==== 代码6-2.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.naive_bayes <span class="hljs-keyword">import</span> MultinomialNB<br><span class="hljs-comment"># 1. 读入数据</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;UniversalBank.csv&#x27;</span>)<br>y = df[<span class="hljs-string">&#x27;Personal Loan&#x27;</span>]<br>X = df[[<span class="hljs-string">&#x27;Family&#x27;</span>, <span class="hljs-string">&#x27;Education&#x27;</span>, <span class="hljs-string">&#x27;Securities Account&#x27;</span>, <br><span class="hljs-string">&#x27;CD Account&#x27;</span>, <span class="hljs-string">&#x27;Online&#x27;</span>, <span class="hljs-string">&#x27;CreditCard&#x27;</span>]]              <span class="hljs-comment">#只选用6个特征</span><br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">0</span>)<br><span class="hljs-comment">#2. 训练多项式朴素贝叶斯模型</span><br>mnb = MultinomialNB()<br>mnb.fit(X_train, y_train)<br>acc = mnb.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;MultinomialNB模型的准确度: %s&#x27;</span>%acc)<br><br><br><span class="hljs-comment"># ==== 代码6-3.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.naive_bayes <span class="hljs-keyword">import</span> MultinomialNB<br><span class="hljs-keyword">from</span> sklearn.naive_bayes <span class="hljs-keyword">import</span> GaussianNB<br><span class="hljs-comment"># 1. 读入数据，建立两个数据集</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;UniversalBank.csv&#x27;</span>)<br>df = df.drop([<span class="hljs-string">&#x27;ID&#x27;</span>, <span class="hljs-string">&#x27;ZIP Code&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>ccol = [<span class="hljs-string">&#x27;Family&#x27;</span>, <span class="hljs-string">&#x27;Education&#x27;</span>, <span class="hljs-string">&#x27;Securities Account&#x27;</span>, <br><span class="hljs-string">&#x27;CD Account&#x27;</span>, <span class="hljs-string">&#x27;Online&#x27;</span>, <span class="hljs-string">&#x27;CreditCard&#x27;</span>]           <span class="hljs-comment">#类别特征的索引</span><br>y = df[<span class="hljs-string">&#x27;Personal Loan&#x27;</span>]<br>X_mul = df[ccol]                                  <span class="hljs-comment">#多项式朴素贝叶斯使用的数据</span><br>X_gau = df.drop(ccol + [<span class="hljs-string">&#x27;Personal Loan&#x27;</span>], axis = <span class="hljs-number">1</span>)       <span class="hljs-comment">#高斯朴素贝叶斯使用的数据</span><br>X_mul_train, X_mul_test,X_gau_train, X_gau_test, y_train, y_test =\<br> train_test_split(X_mul, X_gau, y, test_size=<span class="hljs-number">0.1</span>, random_state = <span class="hljs-number">0</span>)<br><span class="hljs-comment"># 2. 使用类别特征训练多项式朴素贝叶斯分类器</span><br>mnb = MultinomialNB()<br>mnb.fit(X_mul_train, y_train)<br>m_train_pred = mnb.predict_proba(X_mul_train)<br>m_test_pred = mnb.predict_proba(X_mul_test)<br>acc=mnb.score(X_mul_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;MultinomialNB模型的准确度: %s&#x27;</span>%acc)<br><span class="hljs-comment"># 3. 使用数值特征训练高斯朴素贝叶斯模型</span><br>gnb = GaussianNB()<br>gnb.fit(X_gau_train, y_train)<br>g_train_pred = gnb.predict_proba(X_gau_train)<br>g_test_pred = gnb.predict_proba(X_gau_test)<br>acc = gnb.score(X_gau_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;GaussianNB模型的准确度: %s&#x27;</span>%acc)<br><span class="hljs-comment"># 4. 集成两个模型</span><br>acc=<span class="hljs-built_in">sum</span>(((m_test_pred[: , <span class="hljs-number">1</span>] + g_test_pred[ : , <span class="hljs-number">1</span>]) &gt;= <span class="hljs-number">1</span>) == (y_test == <span class="hljs-number">1</span>)) / <span class="hljs-built_in">len</span>(y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;集成模型的准确度: %s&#x27;</span>%acc)<br><br><br><span class="hljs-comment"># ==== 代码6-4.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier<br><span class="hljs-comment"># 1. 建立数据集</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;UniversalBank.csv&#x27;</span>)<br>y = df[<span class="hljs-string">&#x27;Personal Loan&#x27;</span>]<br>X = df.drop([<span class="hljs-string">&#x27;ID&#x27;</span>, <span class="hljs-string">&#x27;ZIP Code&#x27;</span>, <span class="hljs-string">&#x27;Personal Loan&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">0</span>)<br>n_neighbors = <span class="hljs-number">5</span>                                <span class="hljs-comment">#K值</span><br><span class="hljs-comment"># 2. 采用两种weights参数建立KNN模型，并评估</span><br><span class="hljs-keyword">for</span> weights <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;uniform&#x27;</span>, <span class="hljs-string">&#x27;distance&#x27;</span>]:<br>    knn = KNeighborsClassifier(n_neighbors, weights = weights)<br>    knn.fit(X_train, y_train)<br>    acc = knn.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%s 准确度:  %s&#x27;</span>%(weights, acc))<br><br><br><span class="hljs-comment"># ==== 代码6-5.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier<br>np.random.seed(<span class="hljs-number">10</span>)<br><span class="hljs-comment"># 1. 建立数据集</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;UniversalBank.csv&#x27;</span>)<br>y = df[<span class="hljs-string">&#x27;Personal Loan&#x27;</span>]<br>X = df.drop([<span class="hljs-string">&#x27;ID&#x27;</span>, <span class="hljs-string">&#x27;ZIP Code&#x27;</span>, <span class="hljs-string">&#x27;Personal Loan&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">0</span>)<br><span class="hljs-comment">#2. 使用默认参数训练CART模型</span><br>model1 = DecisionTreeClassifier()<br>model2 = model1.fit(X_train, y_train)<br>acc1 = model1.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;默认参数的CART决策树的准确度: \n&#x27;</span>, acc1)<br><span class="hljs-comment"># 3. 设置sample_weight参数后训练CART模型</span><br>sample_weight = np.ones((y_train.shape[<span class="hljs-number">0</span>],))<br>sample_weight[y_train == <span class="hljs-number">1</span>] = np.ceil(<span class="hljs-built_in">sum</span>(y_train == <span class="hljs-number">0</span>) / <span class="hljs-built_in">sum</span>(y_train == <span class="hljs-number">1</span>))<br>model2 = DecisionTreeClassifier(max_depth = <span class="hljs-number">10</span>)   <span class="hljs-comment">#设置模型的max_depth参数</span><br>model2 = model2.fit(X_train, y_train, sample_weight)<br>acc2 = model2.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;设置参数后的CART决策树的准确度:\n&#x27;</span>, acc2)<br><span class="hljs-comment">#4. 可视化决策树</span><br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> export_graphviz<br><span class="hljs-keyword">import</span> graphviz<br>dot_data = export_graphviz(model2, out_file = <span class="hljs-literal">None</span>,<br>                           feature_names = X.columns,<br>                           class_names=[<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>],<br>                           filled=<span class="hljs-literal">True</span>)  <span class="hljs-comment">#指定是否为节点上色</span><br>graph = graphviz.Source(dot_data)<br>graph.render(<span class="hljs-string">r&#x27;wine&#x27;</span>)<br>graph.view() <br><br><br><span class="hljs-comment"># ==== 代码6-6.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span>  sklearn.neural_network <span class="hljs-keyword">import</span> MLPClassifier<br>df = pd.read_csv(<span class="hljs-string">&#x27;UniversalBank.csv&#x27;</span>)<br>y = df[<span class="hljs-string">&#x27;Personal Loan&#x27;</span>]<br>X = df.drop([<span class="hljs-string">&#x27;ID&#x27;</span>, <span class="hljs-string">&#x27;ZIP Code&#x27;</span>, <span class="hljs-string">&#x27;Personal Loan&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">0</span>)<br><span class="hljs-comment">#构建BP神经网络模型</span><br>model = MLPClassifier(hidden_layer_sizes = (<span class="hljs-number">1000</span>, <span class="hljs-number">10</span>), activation = <span class="hljs-string">&#x27;logistic&#x27;</span>, verbose = <span class="hljs-number">1</span>)<br>model.fit(X_train, y_train)<br>acc = model.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;BP神经网络的准确度：%s&#x27;</span>%acc)<br><br><br><span class="hljs-comment"># ==== 代码6-7.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> make_pipeline<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC, NuSVC<br>df = pd.read_csv(<span class="hljs-string">&#x27;UniversalBank.csv&#x27;</span>)<br>y = df[<span class="hljs-string">&#x27;Personal Loan&#x27;</span>]<br>X = df.drop([<span class="hljs-string">&#x27;ID&#x27;</span>, <span class="hljs-string">&#x27;ZIP Code&#x27;</span>, <span class="hljs-string">&#x27;Personal Loan&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">0</span>)<br><span class="hljs-comment"># 1. 在规范化数据集上训练SVC模型</span><br>model = make_pipeline(StandardScaler(), SVC(gamma = <span class="hljs-string">&#x27;auto&#x27;</span>, C=<span class="hljs-number">3</span>, class_weight=&#123;<span class="hljs-number">0</span>:<span class="hljs-number">1</span>,<span class="hljs-number">1</span>:<span class="hljs-number">2</span>&#125;))<br>model.fit(X_train, y_train)<br>acc = model.score(X_test,y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;在规范化数据集上训练SVC模型的准确度: \n&#x27;</span>, acc)<br><span class="hljs-comment"># 2. 在未规范化数据集上训练SVC模型</span><br>model = SVC(gamma = <span class="hljs-string">&#x27;auto&#x27;</span>, C = <span class="hljs-number">3</span>)<br>model.fit(X_train, y_train)<br>acc = model.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;在未规范化数据集上训练SVC模型的准确度:\n&#x27;</span>, acc)<br><span class="hljs-comment"># 3. 在规范化数据集上训练Nu-SVC模型</span><br>model = make_pipeline(StandardScaler(), NuSVC(gamma = <span class="hljs-string">&#x27;auto&#x27;</span>, nu = <span class="hljs-number">0.07</span>, <br>class_weight = <span class="hljs-string">&#x27;balanced&#x27;</span>))<br>model.fit(X_train, y_train)<br>acc = model.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;在规范化数据集上训练Nu-SVC模型的准确度: \n&#x27;</span>, acc)<br><br><br><span class="hljs-comment"># ==== 代码6-8.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> KFold<br><span class="hljs-comment"># 1. 准备数据集</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;UniversalBank.csv&#x27;</span>)<br>y = df[<span class="hljs-string">&#x27;Personal Loan&#x27;</span>]<br>X = df[[<span class="hljs-string">&#x27;Age&#x27;</span>, <span class="hljs-string">&#x27;Experience&#x27;</span>,<span class="hljs-string">&#x27;Income&#x27;</span>, <span class="hljs-string">&#x27;CCAvg&#x27;</span>, <span class="hljs-string">&#x27;Mortgage&#x27;</span>]]<br>n_neighbors = <span class="hljs-number">5</span><br>X2 = np.array(X)   <br>y2 = np.array(y)<br><span class="hljs-comment">#2. 在5折交叉验证数据集上测试KNN的准确度</span><br>kf = KFold(n_splits = <span class="hljs-number">5</span>)<br>acc = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> train_index, test_index <span class="hljs-keyword">in</span> kf.split(X2):<br>    knn = KNeighborsClassifier(n_neighbors)         <span class="hljs-comment">#构建KNN分类模型</span><br>    knn.fit(X2[train_index], y2[train_index])<br>    acc += knn.score(X2[test_index], y2[test_index])  <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;使用KFold实现交叉验证计算KNN的准确度: %s&#x27;</span>% (acc/kf.get_n_splits()))<br><span class="hljs-comment">#3. 使用cross_val_score函数实现5折交叉验证，计算KNN的准确度</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> cross_val_score<br>knn = KNeighborsClassifier(n_neighbors)   <br>acc = cross_val_score(knn, X, y, cv = <span class="hljs-number">5</span>)  <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;使用cross_val_score实现交叉验证计算KNN的准确度：%s&#x27;</span>% np.mean(acc))<br><br><br><span class="hljs-comment"># ==== 代码6-9.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>f_train = <span class="hljs-string">&#x27;cs-training.csv&#x27;</span><br>f_test = <span class="hljs-string">&#x27;cs-test.csv&#x27;</span><br>f_target = <span class="hljs-string">&#x27;sampleEntry.csv&#x27;</span><br>df_train = pd.read_csv(f_train, header = <span class="hljs-number">0</span>)<br>df_test = pd.read_csv(f_test, header = <span class="hljs-number">0</span>)<br>df_target = pd.read_csv(f_target, header = <span class="hljs-number">0</span>)<br>df_train = df_train.iloc[:, <span class="hljs-number">1</span>:]<br>df_test = df_test.iloc[:, <span class="hljs-number">1</span>:]<br><span class="hljs-comment"># 类的分布情况</span><br>pos = <span class="hljs-built_in">sum</span>(df_train[<span class="hljs-string">&#x27;SeriousDlqin2yrs&#x27;</span>] &gt; <span class="hljs-number">0.5</span>)<br>neg = <span class="hljs-built_in">len</span>(df_train) - pos<br>plt.figure(figsize=(<span class="hljs-number">14</span>,<span class="hljs-number">10</span>))<br><span class="hljs-built_in">dict</span> = &#123;<span class="hljs-string">&#x27;POS&#x27;</span>: pos, <span class="hljs-string">&#x27;NEG&#x27;</span>: neg&#125;<br>size = <span class="hljs-built_in">len</span>(<span class="hljs-built_in">dict</span>)<br><span class="hljs-keyword">for</span> i, key <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">dict</span>): <br>    plt.bar(i, <span class="hljs-built_in">dict</span>[key], width=<span class="hljs-number">0.2</span>)<br>    plt.text(i-<span class="hljs-number">0.05</span>, <span class="hljs-built_in">dict</span>[key] + <span class="hljs-number">0.01</span>, <span class="hljs-built_in">dict</span>[key],fontsize=<span class="hljs-number">24</span>)<br>plt.xticks(np.arange(size), <span class="hljs-built_in">dict</span>.keys(), fontsize=<span class="hljs-number">24</span>)<br>plt.yticks([<span class="hljs-number">10000</span>, <span class="hljs-number">70000</span>, <span class="hljs-number">130000</span>],fontsize=<span class="hljs-number">24</span>)<br><br><span class="hljs-comment"># ==== 代码6-10.py ====</span><br><br><span class="hljs-comment">#绘制缺失值柱状图</span><br>plt.figure(figsize=(<span class="hljs-number">14</span>,<span class="hljs-number">10</span>))<br>loc = []<br>s = pd.isnull(df_train).<span class="hljs-built_in">sum</span>() / <span class="hljs-built_in">len</span>(df_train)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, df_train.shape[<span class="hljs-number">1</span>]):<br>    <span class="hljs-keyword">if</span> s[i] != <span class="hljs-number">0</span>:<br>        plt.bar(i, s[i],width=<span class="hljs-number">1</span>)<br>        plt.text(i-<span class="hljs-number">0.1</span>, s[i]+<span class="hljs-number">0.005</span>, <span class="hljs-string">&#x27;%.3f&#x27;</span>%s[i], fontsize=<span class="hljs-number">24</span>)<br>        loc.append(i)<br>plt.xticks(loc, s.index[loc],fontsize=<span class="hljs-number">24</span>)<br>plt.yticks([<span class="hljs-number">0</span>, <span class="hljs-number">0.1</span>,<span class="hljs-number">0.2</span>],fontsize=<span class="hljs-number">24</span>)  <br>plt.ylim(<span class="hljs-number">0</span>, <span class="hljs-number">0.25</span>)<br><span class="hljs-comment"># 处理缺失值  </span><br>df_train = df_train.drop([<span class="hljs-string">&#x27;MonthlyIncome&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>df_test = df_test.drop([<span class="hljs-string">&#x27;MonthlyIncome&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>df_train[<span class="hljs-string">&#x27;NumberOfDependents&#x27;</span>].fillna(df_train[<span class="hljs-string">&#x27;NumberOfDependents&#x27;</span>].mean(),<br> inplace = <span class="hljs-literal">True</span>)<br>df_test[<span class="hljs-string">&#x27;NumberOfDependents&#x27;</span>].fillna(df_train[<span class="hljs-string">&#x27;NumberOfDependents&#x27;</span>].mean(), inplace = <span class="hljs-literal">True</span>)<br><br><br><span class="hljs-comment"># ==== 代码6-11.py ====</span><br><br>fig = plt.figure(figsize=(<span class="hljs-number">14</span>,<span class="hljs-number">8</span>))<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(df_train.shape[<span class="hljs-number">1</span>]):<br>    fig.add_subplot(<span class="hljs-number">5</span>, <span class="hljs-number">2</span>, i+<span class="hljs-number">1</span>)<br>    plt.title(df_train.columns[i], fontsize = <span class="hljs-number">16</span>)<br>    dat = df_train.iloc[:, i]<br>    plt.scatter(np.arange(<span class="hljs-built_in">len</span>(dat)), dat, s = <span class="hljs-number">1</span>)  <br>    plt.xticks([])<br>    plt.yticks(fontsize=<span class="hljs-number">16</span>)<br>fig.tight_layout()<br><span class="hljs-comment"># 删除异常值数据</span><br>index = df_train[<span class="hljs-string">&#x27;RevolvingUtilizationOfUnsecuredLines&#x27;</span>] &lt;= <span class="hljs-number">1</span><br>df_train2 = df_train[index]<br>index = df_train[<span class="hljs-string">&#x27;age&#x27;</span>] &gt; <span class="hljs-number">18</span><br>df_train2 = df_train2[index]<br><br><br><span class="hljs-comment"># ==== 代码6-12.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> KFold<br><span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> make_pipeline<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC<br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier<br><span class="hljs-keyword">from</span>  sklearn.neural_network <span class="hljs-keyword">import</span> MLPClassifier<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> cross_validate<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>np.random.seed(<span class="hljs-number">10</span>)<br>X = np.array(df_train2.iloc[:, <span class="hljs-number">1</span>:])<br>y = np.array(df_train2.iloc[:, <span class="hljs-number">0</span>])<br>weight = <span class="hljs-built_in">sum</span>(y == <span class="hljs-number">0</span>) / <span class="hljs-built_in">sum</span>(y == <span class="hljs-number">1</span>)<br>class_weight =&#123;<span class="hljs-number">0</span>:<span class="hljs-number">1</span>, <span class="hljs-number">1</span>:weight&#125;<br>scoring = [<span class="hljs-string">&#x27;accuracy&#x27;</span>, <span class="hljs-string">&#x27;balanced_accuracy&#x27;</span>, <span class="hljs-string">&#x27;roc_auc&#x27;</span>]<br><span class="hljs-comment"># 创建CART决策树模型</span><br>cart = DecisionTreeClassifier(class_weight = class_weight,<br>                              min_samples_leaf = <span class="hljs-number">80</span>,<br>                              max_depth = <span class="hljs-number">8</span>)<br>scores = cross_validate(cart, X, y, cv = <span class="hljs-number">10</span>, scoring = scoring)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;CART决策树模型的信用评分结果:&#x27;</span>)<br>s = np.mean(scores[<span class="hljs-string">&#x27;test_accuracy&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;accuracy: %s&#x27;</span>% s)<br>s = np.mean(scores[<span class="hljs-string">&#x27;test_balanced_accuracy&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;balanced_accuracy: %s&#x27;</span>% s)<br>s = np.mean(scores[<span class="hljs-string">&#x27;test_roc_auc&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;AUC: %s&#x27;</span>% s)<br><br><br><span class="hljs-comment"># ==== 代码6-13.py ====</span><br><br>svm = make_pipeline(StandardScaler(), SVC(gamma = <span class="hljs-string">&#x27;auto&#x27;</span>, C = <span class="hljs-number">100</span>,<br> class_weight = class_weight))<br>scores = cross_validate(svm, X, y, cv =<span class="hljs-number">2</span>, scoring = scoring)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27; SVM模型的性能评价结果:&#x27;</span>)<br>s = np.mean(scores[<span class="hljs-string">&#x27;test_accuracy&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;accuracy: %s&#x27;</span>% s)<br>s = np.mean(scores[<span class="hljs-string">&#x27;test_balanced_accuracy&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;balanced_accuracy: %s&#x27;</span>% s)<br>s = np.mean(scores[<span class="hljs-string">&#x27;test_roc_auc&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;AUC: %s&#x27;</span>% s)<br><br><br><span class="hljs-comment"># ==== 代码6-14.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> KFold<br><span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> make_pipeline<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC<br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier<br><span class="hljs-keyword">from</span>  sklearn.neural_network <span class="hljs-keyword">import</span> MLPClassifier<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> cross_validate<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> balanced_accuracy_score<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> roc_auc_score<br>weight = <span class="hljs-built_in">sum</span>(y == <span class="hljs-number">0</span>) / <span class="hljs-built_in">sum</span>(y == <span class="hljs-number">1</span>)<br>class_weight =&#123;<span class="hljs-number">0</span>:<span class="hljs-number">1</span>, <span class="hljs-number">1</span>:weight&#125;<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>(<span class="hljs-params">model, name, X_test, y_true</span>):     <span class="hljs-comment">#自定义评价函数</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27; %s模型的信用评分结果：&#x27;</span>% name)<br>    y_pred = model.predict(X_test)<br>    score = accuracy_score(y_true, y_pred)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;accuracy: %s&#x27;</span>%score)<br>    score = balanced_accuracy_score(y_true, y_pred)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;balanced accuracy: %s&#x27;</span>%score)<br>    score = roc_auc_score(y_true, y_pred)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;AUC: %s&#x27;</span>%score)<br>X_test= np.array(df_test.iloc[:,<span class="hljs-number">1</span>:])<br>y_test= df_target[<span class="hljs-string">&#x27;Probability&#x27;</span>].gt(<span class="hljs-number">0.5</span>).astype(np.short)<br><span class="hljs-comment">#使用最优参数训练CART决策树</span><br>cart = DecisionTreeClassifier(class_weight = class_weight,<br>                        min_samples_leaf = <span class="hljs-number">80</span>,<br>                        max_depth = <span class="hljs-number">8</span>)<br>cart.fit(X, y)<br>evaluate(cart, <span class="hljs-string">&#x27;CART&#x27;</span>, X_test, y_test)<br><span class="hljs-comment">#使用最优参数训练SVM模型</span><br>svm = make_pipeline(StandardScaler(), SVC(gamma = <span class="hljs-string">&#x27;auto&#x27;</span>, C = <span class="hljs-number">100</span>,<br> class_weight = class_weight))<br>svm.fit(X, y)<br>evaluate(svm, <span class="hljs-string">&#x27;SVM&#x27;</span>, X_test, y_test)<br><br><br><span class="hljs-comment"># ==== 代码6-15.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression<br>df = pd.read_csv(<span class="hljs-string">&#x27;winequality-white.csv&#x27;</span>, delimiter = <span class="hljs-string">&#x27;;&#x27;</span>)<br>y = np.array(df[<span class="hljs-string">&#x27;quality&#x27;</span>]) <br>X = df.drop([<span class="hljs-string">&#x27;quality&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">0</span>)<br>reg = LinearRegression().fit(X_train, y_train)           <span class="hljs-comment">#线性回归模型</span><br>pred = reg.predict(X_test)<br>mae = np.<span class="hljs-built_in">sum</span>(np.<span class="hljs-built_in">abs</span>(pred - y_test)) / <span class="hljs-built_in">len</span>(y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;线性回归模型的MAE为：&#x27;</span>, mae)<br><br><br><span class="hljs-comment"># ==== 代码6-16.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeRegressor<br>df = pd.read_csv(<span class="hljs-string">&#x27;winequality-white.csv&#x27;</span>, delimiter = <span class="hljs-string">&#x27;;&#x27;</span>)<br>y = df[<span class="hljs-string">&#x27;quality&#x27;</span>] <br>X = df.drop([<span class="hljs-string">&#x27;quality&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">0</span>)<br><span class="hljs-comment">#建立CART决策回归树模型，训练并做性能评价</span><br>regressor = DecisionTreeRegressor(random_state = <span class="hljs-number">0</span>)<br>regressor.fit(X_train, y_train)<br>pred = regressor.predict(X_test)<br>mae = np.<span class="hljs-built_in">sum</span>(np.<span class="hljs-built_in">abs</span>(pred - y_test)) / <span class="hljs-built_in">len</span>(y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;CART决策回归树模型的MAE为：&#x27;</span>, mae)<br>mse = regressor.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;CART决策回归树模型的MSE为：&#x27;</span>, mse)<br><br><br><span class="hljs-comment"># ==== 代码6-17.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span>  sklearn.neural_network <span class="hljs-keyword">import</span> MLPRegressor<br>df = pd.read_csv(<span class="hljs-string">&#x27;winequality-white.csv&#x27;</span>, delimiter = <span class="hljs-string">&#x27;;&#x27;</span>)<br>y = df[<span class="hljs-string">&#x27;quality&#x27;</span>] <br>X = df.drop([<span class="hljs-string">&#x27;quality&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">0</span>)<br><span class="hljs-comment">#建立MLP模型，训练并做性能评价</span><br>regressor = MLPRegressor(hidden_layer_sizes = (<span class="hljs-number">100</span>,<span class="hljs-number">10</span>) , solver = <span class="hljs-string">&#x27;adam&#x27;</span>, <br>                         activation = <span class="hljs-string">&#x27;logistic&#x27;</span>, random_state = <span class="hljs-number">0</span>)<br>regressor.fit(X_train, y_train)<br>pred = regressor.predict(X_test)<br>mae = np.<span class="hljs-built_in">sum</span>(np.<span class="hljs-built_in">abs</span>(pred - y_test)) / <span class="hljs-built_in">len</span>(y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;BPNN模型的MAE为：&#x27;</span>, mae)<br>mse = regressor.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;BPNN模型的MSE为：&#x27;</span>, mse)<br><br><br><span class="hljs-comment"># ==== 代码6-18.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVR <br><span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> make_pipeline<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br>df = pd.read_csv(<span class="hljs-string">&#x27;winequality-white.csv&#x27;</span>, delimiter = <span class="hljs-string">&#x27;;&#x27;</span>)<br>y = np.array(df[<span class="hljs-string">&#x27;quality&#x27;</span>])<br>X = df.drop([<span class="hljs-string">&#x27;quality&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">0</span>)<br><span class="hljs-comment"># 创建SVR模型，训练并预测</span><br>regressor = SVR(C = <span class="hljs-number">100</span>)<br>model = make_pipeline(StandardScaler(), regressor)<br>model.fit(X_train, y_train)<br>pred = model.predict(X_test)<br>mae = np.<span class="hljs-built_in">sum</span>(np.<span class="hljs-built_in">abs</span>(pred - y_test)) / <span class="hljs-built_in">len</span>(y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;SVR模型的MAE为：&#x27;</span>, mae)<br>mse = model.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;SVR模型的MSE为：&#x27;</span>, mse)<br><br><span class="hljs-comment"># ==== 代码7-1.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> BaggingClassifier<br>df = pd.read_csv(<span class="hljs-string">&#x27;UniversalBank.csv&#x27;</span>)<br>y = df[<span class="hljs-string">&#x27;Personal Loan&#x27;</span>]<br>X = df.drop([<span class="hljs-string">&#x27;ID&#x27;</span>, <span class="hljs-string">&#x27;ZIP Code&#x27;</span>, <span class="hljs-string">&#x27;Personal Loan&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">0</span>)<br><span class="hljs-comment">#建立KNN模型和装袋模型</span><br>knn = KNeighborsClassifier(<span class="hljs-number">5</span>, weights = <span class="hljs-string">&#x27;distance&#x27;</span>)<br>bagging_model = BaggingClassifier(base_estimator = knn, n_estimators = <span class="hljs-number">10</span>)<br><span class="hljs-comment"># 模型训练和评估</span><br>knn.fit(X_train, y_train)<br>acc = knn.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;KNN模型的准确度: %s&#x27;</span>%(acc))<br>bagging_model.fit(X_train, y_train)<br>acc = bagging_model.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Bagging模型的准确度: %s&#x27;</span>%(acc))<br><br><br><br><span class="hljs-comment"># ==== 代码7-2.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> AdaBoostClassifier<br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier<br>df = pd.read_csv(<span class="hljs-string">&#x27;UniversalBank.csv&#x27;</span>)<br>y = df[<span class="hljs-string">&#x27;Personal Loan&#x27;</span>]<br>X = df.drop([<span class="hljs-string">&#x27;ID&#x27;</span>, <span class="hljs-string">&#x27;ZIP Code&#x27;</span>, <span class="hljs-string">&#x27;Personal Loan&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">0</span>)<br><span class="hljs-comment">#建立CART决策树基模型和提升模型</span><br>cart = DecisionTreeClassifier(min_samples_leaf = <span class="hljs-number">5</span>, max_depth = <span class="hljs-number">6</span>)<br>ada_model = AdaBoostClassifier(base_estimator = cart, n_estimators = <span class="hljs-number">50</span>,<br> random_state = <span class="hljs-number">10</span>)<br><span class="hljs-comment">#模型训练和测试</span><br>cart.fit(X_train, y_train)<br>acc = cart.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;CART决策树模型的准确度: %s&#x27;</span>%(acc))<br>ada_model.fit(X_train, y_train)<br>acc = ada_model.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Adaboost模型的准确度: %s&#x27;</span>%(acc))<br><br><br><span class="hljs-comment"># ==== 代码7-3.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> StackingClassifier<br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC, NuSVC<br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier<br><span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> make_pipeline<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> KFold<br><span class="hljs-comment"># 1. 读入数据，建立训练集和测试集</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;UniversalBank.csv&#x27;</span>)<br>y = df[<span class="hljs-string">&#x27;Personal Loan&#x27;</span>]<br>X = df.drop([<span class="hljs-string">&#x27;ID&#x27;</span>, <span class="hljs-string">&#x27;ZIP Code&#x27;</span>, <span class="hljs-string">&#x27;Personal Loan&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">0</span>)<br><span class="hljs-comment"># 2. 建立基模型、元模型和堆叠模型</span><br>cart = DecisionTreeClassifier()<br>svm = make_pipeline(StandardScaler(),<br> NuSVC(gamma = <span class="hljs-string">&#x27;auto&#x27;</span>, nu = <span class="hljs-number">0.07</span>, class_weight = <span class="hljs-string">&#x27;balanced&#x27;</span>))<br>lr = LogisticRegression()                  <span class="hljs-comment">#元模型</span><br>estimators = [(<span class="hljs-string">&#x27;cart&#x27;</span>, cart), (<span class="hljs-string">&#x27;svm&#x27;</span>, svm)]       <span class="hljs-comment">#基模型</span><br>kf = KFold(n_splits = <span class="hljs-number">10</span>)<br>stacking_model = StackingClassifier(estimators = estimators,       <span class="hljs-comment">#堆叠模型</span><br>                           final_estimator = lr, cv = kf)<br><span class="hljs-comment">#3. 训练和测试模型</span><br>cart.fit(X_train, y_train)<br>acc = cart.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;CART决策树模型的准确度: %s&#x27;</span>%(acc))<br>svm.fit(X_train, y_train)<br>acc = svm.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;支持向量机模型的准确度: %s&#x27;</span>%(acc))<br>stacking_model.fit(X_train, y_train)<br>acc = stacking_model.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;堆叠(Stacking)模型的准确度: %s&#x27;</span>%(acc))<br><br><br><span class="hljs-comment"># ==== 代码7-4.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<br><span class="hljs-comment">#1. 读数据，建立训练集和测试集</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;UniversalBank.csv&#x27;</span>)<br>y = df[<span class="hljs-string">&#x27;Personal Loan&#x27;</span>]<br>X = df.drop([<span class="hljs-string">&#x27;ID&#x27;</span>, <span class="hljs-string">&#x27;ZIP Code&#x27;</span>,<span class="hljs-string">&#x27;Personal Loan&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">0</span>)<br><span class="hljs-comment">#2. 计算样本权重</span><br>sample_weights = np.ones((y_train.shape[<span class="hljs-number">0</span>],))<br>sample_weights[y_train == <span class="hljs-number">1</span>] = np.ceil(<span class="hljs-built_in">sum</span>(y_train == <span class="hljs-number">0</span>) / <span class="hljs-built_in">sum</span>(y_train == <span class="hljs-number">1</span>))<br><span class="hljs-comment">#3. 构建随机森林</span><br>model = RandomForestClassifier(n_estimators = <span class="hljs-number">400</span>, max_depth = <span class="hljs-number">8</span>,<br>                            min_samples_split = <span class="hljs-number">3</span>, random_state = <span class="hljs-number">0</span>)<br><span class="hljs-comment">#4. 训练和测试模型</span><br>model = model.fit(X_train, y_train, sample_weights)<br>acc = model.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;随机森林模型的准确度: %s&#x27;</span> % acc)<br><br><br><span class="hljs-comment"># ==== 代码7-5.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> GradientBoostingClassifier<br><span class="hljs-comment">#1. 读入数据，建立训练集和测试集</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;UniversalBank.csv&#x27;</span>)<br>y = df[<span class="hljs-string">&#x27;Personal Loan&#x27;</span>]<br>X = df.drop([<span class="hljs-string">&#x27;ID&#x27;</span>, <span class="hljs-string">&#x27;ZIP Code&#x27;</span>, <span class="hljs-string">&#x27;Personal Loan&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">0</span>)<br><span class="hljs-comment">#2. 计算样本权重</span><br>sample_weights = np.ones((y_train.shape[<span class="hljs-number">0</span>],))<br>sample_weights[y_train == <span class="hljs-number">1</span>] = np.ceil(<span class="hljs-built_in">sum</span>(y_train == <span class="hljs-number">0</span>) / <span class="hljs-built_in">sum</span>(y_train == <span class="hljs-number">1</span>))<br><span class="hljs-comment">#3. 建立提升树模型</span><br>model = GradientBoostingClassifier(n_estimators = <span class="hljs-number">200</span>, learning_rate = <span class="hljs-number">0.3</span>,<br>                           max_depth = <span class="hljs-number">5</span>, min_samples_leaf = <span class="hljs-number">4</span>, random_state = <span class="hljs-number">0</span>)<br><span class="hljs-comment">#4. 训练和评估模型</span><br>model.fit(X_train, y_train, sample_weights)<br>acc = model.score(X_test, y_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;提升树模型的准确度: %s&#x27;</span> % acc)<br><br><br><span class="hljs-comment"># ==== 代码7-6.py ====</span><br><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> LabelEncoder<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> OneHotEncoder<br>df = pd.read_csv(<span class="hljs-string">&#x27;churn.csv&#x27;</span>)<br><span class="hljs-comment">#处理TotalCharges特征上的缺失值</span><br>idx = df[<span class="hljs-string">&#x27;TotalCharges&#x27;</span>] == <span class="hljs-string">&#x27; &#x27;</span><br>df[<span class="hljs-string">&#x27;TotalCharges&#x27;</span>][idx] = df[<span class="hljs-string">&#x27;MonthlyCharges&#x27;</span>][idx]<br>df[<span class="hljs-string">&#x27;TotalCharges&#x27;</span>] = pd.to_numeric(df[<span class="hljs-string">&#x27;TotalCharges&#x27;</span>], downcast = <span class="hljs-string">&quot;float&quot;</span>)<br><span class="hljs-comment">#对Churn特征进行编码</span><br>le = LabelEncoder()<br>le.fit(df[<span class="hljs-string">&#x27;Churn&#x27;</span>])<br>y = le.transform(df[<span class="hljs-string">&#x27;Churn&#x27;</span>])<br>df = df.drop([<span class="hljs-string">&#x27;customerID&#x27;</span>, <span class="hljs-string">&#x27;Churn&#x27;</span>], axis=<span class="hljs-number">1</span>)<br><br><br><span class="hljs-comment"># ==== 代码7-7.py ====</span><br><br>excluded_cols = [<span class="hljs-string">&#x27;SeniorCitizen&#x27;</span>, <span class="hljs-string">&#x27;tenure&#x27;</span>, <span class="hljs-string">&#x27;MonthlyCharges&#x27;</span>, <span class="hljs-string">&#x27;TotalCharges&#x27;</span>]<br>cates = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(df.columns) - <span class="hljs-built_in">set</span>(excluded_cols))<br>encoder = OneHotEncoder(drop = <span class="hljs-string">&#x27;first&#x27;</span>)<br>df2 = encoder.fit_transform(df[cates]).toarray()<br>X = np.concatenate((df2, df[excluded_cols]), axis = <span class="hljs-number">1</span>)<br><br><br><span class="hljs-comment"># ==== 代码7-8.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> GradientBoostingClassifier<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> StratifiedKFold <br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> KFold <br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> AdaBoostClassifier<br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> balanced_accuracy_score<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>np.random.seed(<span class="hljs-number">10</span>)<br>skf = StratifiedKFold(n_splits =<span class="hljs-number">10</span>, shuffle = <span class="hljs-literal">True</span>, random_state = <span class="hljs-number">10</span>) <br><br><br><span class="hljs-comment"># ==== 代码7-9.py ====</span><br><br><span class="hljs-comment"># step 1: 设置初始准确度和平衡准确度</span><br>acc_rf, acc_gbt, acc_ada = <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>     <span class="hljs-comment">#设置三种模型的初始准确度</span><br>bacc_rf, bacc_gbt, bacc_ada = <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>  <span class="hljs-comment">#设置三种模型的初始平衡准确度</span><br><span class="hljs-keyword">for</span> train_index, test_index <span class="hljs-keyword">in</span> skf.split(df, y):<br>    X_train = X[train_index]<br>    y_train = y[train_index]<br>    X_test = X[test_index]<br>    y_test = y[test_index]<br><span class="hljs-comment"># step 2: 计算样本权重</span><br>sample_weights = np.ones((<span class="hljs-built_in">len</span>(y_train), ))<br>sample_weights[y_train == <span class="hljs-number">1</span>] = np.ceil(<span class="hljs-built_in">sum</span>(y_train == <span class="hljs-number">0</span>) / <span class="hljs-built_in">sum</span>(y_train == <span class="hljs-number">1</span>))<br><span class="hljs-comment"># step 3: 提升树模型的训练与评估</span><br>gbt = GradientBoostingClassifier(n_estimators = <span class="hljs-number">200</span>, <br>                            learning_rate = <span class="hljs-number">0.3</span>,<br>                            max_depth = <span class="hljs-number">5</span>, <br>                            min_samples_leaf = <span class="hljs-number">4</span>,<br>                            random_state = <span class="hljs-number">0</span>)<br>gbt.fit(X_train, y_train, sample_weights)<br>y_pred = gbt.predict(X_test)<br>acc_gbt += accuracy_score(y_test, y_pred)<br>bacc_gbt += balanced_accuracy_score(y_test, y_pred)<br><span class="hljs-comment"># step 4: 随机森林的训练与评估</span><br>rf = RandomForestClassifier(n_estimators = <span class="hljs-number">1000</span>,<br>                        max_depth = <span class="hljs-number">8</span>,<br>                        min_samples_split = <span class="hljs-number">3</span>, <br>                        random_state = <span class="hljs-number">0</span>)<br>rf.fit(X_train, y_train,sample_weights)<br>y_pred = rf.predict(X_test)<br>acc_rf += accuracy_score(y_test, y_pred)<br>bacc_rf += balanced_accuracy_score(y_test, y_pred)<br><span class="hljs-comment"># step 5: Adaboost的训练与评估</span><br>cart = DecisionTreeClassifier(min_samples_leaf = <span class="hljs-number">15</span>, max_depth = <span class="hljs-number">15</span>)<br>ada = AdaBoostClassifier(base_estimator = cart, n_estimators = <span class="hljs-number">1000</span>, random_state = <span class="hljs-number">10</span>)<br>ada.fit(X_train, y_train, sample_weights)<br>y_pred = ada.predict(X_test)<br>acc_ada += accuracy_score(y_test, y_pred)<br>bacc_ada += balanced_accuracy_score(y_test, y_pred)<br><span class="hljs-comment"># step 6: 显示分类结果</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;提升树的准确度:%s, 平衡准确度: %s&#x27;</span>%(acc_gbt/<span class="hljs-number">10</span>, bacc_gbt/<span class="hljs-number">10</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;随机森林的准确度:%s, 平衡准确度: %s&#x27;</span>% (acc_rf/<span class="hljs-number">10</span>,bacc_rf/<span class="hljs-number">10</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Adaboost的准确度:%s, 平衡准确度: %s&#x27;</span>%(acc_ada/<span class="hljs-number">10</span>, bacc_ada/<span class="hljs-number">10</span>))<br><br><span class="hljs-comment"># ==== 代码7-10.py ====</span><br><br><span class="hljs-keyword">from</span> numpy <span class="hljs-keyword">import</span> mean<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> RepeatedStratifiedKFold<br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier<br><span class="hljs-keyword">from</span> imblearn.pipeline <span class="hljs-keyword">import</span> Pipeline<br><span class="hljs-keyword">from</span> imblearn.over_sampling <span class="hljs-keyword">import</span> SMOTE, ADASYN<br><span class="hljs-keyword">from</span> imblearn.under_sampling <span class="hljs-keyword">import</span> RandomUnderSampler<br><span class="hljs-keyword">from</span> imblearn.over_sampling <span class="hljs-keyword">import</span> RandomOverSampler<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> cross_validate<br><span class="hljs-keyword">from</span> imblearn.ensemble <span class="hljs-keyword">import</span> EasyEnsembleClassifier <br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> AdaBoostClassifier<br>np.random.seed(<span class="hljs-number">10</span>)<br>k = <span class="hljs-number">5</span> <br>df = pd.read_csv(<span class="hljs-string">&#x27;UniversalBank.csv&#x27;</span>)<br>y = df[<span class="hljs-string">&#x27;Personal Loan&#x27;</span>]<br>X = df.drop([<span class="hljs-string">&#x27;ID&#x27;</span>, <span class="hljs-string">&#x27;ZIP Code&#x27;</span>, <span class="hljs-string">&#x27;Personal Loan&#x27;</span>], axis = <span class="hljs-number">1</span>)<br>scorings = [<span class="hljs-string">&#x27;accuracy&#x27;</span>, <span class="hljs-string">&#x27;balanced_accuracy&#x27;</span>]<br><br><br><span class="hljs-comment"># ==== 代码7-11.py ====</span><br><br>model = DecisionTreeClassifier(min_samples_leaf = <span class="hljs-number">7</span>)<br>scores = cross_validate(model, X, y, cv = <span class="hljs-number">10</span>, scoring = scorings)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;不处理不平衡问题的CART决策树模型：&#x27;</span>)<br>s = np.mean(scores[<span class="hljs-string">&#x27;test_balanced_accuracy&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;平衡准确度: %s&#x27;</span>% s)<br>s = np.mean(scores[<span class="hljs-string">&#x27;test_accuracy&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;准确度: %s&#x27;</span>% s)<br><br><br><span class="hljs-comment"># ==== 代码7-12.py ====</span><br><br>class_weight = &#123;<span class="hljs-number">0</span>:<span class="hljs-number">1</span>, <span class="hljs-number">1</span>:<span class="hljs-built_in">sum</span>(y == <span class="hljs-number">0</span>) / <span class="hljs-built_in">sum</span>(y == <span class="hljs-number">1</span>)&#125;        <span class="hljs-comment">#设置类别权重</span><br>model = DecisionTreeClassifier(class_weight = class_weight, min_samples_leaf = <span class="hljs-number">7</span>)<br>scores = cross_validate(model, X, y, cv = <span class="hljs-number">10</span>, scoring = scorings)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;设置类别权重后的CART决策树模型: &#x27;</span>)<br>s = np.mean(scores[<span class="hljs-string">&#x27;test_balanced_accuracy&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;平衡准确度: %s&#x27;</span>% s)<br>s = np.mean(scores[<span class="hljs-string">&#x27;test_accuracy&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;准确度: %s&#x27;</span>% s)<br><br><br><span class="hljs-comment"># ==== 代码7-13.py ====</span><br><br>smote = SMOTE(sampling_strategy = <span class="hljs-string">&#x27;minority&#x27;</span>, k_neighbors = k)<br>X_res, y_res = smote.fit_resample(X, y)<br>model = DecisionTreeClassifier(min_samples_leaf = <span class="hljs-number">7</span>)<br>scores = cross_validate(model, X_res, y_res, cv = <span class="hljs-number">10</span>, scoring = scorings)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;使用SMOTE过采样处理不平衡数据后的CART决策树模型：&#x27;</span>)<br>s = np.mean(scores[<span class="hljs-string">&#x27;test_balanced_accuracy&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;平衡准确度: %s&#x27;</span>% s)<br>s = np.mean(scores[<span class="hljs-string">&#x27;test_accuracy&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;准确度: %s&#x27;</span>% s)<br><br><br><span class="hljs-comment"># ==== 代码7-14.py ====</span><br><br>adasyn = ADASYN(sampling_strategy = <span class="hljs-string">&#x27;minority&#x27;</span>)<br>model = DecisionTreeClassifier(min_samples_leaf = <span class="hljs-number">7</span>)<br>X_res, y_res = adasyn.fit_resample(X, y)<br>scores = cross_validate(model, X_res, y_res, cv = <span class="hljs-number">10</span>, scoring = scorings)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;使用ADASYN过采样处理不平衡数据后的CART决策树模型：&#x27;</span>)<br>s = np.mean(scores[<span class="hljs-string">&#x27;test_balanced_accuracy&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;平衡准确度: %s&#x27;</span>% s)<br>s = np.mean(scores[<span class="hljs-string">&#x27;test_accuracy&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;准确度: %s&#x27;</span>% s)<br><br><br><span class="hljs-comment"># ==== 代码7-15.py ====</span><br><br>cart = DecisionTreeClassifier(min_samples_leaf = <span class="hljs-number">5</span>, max_depth = <span class="hljs-number">6</span>)<br>ada = AdaBoostClassifier(base_estimator = cart, n_estimators = <span class="hljs-number">100</span>)<br>eec = EasyEnsembleClassifier(base_estimator = ada, <br>sampling_strategy = <span class="hljs-string">&#x27;all&#x27;</span>, replacement = <span class="hljs-literal">True</span>)<br>scores = cross_validate(eec, X, y, cv = <span class="hljs-number">10</span>, scoring = scorings)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;处理不平衡问题的Easy Ensemble集成模型：&#x27;</span>)<br>s = np.mean(scores[<span class="hljs-string">&#x27;test_balanced_accuracy&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;平衡准确度: %s&#x27;</span>% s)<br>s = np.mean(scores[<span class="hljs-string">&#x27;test_accuracy&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;准确度: %s&#x27;</span>% s)<br><br><span class="hljs-comment"># ==== 代码8-1.py ====</span><br><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.cluster <span class="hljs-keyword">import</span> KMeans<br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_blobs   <br><span class="hljs-comment">#1. 获得数据集</span><br>n_samples = <span class="hljs-number">200</span>                         <span class="hljs-comment">#样本数量</span><br>X, y = make_blobs(n_samples = n_samples,<br> random_state = <span class="hljs-number">9</span>, centers = <span class="hljs-number">4</span>, cluster_std = <span class="hljs-number">1</span>)<br><span class="hljs-comment">#2. KMeans模型创建和训练预测</span><br>model = KMeans(n_clusters = <span class="hljs-number">4</span>, random_state = <span class="hljs-number">12345</span>)<br>y_pred = model.fit_predict(X)<br><span class="hljs-comment">#3. 聚类结果及评价</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;聚类后的SSE值:&quot;</span>, model.inertia_)     <span class="hljs-comment"># SSE值</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;聚类质心：&quot;</span>, model.cluster_centers_)<br><span class="hljs-comment">#4. 绘图显示聚类结果</span><br>plt.figure(figsize = (<span class="hljs-number">5</span>, <span class="hljs-number">5</span>))<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]      <span class="hljs-comment">#显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span><br>plt.scatter(X[y_pred == <span class="hljs-number">0</span>][:, <span class="hljs-number">0</span>], X[y_pred == <span class="hljs-number">0</span>][:, <span class="hljs-number">1</span>], marker = <span class="hljs-string">&#x27;D&#x27;</span>, color = <span class="hljs-string">&#x27;g&#x27;</span>)<br>plt.scatter(X[y_pred == <span class="hljs-number">1</span>][:, <span class="hljs-number">0</span>], X[y_pred == <span class="hljs-number">1</span>][:, <span class="hljs-number">1</span>], marker = <span class="hljs-string">&#x27;o&#x27;</span>, color = <span class="hljs-string">&#x27;b&#x27;</span>)<br>plt.scatter(X[y_pred == <span class="hljs-number">2</span>][:, <span class="hljs-number">0</span>], X[y_pred == <span class="hljs-number">2</span>][:, <span class="hljs-number">1</span>], marker = <span class="hljs-string">&#x27;s&#x27;</span>, color = <span class="hljs-string">&#x27;m&#x27;</span>)<br>plt.scatter(X[y_pred == <span class="hljs-number">3</span>][:, <span class="hljs-number">0</span>], X[y_pred == <span class="hljs-number">3</span>][:, <span class="hljs-number">1</span>], marker = <span class="hljs-string">&#x27;v&#x27;</span>, color = <span class="hljs-string">&#x27;r&#x27;</span>)<br>plt.title(<span class="hljs-string">&quot;k-means算法的聚类结果， k = 4&quot;</span>)<br>plt.show()<br><br><br><span class="hljs-comment"># ==== 代码8-2.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;1.内部度量指标&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot; 轮廓系数: %0.3f&quot;</span> % metrics.silhouette_score(X, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot; CH指数: %0.3f&quot;</span> % metrics.calinski_harabasz_score(X, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;2.外部度量指标&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot; ARI指数: %0.3f&quot;</span> % metrics.adjusted_rand_score(y, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot; NMI指数: %0.3f&quot;</span> % metrics.normalized_mutual_info_score(y, y_pred))<br><br><br><span class="hljs-comment"># ==== 代码8-3.py ====</span><br><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.cluster <span class="hljs-keyword">import</span> DBSCAN<br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_moons<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics<br><span class="hljs-comment"># 1. 获得数据集</span><br>n_samples = <span class="hljs-number">200</span>                   <span class="hljs-comment">#样本数量</span><br>X, y = make_moons(n_samples = n_samples, random_state = <span class="hljs-number">9</span>,noise = <span class="hljs-number">0.1</span>)<br><span class="hljs-comment">#添加噪声（若无需噪声，此步骤可删除）</span><br>X = np.insert(X, <span class="hljs-number">0</span>, values = np.array([[<span class="hljs-number">1.5</span>, <span class="hljs-number">0.5</span>], [-<span class="hljs-number">0.5</span>, <span class="hljs-number">0</span>]]), axis = <span class="hljs-number">0</span>)<br>y = np.insert(y, <span class="hljs-number">0</span>, [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], axis = <span class="hljs-number">0</span>)<br><span class="hljs-comment">#2. DBSCAN模型创建和训练</span><br>model = DBSCAN( eps = <span class="hljs-number">0.2</span>, min_samples = <span class="hljs-number">4</span>)<br>y_pred = model.fit_predict(X)        <span class="hljs-comment"># -1代表噪声,其余值代表预测的簇标号,0,1</span><br><span class="hljs-comment"># 统计聚类后的簇数量</span><br>n_clusters_ = <span class="hljs-built_in">len</span>(<span class="hljs-built_in">set</span>(y_pred)) - (<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> -<span class="hljs-number">1</span> <span class="hljs-keyword">in</span> y_pred <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>)<br><span class="hljs-comment">#3. 聚类模型评价</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;聚类的簇数: %d&#x27;</span> % n_clusters_)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;轮廓系数: %0.3f&#x27;</span> % metrics.silhouette_score(X, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;调整兰德指数AMI: %0.3f&#x27;</span> % metrics.adjusted_rand_score(y, y_pred))<br><span class="hljs-comment"># 4. 绘图显示聚类结果</span><br>core_samples_mask = np.zeros_like(model.labels_, dtype = <span class="hljs-built_in">bool</span>)    <span class="hljs-comment">#获得核心对象的掩码</span><br>core_samples_mask[model.core_sample_indices_] = <span class="hljs-literal">True</span><br><span class="hljs-comment">#绘制原始数据集</span><br>set_marker = [<span class="hljs-string">&#x27;o&#x27;</span>, <span class="hljs-string">&#x27;v&#x27;</span>, <span class="hljs-string">&#x27;x&#x27;</span>, <span class="hljs-string">&#x27;D&#x27;</span>, <span class="hljs-string">&#x27;&gt;&#x27;</span>, <span class="hljs-string">&#x27;p&#x27;</span>, <span class="hljs-string">&#x27;&lt;&#x27;</span>]<br>set_color = [<span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>, <span class="hljs-string">&#x27;m&#x27;</span>, <span class="hljs-string">&#x27;g&#x27;</span>, <span class="hljs-string">&#x27;c&#x27;</span>, <span class="hljs-string">&#x27;k&#x27;</span>, <span class="hljs-string">&#x27;tan&#x27;</span>]<br>plt.figure(figsize = (<span class="hljs-number">5</span>, <span class="hljs-number">5</span>))<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_clusters_):<br>    plt.scatter(X[y == i][:, <span class="hljs-number">0</span>], X[y == i][:, <span class="hljs-number">1</span>], marker = set_marker[i],<br>             color = <span class="hljs-string">&#x27;none&#x27;</span>, edgecolors = set_color[i])<br>plt.title(<span class="hljs-string">&#x27; Moons数据集(带2个噪声点)&#x27;</span>, fontsize = <span class="hljs-number">14</span>)<br><span class="hljs-comment">#绘制DBSCAN的聚类结果</span><br>plt.figure(figsize = (<span class="hljs-number">5</span>, <span class="hljs-number">5</span>))<br>unique_labels = <span class="hljs-built_in">set</span>(y_pred)<br>i = -<span class="hljs-number">1</span>               <span class="hljs-comment">#flag变量</span><br><span class="hljs-keyword">for</span> k, col <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(unique_labels, set_color[<span class="hljs-number">0</span>: <span class="hljs-built_in">len</span>(unique_labels)]):<br>    <span class="hljs-keyword">if</span> k == -<span class="hljs-number">1</span>:<br>        col = <span class="hljs-string">&#x27;k&#x27;</span>     <span class="hljs-comment"># 黑色表示标记噪声点.</span><br>    class_member_mask = (y_pred == k)<br>    i += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">if</span> (i&gt;=<span class="hljs-built_in">len</span>(unique_labels)):  i = <span class="hljs-number">0</span><br>    <span class="hljs-comment">#绘制核心对象</span><br>    xcore = X[class_member_mask &amp; core_samples_mask]<br>    plt.plot(xcore[:, <span class="hljs-number">0</span>], xcore[:, <span class="hljs-number">1</span>], set_marker[i], markerfacecolor = col,<br>          markeredgecolor = <span class="hljs-string">&#x27;k&#x27;</span>, markersize = <span class="hljs-number">8</span>)<br>    <span class="hljs-comment">#绘制边界对象和噪声</span><br>    xncore = X[class_member_mask &amp; ~core_samples_mask]<br>    plt.plot(xncore[:, <span class="hljs-number">0</span>], xncore[:, <span class="hljs-number">1</span>], set_marker[i], markerfacecolor = col,<br>          markeredgecolor = <span class="hljs-string">&#x27;k&#x27;</span>, markersize = <span class="hljs-number">4</span>)<br>plt.title(<span class="hljs-string">&#x27;DBSCAN算法的聚类结果: 识别的簇= %d&#x27;</span> % n_clusters_, fontsize = <span class="hljs-number">14</span>)<br>plt.show()<br><br><br><span class="hljs-comment"># ==== 代码8-4.py ====</span><br><br><span class="hljs-keyword">from</span> sklearn.mixture <span class="hljs-keyword">import</span> GaussianMixture<br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_blobs    <span class="hljs-comment"># 用于生成数据集的库</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> draw_ellipse, BIC         <span class="hljs-comment"># 引用辅助函数</span><br><span class="hljs-comment"># 1. 获得数据集</span><br>n_samples = <span class="hljs-number">200</span>                        <span class="hljs-comment"># 样本数量</span><br>X, y = make_blobs(n_samples = n_samples, random_state = <span class="hljs-number">9</span>, centers = <span class="hljs-number">4</span>, cluster_std = <span class="hljs-number">1</span>)<br><span class="hljs-comment"># 2. GMM模型的创建和训练</span><br>K = <span class="hljs-number">4</span>                                  <span class="hljs-comment"># 簇的数量</span><br>model = GaussianMixture(n_components = K, covariance_type = <span class="hljs-string">&#x27;full&#x27;</span>, random_state = <span class="hljs-number">15</span>)<br>y_pred = model.fit_predict(X)<br><span class="hljs-comment"># 3. 聚类模型评价</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot; 轮廓系数: %0.3f&quot;</span> % metrics.silhouette_score(X, y_pred))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot; 调整兰德指数AMI: %0.3f&quot;</span> % metrics.adjusted_rand_score(y, y_pred))<br><span class="hljs-comment"># 4绘图显示GMM的聚类结果</span><br>plt.figure(figsize = (<span class="hljs-number">5</span>, <span class="hljs-number">5</span>))<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]             <span class="hljs-comment">#显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(K):<br>    plt.scatter(X[y_pred == i][:, <span class="hljs-number">0</span>], X[y_pred == i][:, <span class="hljs-number">1</span>],   <br>marker=set_marker[i], color=set_color[i])<br>    <span class="hljs-comment"># 为簇绘制椭圆阴影区域</span><br>    <span class="hljs-keyword">for</span> p, c, w <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(model.means_, model.covariances_, model.weights_):<br>        draw_ellipse(p, c, alpha = <span class="hljs-number">0.05</span>)<br>plt.title(<span class="hljs-string">&quot; GMM的聚类结果, K=%d&quot;</span>% K, fontsize = <span class="hljs-number">14</span>)<br>plt.show()<br><br><br><span class="hljs-comment"># ==== 代码8-5.py ====</span><br><br><span class="hljs-keyword">from</span> matplotlib.patches <span class="hljs-keyword">import</span> Ellipse<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.mixture <span class="hljs-keyword">import</span> GaussianMixture<br><span class="hljs-comment"># 函数： 给定的位置画一个椭圆</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">draw_ellipse</span>(<span class="hljs-params">position, covariance, ax = <span class="hljs-literal">None</span>, **kwargs</span>):<br>    ax = ax <span class="hljs-keyword">or</span> plt.gca()<br>    <span class="hljs-comment"># 将协方差转换为主轴</span><br>    <span class="hljs-keyword">if</span> covariance.shape == (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>):<br>        U, s, Vt = np.linalg.svd(covariance)<br>        angle = np.degrees(np.arctan2(U[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], U[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]))<br>        width, height = <span class="hljs-number">2</span> * np.sqrt(s)<br>    <span class="hljs-keyword">else</span>:<br>        angle = <span class="hljs-number">0</span><br>        width, height = <span class="hljs-number">2</span> * np.sqrt(covariance)<br>    ax.add_patch(Ellipse(position, <span class="hljs-number">3</span> * width, <span class="hljs-number">3</span> * height, angle, **kwargs))<br><span class="hljs-comment"># 函数： 计算BIC准则</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">BIC</span>(<span class="hljs-params">X</span>):<br>    lowest_bic = np.infty<br>    bic = []<br>    n_components_range = <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>)<br>    <span class="hljs-keyword">for</span> n_components <span class="hljs-keyword">in</span> n_components_range:<br>        gmm_model = GaussianMixture(n_components = n_components)<br>        gmm_model.fit(X)<br>        bic.append(gmm_model.bic(X))<br>        <span class="hljs-keyword">if</span> bic[-<span class="hljs-number">1</span>] &lt; lowest_bic:<br>            lowest_bic = bic[-<span class="hljs-number">1</span>]<br>    bic = np.array(bic)<br>    <span class="hljs-keyword">return</span> bic.argmin() + <span class="hljs-number">1</span><br><br><br><span class="hljs-comment"># ==== 代码9-1.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> mlxtend.frequent_patterns <span class="hljs-keyword">import</span> apriori<br><span class="hljs-keyword">from</span> mlxtend.preprocessing <span class="hljs-keyword">import</span> TransactionEncoder<br>itemSetList = [[<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;D&#x27;</span>],<br>            [<span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;E&#x27;</span>],<br>            [<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>,<span class="hljs-string">&#x27;E&#x27;</span>],<br>            [<span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;E&#x27;</span>]]<br><span class="hljs-comment">#数据预处理——编码</span><br>te = TransactionEncoder()<br>te_array = te.fit(itemSetList).transform(itemSetList)<br>df = pd.DataFrame(te_array, columns = te.columns_)<br><span class="hljs-comment">#挖掘频繁项集（最小支持度为0.5）</span><br>frequent_itemsets = apriori(df, min_support = <span class="hljs-number">0.5</span>, use_colnames = <span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;发现的频繁项集包括：\n&quot;</span>, frequent_itemsets)<br><br><br><span class="hljs-comment"># ==== 代码9-2.py ====</span><br><br><span class="hljs-keyword">from</span> mlxtend.frequent_patterns <span class="hljs-keyword">import</span> association_rules<br>rules = association_rules(frequent_itemsets, metric = <span class="hljs-string">&#x27;confidence&#x27;</span>, <br>                     min_threshold = <span class="hljs-number">0.5</span>, <br>                     support_only = <span class="hljs-literal">False</span>)<br>rules= rules[ rules[<span class="hljs-string">&#x27;lift&#x27;</span>]&gt;<span class="hljs-number">1</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;生成的强关联规则为：\n&quot;</span>, rules)<br><br><br><span class="hljs-comment"># ==== 代码9-3.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> mlxtend.preprocessing <span class="hljs-keyword">import</span> TransactionEncoder<br><span class="hljs-keyword">from</span> mlxtend.frequent_patterns <span class="hljs-keyword">import</span> fpgrowth, association_rules<br>itemSetList = [[<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;D&#x27;</span>],<br>            [<span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;E&#x27;</span>],<br>            [<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>,<span class="hljs-string">&#x27;E&#x27;</span>],<br>            [<span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;E&#x27;</span>]]<br><span class="hljs-comment">#数据预处理——编码</span><br>te = TransactionEncoder()<br>te_array = te.fit(itemSetList).transform(itemSetList)<br>df = pd.DataFrame(te_array, columns = te.columns_)<br><span class="hljs-comment">#利用FP-Growth算法发现频繁项集，最小支持度为0.5</span><br>frequent_itemsets = fpgrowth(df, min_support = <span class="hljs-number">0.5</span>, use_colnames = <span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;发现的频繁项集包括：\n&quot;</span>, frequent_itemsets)<br><span class="hljs-comment">#生成强规则(最小置信度为0.5, 提升度&gt;1)</span><br>rules = association_rules(frequent_itemsets, metric = <span class="hljs-string">&#x27;confidence&#x27;</span>, <br>                          min_threshold = <span class="hljs-number">0.5</span>, support_only = <span class="hljs-literal">False</span>)<br>rules= rules[ rules[<span class="hljs-string">&#x27;lift&#x27;</span>] &gt; <span class="hljs-number">1</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;生成的强关联规则为：\n&quot;</span>, rules)<br><br><br><span class="hljs-comment"># ==== 代码9-4.py ====</span><br><br><span class="hljs-comment">#Eclat类的定义</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Eclat</span>:   <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, min_support = <span class="hljs-number">3</span>, min_confidence = <span class="hljs-number">0.6</span>, min_lift = <span class="hljs-number">1</span></span>):<br>        self.min_support = min_support<br>        self.min_confidence = min_confidence<br>        self.min_lift = min_lift<br>    <span class="hljs-comment">#函数：倒排数据</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">invert</span>(<span class="hljs-params">self, data</span>):<br>        invert_data = &#123;&#125;<br>        fq_item = []<br>        sup = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(data)):<br>            <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> data[i]:<br>                <span class="hljs-keyword">if</span> invert_data.get(item) <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                    invert_data[item].append(i)<br>                <span class="hljs-keyword">else</span>:<br>                    invert_data[item] = [i]<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> invert_data.keys():<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(invert_data[item]) &gt;= self.min_support:<br>                fq_item.append([item])<br>                sup.append(invert_data[item])<br>        fq_item = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">frozenset</span>, fq_item))<br>        <span class="hljs-keyword">return</span> fq_item, sup<br>    <span class="hljs-comment">#函数：取交集</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">getIntersection</span>(<span class="hljs-params">self, fq_item, sup</span>):<br>        sub_fq_item = []<br>        sub_sup = []<br>        k = <span class="hljs-built_in">len</span>(fq_item[<span class="hljs-number">0</span>]) + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(fq_item)):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(i+<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(fq_item)):<br>                L1 = <span class="hljs-built_in">list</span>(fq_item[i])[: k-<span class="hljs-number">2</span>]<br>                L2 = <span class="hljs-built_in">list</span>(fq_item[j])[: k-<span class="hljs-number">2</span>]<br>                <span class="hljs-keyword">if</span> L1 == L2:<br>                    flag = <span class="hljs-built_in">len</span>(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(sup[i]).intersection(<span class="hljs-built_in">set</span>(sup[j]))))<br>                    <span class="hljs-keyword">if</span> flag &gt;= self.min_support:<br>                        sub_fq_item.append(fq_item[i] | fq_item[j])<br>                        sub_sup.append(<br><span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(sup[i]).intersection(<span class="hljs-built_in">set</span>(sup[j]))))<br>        <span class="hljs-keyword">return</span> sub_fq_item, sub_sup<br>    <span class="hljs-comment">#函数：获得频繁项</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">findFrequentItem</span>(<span class="hljs-params">self, fq_item, sup, fq_set,sup_set</span>):<br>        fq_set.append(fq_item)<br>        sup_set.append(sup)<br>        <span class="hljs-keyword">while</span> <span class="hljs-built_in">len</span>(fq_item) &gt;= <span class="hljs-number">2</span>:<br>            fq_item, sup = self.getIntersection(fq_item, sup)<br>            fq_set.append(fq_item)<br>            sup_set.append(sup)<br><span class="hljs-comment">#函数，生成关联规则</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">generateRules</span>(<span class="hljs-params">self, fq_set, rules, len_data</span>):<br>        <span class="hljs-keyword">for</span> fq_item <span class="hljs-keyword">in</span> fq_set:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(fq_item) &gt; <span class="hljs-number">1</span>:<br>                self.getRules(fq_item, fq_item, fq_set, rules, len_data)<br>    <span class="hljs-comment">#辅助函数，删除项目</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">removeItem</span>(<span class="hljs-params">self, current_item, item</span>):<br>        tempSet = []<br>        <span class="hljs-keyword">for</span> elem <span class="hljs-keyword">in</span> current_item:<br>            <span class="hljs-keyword">if</span> elem != item:<br>                tempSet.append(elem)<br>        tempFrozenSet = <span class="hljs-built_in">frozenset</span>(tempSet)<br>        <span class="hljs-keyword">return</span> tempFrozenSet<br>    <span class="hljs-comment">#辅助函数：生成关联规则</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">getRules</span>(<span class="hljs-params">self, fq_item, cur_item, fq_set, rules,len_data</span>):<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> cur_item:<br>            subset = self.removeItem(cur_item, item)<br>            confidence = fq_set[fq_item] / fq_set[subset]<br>            supp = fq_set[fq_item] / len_data<br>            lift = confidence / (fq_set[fq_item - subset] / len_data)<br>            <span class="hljs-keyword">if</span> confidence &gt;= self.min_confidence <span class="hljs-keyword">and</span> lift &gt; self.min_lift:<br>                flag = <span class="hljs-literal">False</span><br>                <span class="hljs-keyword">for</span> rule <span class="hljs-keyword">in</span> rules:<br>                    <span class="hljs-keyword">if</span> (rule[<span class="hljs-number">0</span>] == subset) <span class="hljs-keyword">and</span> (rule[<span class="hljs-number">1</span>] == fq_item-subset):<br>                        flag = <span class="hljs-literal">True</span><br>                <span class="hljs-keyword">if</span> flag == <span class="hljs-literal">False</span>:<br>                    rules.append((<span class="hljs-string">&quot;%s --&gt; %s,support=%5.3f, confidence=%5.3f,  lift = %5.3f&quot;</span>%(<span class="hljs-built_in">list</span>(subset), <span class="hljs-built_in">list</span>(fq_item - subset),<br>                          supp, confidence, lift)))<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(subset) &gt;= <span class="hljs-number">2</span>:<br>                    self.getRules(fq_item, subset, fq_set, rules, len_data)<br>    <span class="hljs-comment">#函数：Eclat模型训练</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, data, display = <span class="hljs-literal">True</span></span>):<br>        frequent_item, support = self.invert(data)<br>        frequent_set = []<br>        support_set = []<br>        len_data= <span class="hljs-built_in">len</span>(data)<br>        self.findFrequentItem(frequent_item, support, frequent_set, support_set)<br>        data = &#123;&#125;<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(frequent_set)):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(frequent_set[i])):<br>                data[frequent_set[i][j]] = <span class="hljs-built_in">len</span>(support_set[i][j])<br>        rules = []<br>        self.generateRules(data, rules, len_data)<br>        <span class="hljs-keyword">if</span> display:     <br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Association Rules:&quot;</span>)<br>            <span class="hljs-keyword">for</span> rule <span class="hljs-keyword">in</span> rules:<br>                <span class="hljs-built_in">print</span>(rule)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;发现的规则数量：&quot;</span>, <span class="hljs-built_in">len</span>(rules))<br>        <span class="hljs-keyword">return</span> frequent_set, rules<br><span class="hljs-comment">#用Eclat类创建一个关联规则模型，训练后生成关联规则</span><br>itemSetList = [[<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;D&#x27;</span>],<br>            [<span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;E&#x27;</span>],<br>            [<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>,<span class="hljs-string">&#x27;E&#x27;</span>],<br>            [<span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;E&#x27;</span>]]<br>et = Eclat(min_support = <span class="hljs-number">2</span>, min_confidence = <span class="hljs-number">0.5</span>, min_lift = <span class="hljs-number">1</span>)<br>et.fit(itemSetList, <span class="hljs-literal">True</span>)<br><br><br><span class="hljs-comment"># ==== 代码9-5.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> mlxtend.frequent_patterns <span class="hljs-keyword">import</span> apriori, association_rules<br>inputfile = <span class="hljs-string">&#x27;Online_Retail.xlsx&#x27;</span>          <span class="hljs-comment"># 输入的数据文件</span><br>data = pd.read_excel(inputfile)<br><span class="hljs-comment">#步骤1：数据探索</span><br>data.info()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;不同的国家名称:\n&quot;</span>, data.Country.unique())<br><span class="hljs-comment">#步骤2：预处理</span><br>data[<span class="hljs-string">&#x27;Description&#x27;</span>] = data[<span class="hljs-string">&#x27;Description&#x27;</span>].<span class="hljs-built_in">str</span>.strip()             <span class="hljs-comment">#去除空格</span><br>data.dropna(axis = <span class="hljs-number">0</span>,subset = [<span class="hljs-string">&#x27;CustomerID&#x27;</span>], inplace = <span class="hljs-literal">True</span>)   <span class="hljs-comment">#删除含缺失值的行</span><br>data[<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>] = data[<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>].astype(<span class="hljs-string">&#x27;str&#x27;</span>)<br>data = data[~data[<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>].<span class="hljs-built_in">str</span>.contains(<span class="hljs-string">&#x27;C&#x27;</span>)]              <span class="hljs-comment">#删除所有已取消交易</span><br><span class="hljs-comment">#步骤3:数据分割和转换</span><br>basket_France = (data[data[<span class="hljs-string">&#x27;Country&#x27;</span>] == <span class="hljs-string">&quot;France&quot;</span>]<br>          .groupby([<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>, <span class="hljs-string">&#x27;Description&#x27;</span>])[<span class="hljs-string">&#x27;Quantity&#x27;</span>]<br>          .<span class="hljs-built_in">sum</span>().unstack().reset_index().fillna(<span class="hljs-number">0</span>)<br>          .set_index(<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>))<br>basket_Por = (data[data[<span class="hljs-string">&#x27;Country&#x27;</span>] == <span class="hljs-string">&quot;Portugal&quot;</span>]<br>          .groupby([<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>, <span class="hljs-string">&#x27;Description&#x27;</span>])[<span class="hljs-string">&#x27;Quantity&#x27;</span>]<br>          .<span class="hljs-built_in">sum</span>().unstack().reset_index().fillna(<span class="hljs-number">0</span>)<br>          .set_index(<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>))<br>basket_Sweden = (data[data[<span class="hljs-string">&#x27;Country&#x27;</span>] == <span class="hljs-string">&quot;Sweden&quot;</span>]<br>          .groupby([<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>, <span class="hljs-string">&#x27;Description&#x27;</span>])[<span class="hljs-string">&#x27;Quantity&#x27;</span>]<br>          .<span class="hljs-built_in">sum</span>().unstack().reset_index().fillna(<span class="hljs-number">0</span>)<br>          .set_index(<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>))<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">hot_encode</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">if</span>(x&lt;= <span class="hljs-number">0</span>):  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>    <span class="hljs-keyword">if</span>(x&gt;= <span class="hljs-number">1</span>):  <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>basket_France = basket_France.applymap(hot_encode)       <span class="hljs-comment">#0/1编码数据</span><br>basket_Por = basket_Por.applymap(hot_encode)<br>basket_Sweden = basket_Sweden.applymap(hot_encode)<br><br><br><span class="hljs-comment"># ==== 代码9-6.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> mlxtend.frequent_patterns <span class="hljs-keyword">import</span> apriori, association_rules<br>inputfile = <span class="hljs-string">&#x27;./Online_Retail.xlsx&#x27;</span>   <span class="hljs-comment"># 输入的数据文件</span><br>data = pd.read_excel(inputfile)<br><span class="hljs-comment">#步骤1：数据探索</span><br>data.info()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;不同的国家名称:\n&quot;</span>, data.Country.unique())<br><span class="hljs-comment">#步骤2：预处理</span><br>data[<span class="hljs-string">&#x27;Description&#x27;</span>] = data[<span class="hljs-string">&#x27;Description&#x27;</span>].<span class="hljs-built_in">str</span>.strip() <span class="hljs-comment">#去除空格</span><br>data.dropna(axis = <span class="hljs-number">0</span>,subset =[<span class="hljs-string">&#x27;CustomerID&#x27;</span>],inplace = <span class="hljs-literal">True</span>) <span class="hljs-comment">#删除含缺失值的行</span><br>data[<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>] = data[<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>].astype(<span class="hljs-string">&#x27;str&#x27;</span>)<br>data = data[~data[<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>].<span class="hljs-built_in">str</span>.contains(<span class="hljs-string">&#x27;C&#x27;</span>)]   <span class="hljs-comment">#删除所有已取消交易</span><br><span class="hljs-built_in">print</span>(data.head(<span class="hljs-number">5</span>))<br><span class="hljs-comment">#步骤3:数据分割和转换</span><br>basket_France = (data[data[<span class="hljs-string">&#x27;Country&#x27;</span>] ==<span class="hljs-string">&quot;France&quot;</span>]<br>          .groupby([<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>, <span class="hljs-string">&#x27;Description&#x27;</span>])[<span class="hljs-string">&#x27;Quantity&#x27;</span>]<br>          .<span class="hljs-built_in">sum</span>().unstack().reset_index().fillna(<span class="hljs-number">0</span>)<br>          .set_index(<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>))<br>basket_Por = (data[data[<span class="hljs-string">&#x27;Country&#x27;</span>] ==<span class="hljs-string">&quot;Portugal&quot;</span>]<br>          .groupby([<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>, <span class="hljs-string">&#x27;Description&#x27;</span>])[<span class="hljs-string">&#x27;Quantity&#x27;</span>]<br>          .<span class="hljs-built_in">sum</span>().unstack().reset_index().fillna(<span class="hljs-number">0</span>)<br>          .set_index(<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>))<br>basket_Sweden = (data[data[<span class="hljs-string">&#x27;Country&#x27;</span>] ==<span class="hljs-string">&quot;Sweden&quot;</span>]<br>          .groupby([<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>, <span class="hljs-string">&#x27;Description&#x27;</span>])[<span class="hljs-string">&#x27;Quantity&#x27;</span>]<br>          .<span class="hljs-built_in">sum</span>().unstack().reset_index().fillna(<span class="hljs-number">0</span>)<br>          .set_index(<span class="hljs-string">&#x27;InvoiceNo&#x27;</span>))<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">hot_encode</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">if</span>(x&lt;= <span class="hljs-number">0</span>):  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>    <span class="hljs-keyword">if</span>(x&gt;= <span class="hljs-number">1</span>):  <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>basket_France = basket_France.applymap(hot_encode)   <span class="hljs-comment">#0/1编码数据</span><br>basket_Por = basket_Por.applymap(hot_encode)<br>basket_Sweden = basket_Sweden.applymap(hot_encode)<br><span class="hljs-comment"># (1)法国数据集的关联规则挖掘</span><br>frq_items = apriori(basket_France, min_support = <span class="hljs-number">0.1</span>, use_colnames = <span class="hljs-literal">True</span>)<br>rules =association_rules(frq_items, metric =<span class="hljs-string">&quot;confidence&quot;</span>, min_threshold= <span class="hljs-number">0.3</span>)<br>rules= rules[ rules[<span class="hljs-string">&#x27;lift&#x27;</span>]&gt;=<span class="hljs-number">1.5</span>]            <span class="hljs-comment">#设置最小提升度</span><br>rules = rules.sort_values([<span class="hljs-string">&#x27;confidence&#x27;</span>, <span class="hljs-string">&#x27;lift&#x27;</span>], ascending =[<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>])<br><span class="hljs-built_in">print</span>(rules.head())                                 <span class="hljs-comment">#显示前5条强关联规则</span><br><span class="hljs-comment">#（2）葡萄牙数据集的关联规则挖掘</span><br>frq_items = apriori(basket_Por, min_support = <span class="hljs-number">0.1</span>, use_colnames = <span class="hljs-literal">True</span>)<br>rules =association_rules(frq_items, metric =<span class="hljs-string">&quot;confidence&quot;</span>, min_threshold= <span class="hljs-number">0.3</span>)<br>rules= rules[ rules[<span class="hljs-string">&#x27;lift&#x27;</span>]&gt;=<span class="hljs-number">1.5</span>]            <span class="hljs-comment">#设置最小提升度</span><br>rules = rules.sort_values([<span class="hljs-string">&#x27;confidence&#x27;</span>, <span class="hljs-string">&#x27;lift&#x27;</span>], ascending =[<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>])<br><span class="hljs-built_in">print</span>(rules.head())                                 <span class="hljs-comment">#显示前5条强关联规则</span><br><span class="hljs-comment">#（3） 瑞典数据集的关联规则挖掘</span><br>frq_items = apriori(basket_Sweden, min_support = <span class="hljs-number">0.05</span>, use_colnames = <span class="hljs-literal">True</span>)<br>rules =association_rules(frq_items, metric =<span class="hljs-string">&quot;confidence&quot;</span>, min_threshold= <span class="hljs-number">0.3</span>)<br>rules= rules[ rules[<span class="hljs-string">&#x27;lift&#x27;</span>]&gt;=<span class="hljs-number">1.5</span>]            <span class="hljs-comment">#设置最小提升度</span><br>rules = rules.sort_values([<span class="hljs-string">&#x27;confidence&#x27;</span>, <span class="hljs-string">&#x27;lift&#x27;</span>], ascending =[<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>])<br><span class="hljs-built_in">print</span>(rules.head())                                 <span class="hljs-comment">#显示前5条强关联规则</span><br><br><br><br><span class="hljs-comment"># ==== 代码10-1.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> pandas <span class="hljs-keyword">import</span> datetime<br>file = <span class="hljs-string">&#x27;./data/shampoo.csv&#x27;</span>          <span class="hljs-comment">#该数据放置在data文件夹下，读者可以自行定义</span><br><span class="hljs-comment">#函数：日期数据解析</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">date_parser</span> (x):<br>    <span class="hljs-keyword">return</span> datetime.strptime(<span class="hljs-string">&#x27;190&#x27;</span>+x, <span class="hljs-string">&#x27;%Y-%m&#x27;</span>)<br>data = pd.read_csv(file, header = <span class="hljs-number">0</span>, parse_dates = [<span class="hljs-number">0</span>], index_col = <span class="hljs-number">0</span>, squeeze = <span class="hljs-literal">True</span>, <br>date_parser = date_parser)<br><br><br><span class="hljs-comment"># ==== 代码10-2.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> pandas <span class="hljs-keyword">import</span> datetime<br>file = <span class="hljs-string">&#x27;./data/shampoo.csv&#x27;</span>          <span class="hljs-comment">#该数据放置在data文件夹下，读者可以自行定义</span><br><span class="hljs-comment">#函数：日期数据解析</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">date_parser</span> (x):<br>    <span class="hljs-keyword">return</span> datetime.strptime(<span class="hljs-string">&#x27;190&#x27;</span>+x, <span class="hljs-string">&#x27;%Y-%m&#x27;</span>)<br>data = pd.read_csv(file, header = <span class="hljs-number">0</span>, parse_dates = [<span class="hljs-number">0</span>], index_col = <span class="hljs-number">0</span>, squeeze = <span class="hljs-literal">True</span>, <br>date_parser = date_parser)<br><span class="hljs-comment"># 时序图</span><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]     <span class="hljs-comment"># 用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span>    <span class="hljs-comment"># 用来正常显示负号</span><br>plt.plot(data)<br>plt.legend()<br>plt.show()<br><span class="hljs-comment"># 自相关图</span><br><span class="hljs-keyword">from</span> statsmodels.graphics.tsaplots <span class="hljs-keyword">import</span> plot_acf<br>plot_acf(data).show()<br>plt.show()<br><span class="hljs-comment"># ADF单位根检测方法</span><br><span class="hljs-keyword">from</span> statsmodels.tsa.stattools <span class="hljs-keyword">import</span> adfuller <span class="hljs-keyword">as</span> ADF<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;原始序列的ADF检验结果为：&#x27;</span>, ADF(data))      <span class="hljs-comment"># 返回值依次为adf、p值等</span><br><br><br><span class="hljs-comment"># ==== 代码10-3.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> pandas <span class="hljs-keyword">import</span> datetime<br>file = <span class="hljs-string">&#x27;./data/shampoo.csv&#x27;</span>          <span class="hljs-comment">#该数据放置在data文件夹下，读者可以自行定义</span><br><span class="hljs-comment">#函数：日期数据解析</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">date_parser</span> (x):<br>    <span class="hljs-keyword">return</span> datetime.strptime(<span class="hljs-string">&#x27;190&#x27;</span>+x, <span class="hljs-string">&#x27;%Y-%m&#x27;</span>)<br>data = pd.read_csv(file, header = <span class="hljs-number">0</span>, parse_dates = [<span class="hljs-number">0</span>], index_col = <span class="hljs-number">0</span>, squeeze = <span class="hljs-literal">True</span>, <br>date_parser = date_parser)<br><span class="hljs-comment"># 时序图</span><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]     <span class="hljs-comment"># 用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span>    <span class="hljs-comment"># 用来正常显示负号</span><br>plt.plot(data)<br>plt.legend()<br>plt.show()<br><span class="hljs-comment"># 自相关图</span><br><span class="hljs-keyword">from</span> statsmodels.graphics.tsaplots <span class="hljs-keyword">import</span> plot_acf<br>plot_acf(data).show()<br>plt.show()<br><span class="hljs-comment"># ADF单位根检测方法</span><br><span class="hljs-keyword">from</span> statsmodels.tsa.stattools <span class="hljs-keyword">import</span> adfuller <span class="hljs-keyword">as</span> ADF<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;原始序列的ADF检验结果为：&#x27;</span>, ADF(data))      <span class="hljs-comment"># 返回值依次为adf、p值等</span><br><span class="hljs-comment"># 差分操作</span><br>Date_data = data.diff().dropna()<br>plt.plot(Date_data)               <span class="hljs-comment"># 差分序列的时序图</span><br>plt.show()<br><span class="hljs-comment">#差分序列的平稳性检验</span><br>plot_acf(Date_data).show()       <span class="hljs-comment"># 自相关图</span><br><span class="hljs-keyword">from</span> statsmodels.graphics.tsaplots <span class="hljs-keyword">import</span> plot_pacf<br>plot_pacf(Date_data).show()     <span class="hljs-comment"># 偏自相关图</span><br>plt.show()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;差分序列的ADF检验结果为：&#x27;</span>, ADF(Date_data))     <span class="hljs-comment">#ADF单位根检测方法</span><br><br><br><span class="hljs-comment"># ==== 代码10-4.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> pandas <span class="hljs-keyword">import</span> datetime<br>file = <span class="hljs-string">&#x27;./data/shampoo.csv&#x27;</span>          <span class="hljs-comment">#该数据放置在data文件夹下，读者可以自行定义</span><br><span class="hljs-comment">#函数：日期数据解析</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">date_parser</span> (x):<br>    <span class="hljs-keyword">return</span> datetime.strptime(<span class="hljs-string">&#x27;190&#x27;</span>+x, <span class="hljs-string">&#x27;%Y-%m&#x27;</span>)<br>data = pd.read_csv(file, header = <span class="hljs-number">0</span>, parse_dates = [<span class="hljs-number">0</span>], index_col = <span class="hljs-number">0</span>, squeeze = <span class="hljs-literal">True</span>, <br>date_parser = date_parser)<br><span class="hljs-comment"># 时序图</span><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]     <span class="hljs-comment"># 用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span>    <span class="hljs-comment"># 用来正常显示负号</span><br>plt.plot(data)<br>plt.legend()<br>plt.show()<br><span class="hljs-comment"># 自相关图</span><br><span class="hljs-keyword">from</span> statsmodels.graphics.tsaplots <span class="hljs-keyword">import</span> plot_acf<br>plot_acf(data).show()<br>plt.show()<br><span class="hljs-comment"># ADF单位根检测方法</span><br><span class="hljs-keyword">from</span> statsmodels.tsa.stattools <span class="hljs-keyword">import</span> adfuller <span class="hljs-keyword">as</span> ADF<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;原始序列的ADF检验结果为：&#x27;</span>, ADF(data))      <span class="hljs-comment"># 返回值依次为adf、p值等</span><br><span class="hljs-comment"># 差分操作</span><br>Date_data = data.diff().dropna()<br>plt.plot(Date_data)               <span class="hljs-comment"># 差分序列的时序图</span><br>plt.show()<br><span class="hljs-comment">#差分序列的平稳性检验</span><br>plot_acf(Date_data).show()       <span class="hljs-comment"># 自相关图</span><br><span class="hljs-keyword">from</span> statsmodels.graphics.tsaplots <span class="hljs-keyword">import</span> plot_pacf<br>plot_pacf(Date_data).show()     <span class="hljs-comment"># 偏自相关图</span><br>plt.show()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;差分序列的ADF检验结果为：&#x27;</span>, ADF(Date_data))     <span class="hljs-comment">#ADF单位根检测方法</span><br><span class="hljs-comment"># 纯随机性检验</span><br><span class="hljs-keyword">from</span> statsmodels.stats.diagnostic <span class="hljs-keyword">import</span> acorr_ljungbox<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;差分序列的白噪声检验结果为：&#x27;</span>, acorr_ljungbox(Date_data, lags = <span class="hljs-number">1</span>))  <br><span class="hljs-comment"># 分别返回LB统计量和p值</span><br><br><br><span class="hljs-comment"># ==== 代码10-5.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> pandas <span class="hljs-keyword">import</span> datetime<br>file = <span class="hljs-string">&#x27;./data/shampoo.csv&#x27;</span>          <span class="hljs-comment">#该数据放置在data文件夹下，读者可以自行定义</span><br><span class="hljs-comment">#函数：日期数据解析</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">date_parser</span> (x):<br>    <span class="hljs-keyword">return</span> datetime.strptime(<span class="hljs-string">&#x27;190&#x27;</span>+x, <span class="hljs-string">&#x27;%Y-%m&#x27;</span>)<br>data = pd.read_csv(file, header = <span class="hljs-number">0</span>, parse_dates = [<span class="hljs-number">0</span>], index_col = <span class="hljs-number">0</span>, squeeze = <span class="hljs-literal">True</span>, <br>date_parser = date_parser)<br><span class="hljs-comment"># 时序图</span><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]     <span class="hljs-comment"># 用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span>    <span class="hljs-comment"># 用来正常显示负号</span><br>plt.plot(data)<br>plt.legend()<br>plt.show()<br><span class="hljs-comment"># 自相关图</span><br><span class="hljs-keyword">from</span> statsmodels.graphics.tsaplots <span class="hljs-keyword">import</span> plot_acf<br>plot_acf(data).show()<br>plt.show()<br><span class="hljs-comment"># ADF单位根检测方法</span><br><span class="hljs-keyword">from</span> statsmodels.tsa.stattools <span class="hljs-keyword">import</span> adfuller <span class="hljs-keyword">as</span> ADF<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;原始序列的ADF检验结果为：&#x27;</span>, ADF(data))      <span class="hljs-comment"># 返回值依次为adf、p值等</span><br><span class="hljs-comment"># 差分操作</span><br>Date_data = data.diff().dropna()<br>plt.plot(Date_data)               <span class="hljs-comment"># 差分序列的时序图</span><br>plt.show()<br><span class="hljs-comment">#差分序列的平稳性检验</span><br>plot_acf(Date_data).show()       <span class="hljs-comment"># 自相关图</span><br><span class="hljs-keyword">from</span> statsmodels.graphics.tsaplots <span class="hljs-keyword">import</span> plot_pacf<br>plot_pacf(Date_data).show()     <span class="hljs-comment"># 偏自相关图</span><br>plt.show()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;差分序列的ADF检验结果为：&#x27;</span>, ADF(Date_data))     <span class="hljs-comment">#ADF单位根检测方法</span><br><span class="hljs-comment"># 纯随机性检验</span><br><span class="hljs-keyword">from</span> statsmodels.stats.diagnostic <span class="hljs-keyword">import</span> acorr_ljungbox<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;差分序列的白噪声检验结果为：&#x27;</span>, acorr_ljungbox(Date_data, lags = <span class="hljs-number">1</span>))  <br><span class="hljs-comment"># 分别返回LB统计量和p值</span><br><span class="hljs-comment"># 模型定阶：相对最优模型法</span><br><span class="hljs-comment">#from statsmodels.tsa.arima.model import ARIMA</span><br><span class="hljs-keyword">from</span> statsmodels.tsa.arima_model <span class="hljs-keyword">import</span> ARIMA<br>data = data.astype(<span class="hljs-built_in">float</span>)<br>pmax = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">len</span>(Date_data) /<span class="hljs-number">10</span>)     <span class="hljs-comment"># 阶数p不超过序列长度的1/10</span><br>qmax = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">len</span>(Date_data) /<span class="hljs-number">10</span>)     <span class="hljs-comment"># 阶数q不超过序列长度的1/10</span><br>bic_matrix = []                  <span class="hljs-comment"># BIC矩阵</span><br><span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(pmax + <span class="hljs-number">1</span>):<br>  tmp = []<br>  <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(qmax + <span class="hljs-number">1</span>):<br>    <span class="hljs-keyword">try</span>:                       <span class="hljs-comment"># 错误处理块</span><br>      tmp.append(ARIMA(data.values, order=(x,<span class="hljs-number">1</span>,y)).fit().bic)<br>    <span class="hljs-keyword">except</span>:<br>      tmp.append(<span class="hljs-literal">None</span>)<br>  bic_matrix.append(tmp)<br>bic_matrix = pd.DataFrame(bic_matrix) <br><span class="hljs-built_in">print</span>(bic_matrix)<br>p,q = bic_matrix.stack().idxmin()      <span class="hljs-comment">#找出最小值位置</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;BIC最小的p值和q值为：%s、%s&#x27;</span> % (p,q))<br><br><br><span class="hljs-comment"># ==== 代码11-1.py ====</span><br><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.datasets._samples_generator <span class="hljs-keyword">import</span>  make_blobs<br><span class="hljs-comment">#函数：生成数据集</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_data</span>(<span class="hljs-params">n_normal = <span class="hljs-number">500</span>, n_anomaly = <span class="hljs-number">20</span></span>):<br>    X_normal, Y_normal = make_blobs(n_samples = n_normal, centers = [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]],<br>                                    cluster_std = <span class="hljs-number">0.8</span>, random_state = <span class="hljs-number">5</span>)  <br>    X_anomaly = np.random.rand(n_anomaly, <span class="hljs-number">2</span>) * <span class="hljs-number">10</span> - <span class="hljs-number">5</span><br>    Y_anomaly = np.zeros(n_anomaly)<br>    X = np.vstack([X_normal, X_anomaly])<br>    Y = np.hstack([Y_normal, [<span class="hljs-number">1</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(X_anomaly.shape[<span class="hljs-number">0</span>])]])<br>    <span class="hljs-keyword">return</span> X, Y<br><span class="hljs-comment">#函数：计算数据在正态分布上的概率值</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">multivariate_Gaussian</span>(<span class="hljs-params">X, mu, sigma</span>):<br>    d = <span class="hljs-built_in">len</span>(mu)                      <span class="hljs-comment">#特征维度</span><br>    X -= mu.T<br>    cov_mat_inv = np.linalg.pinv(sigma)<br>    cov_mat_det = np.linalg.det(sigma)<br>    p = (np.exp(-<span class="hljs-number">0.5</span> * np.dot(X, np.dot(cov_mat_inv, X.T)))<br>        / (<span class="hljs-number">2.</span> * np.pi) ** (d/<span class="hljs-number">2.</span>) / np.sqrt(cov_mat_det))<br>    <span class="hljs-keyword">return</span> p<br><span class="hljs-comment">#获得人工合成数据集</span><br>X, Y = generate_data()<br><span class="hljs-comment">#计算均值和协方差，设置全局阈值（经验给定）</span><br>mu = X.mean(axis = <span class="hljs-number">0</span>)<br>sigma = np.cov(X.T)<br>threshold = <span class="hljs-number">0.0025</span><br><span class="hljs-comment">#计算每个训练样本的概率</span><br>pro = []<br><span class="hljs-keyword">for</span> i, _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(X):<br>    p = multivariate_Gaussian(X[i], mu, sigma)<br>    pro += [p]<br>pro = np.array(pro)<br><span class="hljs-comment">#识别异常对象，并绘图显示</span><br>anomaly_index = (pro &lt;= threshold)<br>plt.figure(figsize = (<span class="hljs-number">6</span>, <span class="hljs-number">4</span>))<br>predict_anomaly = X[anomaly_index]<br>predict_normal = X[~anomaly_index]<br>plt.scatter(predict_normal[:, <span class="hljs-number">0</span>], predict_normal[:, <span class="hljs-number">1</span>],<br>            s = <span class="hljs-number">60</span>, marker = <span class="hljs-string">&#x27;o&#x27;</span>, alpha = <span class="hljs-number">0.6</span>)<br>plt.scatter(predict_anomaly[:, <span class="hljs-number">0</span>], predict_anomaly[:, <span class="hljs-number">1</span>], <br>            s = <span class="hljs-number">60</span>, marker = <span class="hljs-string">&#x27;x&#x27;</span>, c = <span class="hljs-string">&#x27;r&#x27;</span>)<br>plt.grid(<span class="hljs-literal">True</span>, which = <span class="hljs-string">&#x27;major&#x27;</span>, linestyle = <span class="hljs-string">&#x27;--&#x27;</span>, linewidth = <span class="hljs-number">1</span>)<br>plt.show()<br><br><br><span class="hljs-comment"># ==== 代码11-2.py ====</span><br><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.datasets._samples_generator <span class="hljs-keyword">import</span>  make_blobs<br><span class="hljs-comment">#函数：生成数据集</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_data</span>(<span class="hljs-params">n_normal = <span class="hljs-number">500</span>, n_anomaly = <span class="hljs-number">20</span></span>):<br>    X_normal, Y_normal = make_blobs(n_samples = n_normal, centers = [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]],<br>                                    cluster_std = <span class="hljs-number">0.8</span>, random_state = <span class="hljs-number">5</span>)  <br>    X_anomaly = np.random.rand(n_anomaly, <span class="hljs-number">2</span>) * <span class="hljs-number">10</span> - <span class="hljs-number">5</span><br>    Y_anomaly = np.zeros(n_anomaly)<br>    X = np.vstack([X_normal, X_anomaly])<br>    Y = np.hstack([Y_normal, [<span class="hljs-number">1</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(X_anomaly.shape[<span class="hljs-number">0</span>])]])<br>    <span class="hljs-keyword">return</span> X, Y<br><span class="hljs-comment">#函数：计算数据在正态分布上的概率值</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">multivariate_Gaussian</span>(<span class="hljs-params">X, mu, sigma</span>):<br>    d = <span class="hljs-built_in">len</span>(mu)                      <span class="hljs-comment">#特征维度</span><br>    X -= mu.T<br>    cov_mat_inv = np.linalg.pinv(sigma)<br>    cov_mat_det = np.linalg.det(sigma)<br>    p = (np.exp(-<span class="hljs-number">0.5</span> * np.dot(X, np.dot(cov_mat_inv, X.T)))<br>        / (<span class="hljs-number">2.</span> * np.pi) ** (d/<span class="hljs-number">2.</span>) / np.sqrt(cov_mat_det))<br>    <span class="hljs-keyword">return</span> p<br><span class="hljs-comment">#获得人工合成数据集</span><br>X, Y = generate_data()<br><span class="hljs-comment">#计算均值和协方差，设置全局阈值（经验给定）</span><br>mu = X.mean(axis = <span class="hljs-number">0</span>)<br>sigma = np.cov(X.T)<br>threshold = <span class="hljs-number">0.0025</span><br><span class="hljs-comment">#计算每个训练样本的概率</span><br>pro = []<br><span class="hljs-keyword">for</span> i, _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(X):<br>    p = multivariate_Gaussian(X[i], mu, sigma)<br>    pro += [p]<br>pro = np.array(pro)<br><span class="hljs-comment">#识别异常对象，并绘图显示</span><br>anomaly_index = (pro &lt;= threshold)<br>plt.figure(figsize = (<span class="hljs-number">6</span>, <span class="hljs-number">4</span>))<br>predict_anomaly = X[anomaly_index]<br>predict_normal = X[~anomaly_index]<br>plt.scatter(predict_normal[:, <span class="hljs-number">0</span>], predict_normal[:, <span class="hljs-number">1</span>],<br>            s = <span class="hljs-number">60</span>, marker = <span class="hljs-string">&#x27;o&#x27;</span>, alpha = <span class="hljs-number">0.6</span>)<br>plt.scatter(predict_anomaly[:, <span class="hljs-number">0</span>], predict_anomaly[:, <span class="hljs-number">1</span>], <br>            s = <span class="hljs-number">60</span>, marker = <span class="hljs-string">&#x27;x&#x27;</span>, c = <span class="hljs-string">&#x27;r&#x27;</span>)<br>plt.grid(<span class="hljs-literal">True</span>, which = <span class="hljs-string">&#x27;major&#x27;</span>, linestyle = <span class="hljs-string">&#x27;--&#x27;</span>, linewidth = <span class="hljs-number">1</span>)<br>plt.show()<br><span class="hljs-keyword">from</span> sklearn.cluster <span class="hljs-keyword">import</span> DBSCAN<br>model = DBSCAN(eps = <span class="hljs-number">0.4</span>, min_samples = <span class="hljs-number">4</span>)     <span class="hljs-comment"># DBSCAN聚类建模</span><br><span class="hljs-comment"># 根据DBSCAN的聚类结果识别异常点（DBSCAN将-1类作为异常点的）</span><br>Y_pred = model.fit_predict(X)<br>anomaly_index = (Y_pred == -<span class="hljs-number">1</span>)<br>X_anomaly = X[anomaly_index]<br>X_normal = X[~anomaly_index]<br><span class="hljs-comment">#绘图</span><br>plt.figure(figsize = (<span class="hljs-number">6</span>, <span class="hljs-number">4</span>))<br>plt.scatter(X_normal[:, <span class="hljs-number">0</span>], X_normal[:, <span class="hljs-number">1</span>],  s=<span class="hljs-number">60</span>, marker = <span class="hljs-string">&#x27;o&#x27;</span>, alpha = <span class="hljs-number">0.6</span>)<br>plt.scatter(X_anomaly[:, <span class="hljs-number">0</span>], X_anomaly[:, <span class="hljs-number">1</span>],  s = <span class="hljs-number">60</span>, marker = <span class="hljs-string">&#x27;x&#x27;</span>, c = <span class="hljs-string">&#x27;r&#x27;</span>)<br>plt.grid(<span class="hljs-literal">True</span>, which = <span class="hljs-string">&#x27;major&#x27;</span>, linestyle = <span class="hljs-string">&#x27;--&#x27;</span>, linewidth = <span class="hljs-number">1</span>)<br>plt.show()<br><br><br><span class="hljs-comment"># ==== 代码11-3.py ====</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>data = pd.read_csv(<span class="hljs-string">&#x27;./creditcard.csv&#x27;</span>,encoding=<span class="hljs-string">&#x27;gbk&#x27;</span>)<br><span class="hljs-comment"># 绘制柱状图，查看两个类别的数量</span><br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]<br>count_classes = pd.value_counts(data[<span class="hljs-string">&#x27;Class&#x27;</span>], sort = <span class="hljs-literal">False</span>)<br>plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">8</span>))<br>plt.bar([<span class="hljs-number">0</span>,<span class="hljs-number">1</span>], count_classes, width=<span class="hljs-number">0.6</span>)<br>plt.xticks([<span class="hljs-number">0</span>,<span class="hljs-number">1</span>], [<span class="hljs-string">&#x27;0&#x27;</span>,<span class="hljs-string">&#x27;1&#x27;</span>], fontsize=<span class="hljs-number">20</span>)<br>plt.yticks(fontsize=<span class="hljs-number">20</span>)<br>plt.title (<span class="hljs-string">&quot;不同类别的数量&quot;</span>,fontsize=<span class="hljs-number">20</span>)<br>plt.xlabel (<span class="hljs-string">&quot;Class&quot;</span>,fontsize=<span class="hljs-number">20</span>)<br>plt.ylabel (<span class="hljs-string">&quot;Frequency&quot;</span>,fontsize=<span class="hljs-number">20</span>)<br>plt.show()<br><span class="hljs-comment">#查看是否有缺失值</span><br><span class="hljs-built_in">print</span>(data.isnull().<span class="hljs-built_in">sum</span>())<br><span class="hljs-comment">#查看数据的描述性统计信息</span><br><span class="hljs-built_in">print</span>(data.describe())<br><br><br><span class="hljs-comment"># ==== 代码11-4.py ====</span><br><br><span class="hljs-keyword">from</span> pyod.models.iforest <span class="hljs-keyword">import</span> IForest  <span class="hljs-comment">#孤立森林</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-comment">#划分训练集和测试</span><br>X = data.iloc[:, data.columns != <span class="hljs-string">&#x27;Class&#x27;</span>]<br>y = data.iloc[:, data.columns == <span class="hljs-string">&#x27;Class&#x27;</span>]<br>X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = <span class="hljs-number">0.3</span>, <br>random_state= <span class="hljs-number">123456</span>, stratify = y)<br><span class="hljs-comment">#创建IForest模型</span><br>iforest = IForest(n_estimators = <span class="hljs-number">300</span>, contamination = <span class="hljs-number">0.00172</span>)<br>iforest.fit(X_train)<br><span class="hljs-comment"># 得到测试结果</span><br>y_test_pred = iforest.predict(X_test)            <span class="hljs-comment"># 预测的类别标签</span><br>y_test_scores = iforest.decision_function(X_test)  <span class="hljs-comment">#预测的属于异常的概率</span><br><span class="hljs-comment"># 混淆矩阵绘图函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_confusion_matrix</span>(<span class="hljs-params">cm, title = <span class="hljs-string">&quot;Confusion Matrix&quot;</span></span>):<br>    sns.<span class="hljs-built_in">set</span>()<br>    f,ax=plt.subplots()<br>    sns.heatmap(cm, annot = <span class="hljs-literal">True</span>, ax = ax, cmap = <span class="hljs-string">&quot;Blues&quot;</span>, fmt = <span class="hljs-string">&quot;4d&quot;</span>)<br>    ax.set_title(<span class="hljs-string">&quot;confusion matrix&quot;</span>)<br>    ax.set_xlabel(<span class="hljs-string">&quot;predict&quot;</span>)<br>    ax.set_ylabel(<span class="hljs-string">&quot;true&quot;</span>)  <br>    plt.show()<br><span class="hljs-comment">#绘制混淆矩阵</span><br>cm= confusion_matrix(y_test, y_test_pred1, labels = [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>])<br>plot_confusion_matrix(cm)<br><br><br><span class="hljs-comment"># ==== 代码12-1.py ====</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-comment">#评分数据读取</span><br>file_path = <span class="hljs-string">&#x27;./ml-1m/&#x27;</span><br>file_rating = <span class="hljs-built_in">open</span>(file_path+<span class="hljs-string">&#x27;ratings.dat&#x27;</span>,<span class="hljs-string">&#x27;r&#x27;</span>,encoding = <span class="hljs-string">&quot;ISO-8859-1&quot;</span>)<br>data = file_rating.read()<br>data = data.split(<span class="hljs-string">&#x27;\n&#x27;</span>)<br>file_rating.close()<br>train_data, test_data = train_test_split(data, test_size = <span class="hljs-number">0.2</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练数据数据量：&#x27;</span>+ <span class="hljs-built_in">str</span>(<span class="hljs-built_in">len</span>(train_data)))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;测试数据数据量：&#x27;</span>+ <span class="hljs-built_in">str</span>(<span class="hljs-built_in">len</span>(test_data)))<br>CF_matrix = np.zeros((<span class="hljs-number">6040</span>,<span class="hljs-number">3952</span>))      <span class="hljs-comment">#最大用户ID为6040 ,最大电影ID为3952</span><br><span class="hljs-keyword">for</span> each_data <span class="hljs-keyword">in</span> train_data:<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(each_data) == <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">break</span><br>    str_temp = each_data.split(<span class="hljs-string">&#x27;::&#x27;</span>)      <span class="hljs-comment">#分割数据</span><br>    user_id_temp = <span class="hljs-built_in">int</span>(str_temp[<span class="hljs-number">0</span>]) - <span class="hljs-number">1</span>   <span class="hljs-comment">#将用户ID从0开始编码</span><br>    movies_id_temp = <span class="hljs-built_in">int</span>(str_temp[<span class="hljs-number">1</span>]) - <span class="hljs-number">1</span> <span class="hljs-comment">#将电影ID从0开始编码</span><br>    rating_temp = <span class="hljs-built_in">int</span>(str_temp[<span class="hljs-number">2</span>])       <span class="hljs-comment">#读取评分</span><br>    CF_matrix[user_id_temp][movies_id_temp] = rating_temp   <span class="hljs-comment">#填充矩阵</span><br><span class="hljs-comment">#余弦相似度函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sim_cosine</span>(<span class="hljs-params">x, y</span>):<br>    <span class="hljs-keyword">if</span> np.linalg.norm(x) == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> np.linalg.norm(y) == <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>(x*y) / np.linalg.norm(x) / np.linalg.norm(y)<br><span class="hljs-comment">#计算用户相似度</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;计算用户相似度矩阵：&quot;</span>)<br>user_cross_sim = np.zeros((<span class="hljs-number">6040</span>, <span class="hljs-number">6040</span>))      <span class="hljs-comment">#矩阵初始化</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(CF_matrix.shape[<span class="hljs-number">0</span>])):<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(i, CF_matrix.shape[<span class="hljs-number">0</span>]):<br>        user_cross_sim[i, j] = sim_cosine(CF_matrix[i, :], CF_matrix[j, :]) <span class="hljs-comment">#使用余弦相似度</span><br>        user_cross_sim[j, i] = user_cross_sim[i, j]<br><span class="hljs-comment">#评分预测函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_rating</span>(<span class="hljs-params">user_id, movies_id</span>):<br>    sum_w = <span class="hljs-number">0</span><br>    sum_w_rating = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">6040</span>):<br>        <span class="hljs-keyword">if</span> CF_matrix[i, movies_id] != <span class="hljs-number">0</span>:<br>            sum_w += user_cross_sim[user_id, i]<br>            sum_w_rating += user_cross_sim[user_id, i]*CF_matrix[i, movies_id]<br>    <span class="hljs-keyword">return</span> sum_w_rating / sum_w<br>mae = <span class="hljs-number">0</span><br><span class="hljs-comment">#在测试集上对推荐模型的性能进行评价（MAE）</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(test_data)):<br>    temp_i = train_data[i]<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(temp_i) == <span class="hljs-number">0</span>:              <span class="hljs-comment">#结束</span><br>        <span class="hljs-keyword">break</span><br>    str_temp = temp_i.split(<span class="hljs-string">&#x27;::&#x27;</span>)<br>    user_id_temp = <span class="hljs-built_in">int</span>(str_temp[<span class="hljs-number">0</span>]) - <span class="hljs-number">1</span><br>    movies_id_temp = <span class="hljs-built_in">int</span>(str_temp[<span class="hljs-number">1</span>]) - <span class="hljs-number">1</span><br>    rating_temp = <span class="hljs-built_in">int</span>(str_temp[<span class="hljs-number">2</span>])<br>    rating_pre = predict_rating(user_id_temp, movies_id_temp)<br>    rating_pre = <span class="hljs-built_in">int</span>(rating_pre + <span class="hljs-number">0.5</span>)<br>    mae += <span class="hljs-built_in">abs</span>(rating_temp-rating_pre)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;推荐模型的平均绝对误差:&#x27;</span> + <span class="hljs-built_in">str</span>(mae / (i + <span class="hljs-number">1</span>)))<br><span class="hljs-comment">#对用户1进行电影推荐</span><br>rating_pre_list = []<br>user_id_1 = <span class="hljs-number">0</span><br><span class="hljs-comment">#通过预测的评分矩阵对用户1的评分序列排序，选取前五只属性为其未观看的电影。</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-number">3952</span>):<br>    <span class="hljs-comment">#最大电影ID为3952</span><br>    rating_pre = predict_rating(user_id_1, i)<br>rating_pre_list.append(rating_pre)<br>rating_pre_list_1 = <span class="hljs-built_in">sorted</span>(rating_pre_list, reverse = <span class="hljs-literal">True</span>)<br><span class="hljs-comment">#输出评分top5的未观看电影</span><br>top5 = []<br>count_num = <span class="hljs-number">5</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> rating_pre_list_1:<br>    movies_id_temp = rating_pre_list.index(i)<br>    <span class="hljs-keyword">if</span> CF_matrix[user_id_1, movies_id_temp] == <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">try</span>:<br>            top5.index(movies_id_temp)<br>        <span class="hljs-keyword">except</span> ValueError:<br>            top5.append(movies_id_temp)<br>            count_num -= <span class="hljs-number">1</span><br>            rating_pre_list.pop(movies_id_temp)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">continue</span><br>    <span class="hljs-keyword">if</span> count_num &lt; <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">break</span>  <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;为用户1推荐的评分前五未观看电影为：&quot;</span>, top5)  <br><br><br><br></code></pre></td></tr></table></figure>

<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><h3 id="1-ud-pearsonr-X-y"><a href="#1-ud-pearsonr-X-y" class="headerlink" title="1.ud_pearsonr(X, y)"></a>1.ud_pearsonr(X, y)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 封装的皮尔森相关系数计算函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ud_pearsonr</span>(<span class="hljs-params">X, y</span>):  <br>    result = np.array([pearsonr(x, y) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X.T])     <span class="hljs-comment"># 返回皮尔森相关系数, p值</span><br>    <span class="hljs-keyword">return</span> np.absolute(result[:, <span class="hljs-number">0</span>]), result[:, <span class="hljs-number">1</span>] <br></code></pre></td></tr></table></figure>

<p>这段代码定义了一个名为 <code>ud_pearsonr</code> 的函数，用于计算特征矩阵 <code>X</code> 中的每一列与目标变量 <code>y</code> 之间的皮尔森相关系数。以下是对代码的详细解释：</p>
<p>代码解释</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 封装的皮尔森相关系数计算函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ud_pearsonr</span>(<span class="hljs-params">X, y</span>):  <br>    result = np.array([pearsonr(x, y) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X.T])     <span class="hljs-comment"># 返回皮尔森相关系数, p值</span><br>    <span class="hljs-keyword">return</span> np.absolute(result[:, <span class="hljs-number">0</span>]), result[:, <span class="hljs-number">1</span>] <br></code></pre></td></tr></table></figure>

<ol>
<li>函数定义</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">ud_pearsonr</span>(<span class="hljs-params">X, y</span>):<br></code></pre></td></tr></table></figure>

<ul>
<li><code>ud_pearsonr</code> 是函数的名称。</li>
<li><code>X</code> 是特征矩阵，形状为 <code>(n_samples, n_features)</code>，其中 <code>n_samples</code> 是样本数量，<code>n_features</code> 是特征数量。</li>
<li><code>y</code> 是目标变量，形状为 <code>(n_samples,)</code>。</li>
</ul>
<ol start="2">
<li>计算皮尔森相关系数</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">result = np.array([pearsonr(x, y) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X.T])<br></code></pre></td></tr></table></figure>

<ul>
<li><code>X.T</code> 是特征矩阵 <code>X</code> 的转置，形状为 <code>(n_features, n_samples)</code>。这样做是为了方便对每一列（即每个特征）进行操作。</li>
<li><code>pearsonr(x, y)</code> 是 <code>scipy.stats</code> 模块中的函数，用于计算两个变量之间的皮尔森相关系数及其 p 值。</li>
<li><code>[pearsonr(x, y) for x in X.T]</code> 是一个列表推导式，对 <code>X.T</code> 中的每一列 <code>x</code> 计算其与 <code>y</code> 的皮尔森相关系数和 p 值。</li>
<li><code>np.array(...)</code> 将列表转换为 NumPy 数组，形状为 <code>(n_features, 2)</code>，其中每行包含一个特征的皮尔森相关系数和 p 值。</li>
</ul>
<ol start="3">
<li>返回结果</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">return</span> np.absolute(result[:, <span class="hljs-number">0</span>]), result[:, <span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure>

<ul>
<li><code>result[:, 0]</code> 提取皮尔森相关系数，形状为 <code>(n_features,)</code>。</li>
<li><code>np.absolute(...)</code> 计算相关系数的绝对值，因为相关系数的正负只表示方向，绝对值表示相关性的强度。</li>
<li><code>result[:, 1]</code> 提取 p 值，形状为 <code>(n_features,)</code>。</li>
<li>函数返回两个数组：一个是皮尔森相关系数的绝对值，另一个是 p 值。</li>
</ul>
<p>总结</p>
<p>这个函数的主要作用是计算特征矩阵 <code>X</code> 中的每一列与目标变量 <code>y</code> 之间的皮尔森相关系数，并返回相关系数的绝对值和对应的 p 值。这些值可以用于特征选择，帮助识别哪些特征与目标变量最相关。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" class="category-chain-item">大数据</a>
  
  

      </span>
    
  
    
      <span class="category-chain">
        
  <a href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/" class="category-chain-item">编程语言</a>
  
  
    <span>></span>
    
  <a href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/python/" class="category-chain-item">python</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/python/" class="print-no-link">#python</a>
      
        <a href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" class="print-no-link">#数据挖掘</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Python数据挖掘实战代码</div>
      <div>http://example.com/2024/10/04/Python数据挖掘实战代码/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Tingfeng</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年10月4日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/10/11/%E7%94%A8python%E5%86%99%E4%B8%80%E4%B8%AA%E6%A0%A1%E5%9B%AD%E7%BD%91%E7%99%BB%E5%BD%95%E7%A8%8B%E5%BA%8F/" title="用python写一个校园网登录程序">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">用python写一个校园网登录程序</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/09/02/Hadoop%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/" title="Hadoop大数据技术与应用">
                        <span class="hidden-mobile">Hadoop大数据技术与应用</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"SoI1dWbW2477fTnIsxaEGPdK-gzGzoHsz","appKey":"QW2VXyiVg7h8JOttaYRvJNQT","path":"window.location.pathname","placeholder":"留下你的足迹o(*￣▽￣*)ブ","avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":15,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  
<script src="//cdn.jsdelivr.net/gh/EmoryHuang/BlogBeautify@1.1/love.min.js"></script>
<script src="/js/scrollAnimation.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<!-- hexo injector body_end start --><script src="/js/backgroundize.js"></script><!-- hexo injector body_end end --></body>
</html>
